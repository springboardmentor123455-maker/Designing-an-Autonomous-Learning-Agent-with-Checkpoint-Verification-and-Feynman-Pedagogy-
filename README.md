# Designing an Autonomous Learning Agent with Checkpoint Verification and Feynman Pedagogy

# ğŸ§  Adaptive AI Tutor (LangGraph + Groq + Tavily + Streamlit)

An **Adaptive AI Tutor** that teaches concepts step-by-step, generates short test questions, evaluates learner answers, and if the learner struggles, it automatically switches to **Feynman Technique** teaching mode and re-tests until mastery (or attempts run out).

This project is designed as a complete learning pipeline that includes:

- ğŸ“š **Content generation + enrichment**
- ğŸ§© **Chunking + semantic retrieval**
- ğŸ“ **Adaptive questioning**
- âœ… **Checkpoint verification**
- ğŸ§  **Feynman remediation**
- ğŸ›ï¸ **Streamlit UI**

---

## âœ¨ Key Technologies Used

- **LangGraph** â†’ workflow orchestration + state-based agent execution  
- **Groq LLM (LangChain Groq)** â†’ explanation writing, question generation, answer scoring  
- **Tavily Search** â†’ fetches web content as learning context  
- **SentenceTransformers + NumPy** â†’ embeddings + semantic retrieval for better grading  
- **PyPDF2** â†’ optional PDF reading support  
- **ReportLab** â†’ optional PDF export for raw LLM logs  
- **Streamlit** â†’ frontend UI for interactive learning  

---

## ğŸš€ Features

### ğŸ¯ Learning & Teaching
- âœ… Select a checkpoint topic (or choose **Custom Topic**)
- âœ… Generates structured learning content based on objectives
- âœ… Supports optional learner notes (used to enrich final context)
- âœ… Fetches trusted web content automatically using Tavily
- âœ… Summarizes large content to keep it clean and relevant

### ğŸ§© Context Processing
- âœ… Splits content into overlapping chunks (chunking strategy)
- âœ… Builds a temporary in-memory vector store using embeddings
- âœ… Retrieves the top-k most relevant chunks for question generation & grading

### ğŸ“ Adaptive Testing
- âœ… Generates **exactly 3 short questions**
- âœ… Questions follow strict rules:
  - 1 sentence only
  - Max 18 words
  - Beginner-friendly
  - Must end with `?`
- âœ… Uses different question styles across attempts (role / process / why / application)

### âœ… Answer Evaluation
- âœ… Rejects answers that are too short (less than 30 characters)
- âœ… Rejects unrelated answers using keyword overlap guard
- âœ… Scores answers strictly using buckets:
 
### ğŸ§  Feynman Teaching Mode
- âœ… Automatically activates if the learner fails
- âœ… Generates simplified teaching focused only on weak concepts
- âœ… Re-tests learner with new questions
- âœ… Attempts are limited (default: 3)

---

## ğŸ—‚ï¸ Project Structure

```text
adaptive-ai-tutor/
â”‚
â”œâ”€â”€ backend.py          # LangGraph workflow + tutoring logic
â”œâ”€â”€ app.py              # Streamlit UI
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ README.md           # Documentation
```

---

## âš™ï¸ Setup Instructions (Windows Only)

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/adaptive-ai-tutor.git
cd adaptive-ai-tutor
```

---

### 2ï¸âƒ£ Create Virtual Environment (Recommended)

```bash
python -m venv venv
```

Activate it:

```bash
venv\Scripts\activate
```

If activation works, you will see something like:

```text
(venv)
```

---

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ“¦ requirements.txt (Example)

Create a `requirements.txt` like this:

```txt
streamlit
langgraph
langchain-groq
tavily-python
sentence-transformers
numpy
PyPDF2
reportlab
langsmith
ipython
```

---

## ğŸ”‘ Environment Variables (IMPORTANT)

This project requires API keys for:

- **Groq** â†’ LLM inference  
- **Tavily** â†’ web search context  
- **LangSmith** (optional) â†’ tracing & debugging  

### âœ… Recommended: Set Keys in Windows PowerShell

Open PowerShell and run:

```powershell
$env:GROQ_API_KEY="YOUR_TOKEN"
$env:TAVILY_API_KEY="YOUR_TOKEN"
$env:LANGSMITH_TRACING="true"
$env:LANGSMITH_API_KEY="YOUR_TOKEN"
```

âš ï¸ These keys apply only to the current terminal session.

---


## â–¶ï¸ Run the Streamlit App

Start the UI:

```bash
streamlit run app.py
```

Then open the URL shown in terminal (usually):

```text
http://localhost:8501
```

---

## ğŸ§ª Run Backend in Terminal Mode (Optional)

You can run the backend without Streamlit:

```bash
python backend.py
```

It will ask you to choose:

- `1` â†’ interactive learning run (answer questions manually)
- `2` â†’ evaluation suite (automated testing)

---

## ğŸ“Œ How the Tutor Works (Pipeline Overview)

### Step 1: Checkpoint Selection
User selects a checkpoint like:

- CP1 â€” Basics of Neural Networks
- CP2 â€” Loss Functions
- ...
- CP10 â€” Regularization Techniques

Or selects **Custom Topic**.

---

### Step 2: Context Gathering
The tutor gathers learning content from:

- **User notes** (optional)
- **PDFs** (optional, supported in backend)
- **Web search** (always enabled via Tavily)

Then it merges everything into one clean explanation.

---

### Step 3: Context Validation
The system checks relevance using embeddings:

- If content is unrelated â†’ it refetches from the web
- It also scores coverage of objectives (1â€“5)

---

### Step 4: Chunking + Temporary Vector Store
The context is split into chunks:

- Chunk size: **1200**
- Overlap: **250**
- Minimum chunk length: **300**

Embeddings are generated using:

- `all-MiniLM-L6-v2`

This allows top-k retrieval for grading.

---

### Step 5: Question Generation
The tutor generates 3 questions per attempt:

- Short and simple
- Different style per attempt
- Focused on weak concepts

---

### Step 6: Answer Verification
Each answer is checked using:

1. **Short answer filter**
2. **Keyword overlap guard**
3. **LLM-based scoring bucket**

Final pass condition:

- All answers must score **>= 70**

---

### Step 7: Feynman Remediation (If Failed)
If learner fails:

- Tutor explains only the weak concepts
- Uses simple step-by-step teaching
- Generates new questions again
- Repeats until pass or attempts finish

---

## ğŸ§  Scoring System

Each answer gets one of:

- **0** â†’ wrong/unrelated
- **40** â†’ partial understanding
- **70** â†’ correct with minor gaps
- **100** â†’ fully correct

Overall score is average of the 3 answers.

Passing rule:

- Must score **>= 70 on all questions**

---

## ğŸ§© Checkpoints Included

The current learning path includes:

- CP1 â€” Basics of Neural Networks  
- CP2 â€” Loss Functions  
- CP3 â€” Gradient Descent  
- CP4 â€” Learning Rate  
- CP5 â€” Activation Functions  
- CP6 â€” Backpropagation  
- CP7 â€” Overfitting and Generalization  
- CP8 â€” Train Validation and Test Data  
- CP9 â€” Weight Initialization  
- CP10 â€” Regularization Techniques  

---

## ğŸ›¡ï¸ Notes & Security

- Never commit API keys to GitHub
- Always use environment variables
- Web results depend on Tavily + internet
- Scoring is strict by design to encourage real understanding

---

## ğŸŒŸ Future Improvements

- Add PDF upload option inside Streamlit UI
- Add progress tracking per checkpoint
- Add difficulty levels (Beginner / Intermediate / Advanced)
- Add database support for multi-user learning sessions
- Add better UI analytics (weak topics chart)

---

## ğŸ“œ License

This project is open-source and free to use for learning and educational purposes.
