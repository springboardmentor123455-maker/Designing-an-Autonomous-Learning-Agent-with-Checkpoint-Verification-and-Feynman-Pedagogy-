# ğŸ“‚ Project Structure Guide

**Autonomous Learning Agent - Complete Directory Structure**

---

## ğŸ“‹ Table of Contents

1. [Directory Tree](#-directory-tree)
2. [File-by-File Breakdown](#-file-by-file-breakdown)
3. [Module Dependencies](#-module-dependencies)
4. [Data Flow Diagram](#-data-flow-diagram)
5. [Code Organization](#-code-organization)

---

## ğŸŒ³ Directory Tree

```
Tutor/
â”‚
â”œâ”€â”€ ğŸ“„ app.py                                    [986 lines] - Streamlit Web Interface
â”œâ”€â”€ ğŸ“„ main.py                                   [218 lines] - CLI Demo Script
â”œâ”€â”€ ğŸ“„ requirements.txt                          [24 lines]  - Python Dependencies
â”œâ”€â”€ ğŸ“„ README.md                                 [860 lines] - User Documentation
â”œâ”€â”€ ğŸ“„ DOCUMENTATION.md                          [NEW]       - Technical Documentation
â”œâ”€â”€ ğŸ“„ PROJECT_STRUCTURE.md                      [NEW]       - This File
â”œâ”€â”€ ğŸ“„ LICENSE                                               - MIT License
â”œâ”€â”€ ğŸ“„ .env.example                                          - Environment Template
â”œâ”€â”€ ğŸ“„ .env                                                  - API Keys (DO NOT COMMIT)
â”œâ”€â”€ ğŸ“„ .gitignore                                            - Git Ignore Rules
â”‚
â”œâ”€â”€ ğŸ“ src/                                                  - Source Code (Main Application)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py                                       - Package Initializer
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ models/                                           - Data Models & State
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ checkpoint.py                    [48 lines]  - Checkpoint & Context Models
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ class Checkpoint                            - Learning checkpoint definition
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ topic: str
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ objectives: List[str]
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ difficulty_level: str
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ estimated_time_minutes: int
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ class GatheredContext                       - Gathered learning content
â”‚   â”‚   â”‚       â”œâ”€â”€ source: str
â”‚   â”‚   â”‚       â”œâ”€â”€ content: str
â”‚   â”‚   â”‚       â”œâ”€â”€ gathered_at: datetime
â”‚   â”‚   â”‚       â””â”€â”€ relevance_score: float
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“„ state.py                         [133 lines] - LangGraph State Definition
â”‚   â”‚       â”‚
â”‚   â”‚       â”œâ”€â”€ class LearningState(TypedDict)              - Workflow state container
â”‚   â”‚       â”‚   â”œâ”€â”€ all_checkpoints: List[Checkpoint]
â”‚   â”‚       â”‚   â”œâ”€â”€ current_checkpoint_index: int
â”‚   â”‚       â”‚   â”œâ”€â”€ checkpoint: Optional[Checkpoint]
â”‚   â”‚       â”‚   â”œâ”€â”€ completed_checkpoints: List[int]
â”‚   â”‚       â”‚   â”œâ”€â”€ user_notes: Optional[str]
â”‚   â”‚       â”‚   â”œâ”€â”€ gathered_contexts: List[GatheredContext]
â”‚   â”‚       â”‚   â”œâ”€â”€ context_valid: bool
â”‚   â”‚       â”‚   â”œâ”€â”€ context_chunks: List[str]
â”‚   â”‚       â”‚   â”œâ”€â”€ vector_store: Optional[FAISS]
â”‚   â”‚       â”‚   â”œâ”€â”€ questions: List[Dict]
â”‚   â”‚       â”‚   â”œâ”€â”€ answers: List[Dict]
â”‚   â”‚       â”‚   â”œâ”€â”€ understanding_score: Optional[float]
â”‚   â”‚       â”‚   â”œâ”€â”€ passed_checkpoint: bool
â”‚   â”‚       â”‚   â”œâ”€â”€ weak_concepts: List[str]
â”‚   â”‚       â”‚   â”œâ”€â”€ feynman_explanations: List[Dict]
â”‚   â”‚       â”‚   â”œâ”€â”€ feynman_attempts: int
â”‚   â”‚       â”‚   â”œâ”€â”€ current_stage: str
â”‚   â”‚       â”‚   â”œâ”€â”€ messages: List[str]
â”‚   â”‚       â”‚   â””â”€â”€ error: Optional[str]
â”‚   â”‚       â”‚
â”‚   â”‚       â””â”€â”€ def create_initial_state()                  - State factory function
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ graph/                                            - LangGraph Workflow
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â””â”€â”€ ğŸ“„ learning_graph.py                [756 lines] - Workflow Orchestration
â”‚   â”‚       â”‚
â”‚   â”‚       â”œâ”€â”€ class LearningGraph                         - Main workflow engine
â”‚   â”‚       â”‚   â”‚
â”‚   â”‚       â”‚   â”œâ”€â”€ __init__()                              - Initialize components
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ ContextManager
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ VectorStoreManager
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ QuestionGenerator
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ UnderstandingVerifier
â”‚   â”‚       â”‚   â”‚   â””â”€â”€ FeynmanTeacher
â”‚   â”‚       â”‚   â”‚
â”‚   â”‚       â”‚   â”œâ”€â”€ build_graph()                           - Build StateGraph
â”‚   â”‚       â”‚   â”‚
â”‚   â”‚       â”‚   â”œâ”€â”€ Workflow Nodes:
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ define_checkpoint_node()            - Initialize checkpoint
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ gather_context_node()               - Gather learning content
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ validate_context_node()             - Validate relevance
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ process_context_node()              - Create embeddings
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ generate_questions_node()           - Generate questions
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ evaluate_answers_node()             - Score answers
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ feynman_teaching_node()             - Generate explanations
â”‚   â”‚       â”‚   â”‚   â””â”€â”€ move_to_next_checkpoint_node()      - Advance checkpoint
â”‚   â”‚       â”‚   â”‚
â”‚   â”‚       â”‚   â””â”€â”€ Conditional Logic:
â”‚   â”‚       â”‚       â”œâ”€â”€ should_retry_context()              - Context retry logic
â”‚   â”‚       â”‚       â”œâ”€â”€ should_apply_feynman()              - Feynman trigger (< 70%)
â”‚   â”‚       â”‚       â”œâ”€â”€ should_regenerate_questions()       - Question regen logic
â”‚   â”‚       â”‚       â””â”€â”€ has_more_checkpoints()              - Next checkpoint check
â”‚   â”‚       â”‚
â”‚   â”‚       â””â”€â”€ def create_learning_graph()                 - Factory function
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ modules/                                          - Core Business Logic
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ context_manager.py               [336 lines] - Context Gathering & Validation
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ class ContextManager
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__()                              - Initialize LLMs & text splitter
â”‚   â”‚   â”‚       â”œâ”€â”€ gather_context()                        - Gather from notes + web
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ Process user notes
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ Web search with deduplication
â”‚   â”‚   â”‚       â”œâ”€â”€ validate_context()                      - LLM-based validation
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ Score relevance (0-1)
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ Return is_valid, message
â”‚   â”‚   â”‚       â”œâ”€â”€ chunk_context()                         - Split into chunks
â”‚   â”‚   â”‚       â””â”€â”€ _calculate_relevance_score()            - LLM scoring
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ vector_store_manager.py          [106 lines] - FAISS Vector Operations
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ class VectorStoreManager
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__()                              - Initialize embeddings
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ HuggingFace: all-MiniLM-L6-v2
â”‚   â”‚   â”‚       â”œâ”€â”€ create_vector_store()                   - Create FAISS from chunks
â”‚   â”‚   â”‚       â”œâ”€â”€ similarity_search()                     - Semantic search
â”‚   â”‚   â”‚       â””â”€â”€ get_relevant_context()                  - Multi-objective context
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ question_generator.py            [179 lines] - LLM Question Generation
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ class QuestionGenerator
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__()                              - Initialize LLM
â”‚   â”‚   â”‚       â”œâ”€â”€ generate_questions()                    - Generate 3-5 questions
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ LLM prompt with objectives
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ Parse structured response
â”‚   â”‚   â”‚       â”œâ”€â”€ _parse_questions()                      - Extract from LLM output
â”‚   â”‚   â”‚       â””â”€â”€ _get_default_questions()                - Fallback questions
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ understanding_verifier.py        [222 lines] - Answer Evaluation & Scoring
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ class UnderstandingVerifier
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__()                              - Initialize LLM & threshold
â”‚   â”‚   â”‚       â”œâ”€â”€ evaluate_answers()                      - Score all answers
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ Score each answer (0-1)
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ Calculate average
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ Check 70% threshold
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ Identify weak concepts
â”‚   â”‚   â”‚       â”œâ”€â”€ _score_answer()                         - LLM-based scoring
â”‚   â”‚   â”‚       â””â”€â”€ _parse_score()                          - Extract score from LLM
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“„ feynman_teacher.py               [240 lines] - Adaptive Feynman Teaching
â”‚   â”‚       â”‚
â”‚   â”‚       â””â”€â”€ class FeynmanTeacher
â”‚   â”‚           â”œâ”€â”€ __init__()                              - Initialize LLM
â”‚   â”‚           â”œâ”€â”€ generate_explanations()                 - Generate for weak concepts
â”‚   â”‚           â”‚   â”œâ”€â”€ Identify unique weak concepts
â”‚   â”‚           â”‚   â”œâ”€â”€ Get related Q&A
â”‚   â”‚           â”‚   â””â”€â”€ Generate simplified explanation
â”‚   â”‚           â”œâ”€â”€ _get_related_qa()                       - Find related questions
â”‚   â”‚           â””â”€â”€ _generate_simplified_explanation()      - Feynman prompt
â”‚   â”‚               â”œâ”€â”€ Simple language
â”‚   â”‚               â”œâ”€â”€ Analogies
â”‚   â”‚               â”œâ”€â”€ Step-by-step breakdown
â”‚   â”‚               â””â”€â”€ Code examples
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ utils/                                            - Utility Functions
â”‚       â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ“„ llm_provider.py                  [255 lines] - LLM Initialization
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ def get_llm()                               - Get primary LLM
â”‚       â”‚   â”‚   â”œâ”€â”€ Support for Google Gemini
â”‚       â”‚   â”‚   â”œâ”€â”€ Support for OpenAI
â”‚       â”‚   â”‚   â””â”€â”€ Environment-based config
â”‚       â”‚   â”œâ”€â”€ def get_reasoning_llm()                     - Get powerful LLM
â”‚       â”‚   â””â”€â”€ def get_validation_llm()                    - Get fast LLM
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ“„ search_tools.py                  [152 lines] - Web Search Integration
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€â”€ def search_for_learning_content()           - Multi-provider search
â”‚       â”‚       â”œâ”€â”€ Tavily Search (preferred)
â”‚       â”‚       â”œâ”€â”€ DuckDuckGo Search (fallback)
â”‚       â”‚       â””â”€â”€ Google Search (optional)
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ“„ pdf_generator.py                 [369 lines] - PDF Report Generation
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€â”€ class LearningReportGenerator
â”‚       â”‚       â”œâ”€â”€ __init__()                              - Setup ReportLab styles
â”‚       â”‚       â”œâ”€â”€ generate_report()                       - Main report generator
â”‚       â”‚       â”‚   â”œâ”€â”€ Title page
â”‚       â”‚       â”‚   â”œâ”€â”€ Executive summary
â”‚       â”‚       â”‚   â”œâ”€â”€ Checkpoint details
â”‚       â”‚       â”‚   â”œâ”€â”€ Performance analytics
â”‚       â”‚       â”‚   â”œâ”€â”€ Feynman explanations
â”‚       â”‚       â”‚   â””â”€â”€ Recommendations
â”‚       â”‚       â”œâ”€â”€ _build_title_page()
â”‚       â”‚       â”œâ”€â”€ _build_summary()
â”‚       â”‚       â”œâ”€â”€ _build_checkpoint_details()
â”‚       â”‚       â”œâ”€â”€ _build_analytics()
â”‚       â”‚       â”œâ”€â”€ _build_feynman_section()
â”‚       â”‚       â””â”€â”€ _build_recommendations()
â”‚       â”‚
â”‚       â””â”€â”€ ğŸ“„ database_manager.py              [296 lines] - SQLite Operations
â”‚           â”‚
â”‚           â””â”€â”€ class SessionDatabase
â”‚               â”œâ”€â”€ __init__()                              - Initialize DB connection
â”‚               â”œâ”€â”€ _init_database()                        - Create tables
â”‚               â”‚   â”œâ”€â”€ sessions table
â”‚               â”‚   â”œâ”€â”€ checkpoints table
â”‚               â”‚   â”œâ”€â”€ questions table
â”‚               â”‚   â””â”€â”€ performance_metrics table
â”‚               â”œâ”€â”€ save_session()                          - Save complete session
â”‚               â”œâ”€â”€ get_session_history()                   - Retrieve sessions
â”‚               â”œâ”€â”€ get_performance_stats()                 - Calculate stats
â”‚               â””â”€â”€ delete_session()                        - Delete session
â”‚
â”œâ”€â”€ ğŸ“ notebooks/                                            - Development Artifacts (Optional)
â”‚   â”œâ”€â”€ ğŸ“„ Milestone2.ipynb                                  - Milestone 2 testing
â”‚   â”œâ”€â”€ ğŸ“„ Milestone3.ipynb                                  - Milestone 3 testing
â”‚   â”œâ”€â”€ ğŸ“„ Milestone3_Presentation.ipynb                     - Presentation notebook
â”‚   â”œâ”€â”€ ğŸ“„ Complete_Testing_Tutorial.ipynb                   - Testing guide
â”‚   â”œâ”€â”€ ğŸ“„ interactive_analysis.ipynb                        - Interactive testing
â”‚   â””â”€â”€ ğŸ“„ ter_agent_autonomous_test_checkpoint.ipynb        - Early checkpoint tests
â”‚
â”œâ”€â”€ ğŸ“ tests/                                                - Unit Tests (Placeholder)
â”‚   â””â”€â”€ ğŸ“„ __init__.py
â”‚
â”œâ”€â”€ ğŸ“ venv/                                                 - Virtual Environment (Generated)
â”‚   â”œâ”€â”€ Scripts/                                             - Windows executables
â”‚   â”œâ”€â”€ Lib/                                                 - Python packages
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ ğŸ“„ learning_sessions.db                                  - SQLite Database (Generated)
```

---

## ğŸ“„ File-by-File Breakdown

### Root Level Files

#### `app.py` (986 lines) - Streamlit Web Application

**Purpose:** Complete web interface for the learning agent

**Key Components:**
```python
# Session State Management
def init_session_state()                    # Initialize all session variables

# Page Functions
def setup_page()                            # Setup checkpoints & notes
def learning_page()                         # Display learning progress
def questions_page()                        # Question answering interface
def results_page()                          # Show scores & feedback
def feynman_page()                          # Feynman explanations display
def complete_page()                         # Session completion & PDF download

# Helper Functions
def run_learning_workflow()                 # Execute LangGraph workflow
def generate_pdf_report()                   # Create PDF report
def save_to_database()                      # Save session to DB

# UI Components
- Sidebar with navigation
- Progress tracking
- Real-time analytics dashboard
- PDF download button
- Historical performance charts
```

**Features:**
- âœ… Multi-page navigation
- âœ… Real-time progress tracking
- âœ… Interactive Q&A interface
- âœ… Auto-submit functionality
- âœ… Auto-Feynman trigger
- âœ… PDF report generation
- âœ… Historical analytics
- âœ… Plotly charts

---

#### `main.py` (218 lines) - CLI Demo Script

**Purpose:** Command-line demonstration script

**Structure:**
```python
def main():
    # 1. Create checkpoints
    checkpoints = [checkpoint1, checkpoint2]
    
    # 2. Provide user notes
    user_notes = "..."
    
    # 3. Initialize state
    state = create_initial_state(checkpoints, user_notes)
    
    # 4. Create graph
    graph = create_learning_graph()
    
    # 5. Execute workflow
    result = graph.invoke(state)
    
    # 6. Display results
    print_results(result)
```

**Use Cases:**
- Testing workflow without UI
- Debugging graph execution
- Automated testing
- Demo presentations

---

#### `requirements.txt` (24 lines) - Dependencies

**Categories:**

1. **Core Framework:**
   - streamlit>=1.28.0
   - langgraph>=0.2.0
   - langchain>=0.3.0

2. **LLM Integration:**
   - langchain-openai>=0.2.0
   - langchain-google-genai
   - langchain-groq>=0.2.0

3. **ML/AI:**
   - faiss-cpu>=1.7.4
   - sentence-transformers>=2.2.0
   - langchain-huggingface>=0.0.1

4. **Search:**
   - tavily-python
   - duckduckgo-search>=6.0.0
   - google-search-results>=2.4.2

5. **Reports & Analytics:**
   - reportlab>=4.0.0
   - plotly>=5.17.0
   - pandas>=2.1.0
   - sqlalchemy>=2.0.0

6. **Utilities:**
   - python-dotenv>=1.0.0
   - tiktoken>=0.5.0

---

### Source Code (`src/`)

#### Models Directory (`src/models/`)

##### `checkpoint.py` (48 lines)

**Classes:**

```python
@dataclass
class Checkpoint:
    """Learning checkpoint definition"""
    topic: str                          # Main topic
    objectives: List[str]               # Learning objectives
    difficulty_level: str               # beginner/intermediate/advanced
    estimated_time_minutes: int         # Time estimate
    prerequisites: List[str]            # Prerequisites
    created_at: datetime                # Creation time

@dataclass
class GatheredContext:
    """Context gathered from various sources"""
    source: str                         # user_notes/web_search/etc
    content: str                        # Actual content
    gathered_at: datetime               # Gathering time
    metadata: Dict[str, Any]            # Additional info
    relevance_score: Optional[float]    # 0-1 relevance score
```

---

##### `state.py` (133 lines)

**Classes & Functions:**

```python
class LearningState(TypedDict):
    """Complete workflow state - 25+ fields"""
    # See DOCUMENTATION.md for full structure

def create_initial_state(checkpoints, user_notes) -> LearningState:
    """Factory function to create initial state"""
    # Returns fully initialized LearningState
```

---

#### Graph Directory (`src/graph/`)

##### `learning_graph.py` (756 lines)

**Main Class:**

```python
class LearningGraph:
    """Orchestrates the complete learning workflow"""
    
    # Initialization
    __init__(force_poor_answers=False)
    build_graph() -> StateGraph
    
    # Workflow Nodes (8 nodes)
    define_checkpoint_node(state) -> LearningState
    gather_context_node(state) -> LearningState
    validate_context_node(state) -> LearningState
    process_context_node(state) -> LearningState
    generate_questions_node(state) -> LearningState
    evaluate_answers_node(state) -> LearningState
    feynman_teaching_node(state) -> LearningState
    move_to_next_checkpoint_node(state) -> LearningState
    
    # Conditional Logic (4 functions)
    should_retry_context(state) -> str
    should_apply_feynman(state) -> str
    should_regenerate_questions(state) -> str
    has_more_checkpoints(state) -> str
```

**Graph Structure:**

```
START â†’ define_checkpoint
        â†“
    gather_context
        â†“
    validate_context â†â”€â”€â” (retry if invalid)
        â†“               â”‚
    process_context     â”‚
        â†“               â”‚
    generate_questions  â”‚
        â†“               â”‚
    [WAIT FOR ANSWERS]  â”‚
        â†“               â”‚
    evaluate_answers    â”‚
        â†“               â”‚
    [score >= 70%?]     â”‚
        â†“         â†“     â”‚
       YES       NO     â”‚
        â†“         â†“     â”‚
    next_checkpoint     â”‚
        â†“        feynman_teaching
        â†“         â†“     â”‚
    [more checkpoints?] â”‚
        â†“         â†“     â”‚
       YES   regenerate_questions
        â†“         â†“
    define_checkpoint
        â†“
       END
```

---

#### Modules Directory (`src/modules/`)

##### `context_manager.py` (336 lines)

**Responsibilities:**
1. Gather context from multiple sources
2. Validate context relevance
3. Chunk text for embedding
4. Deduplicate URLs across retries

**Key Methods:**

```python
gather_context(checkpoint, user_notes, max_web_results=6)
    # 1. Process user notes (if provided)
    # 2. Search web with Tavily/DuckDuckGo
    # 3. Deduplicate by URL
    # Returns: List[GatheredContext]

validate_context(checkpoint, contexts)
    # 1. Score each context with LLM (0-1)
    # 2. Check average score >= 0.6
    # 3. Return (is_valid, message, scored_contexts)

chunk_context(contexts, chunk_size=1000)
    # 1. Combine all contexts
    # 2. Split with RecursiveCharacterTextSplitter
    # Returns: List[str] chunks
```

---

##### `vector_store_manager.py` (106 lines)

**Responsibilities:**
1. Create FAISS vector stores
2. Perform similarity search
3. Retrieve relevant context

**Key Methods:**

```python
create_vector_store(text_chunks)
    # 1. Create Document objects
    # 2. Generate embeddings
    # 3. Build FAISS index
    # Returns: FAISS vector store

similarity_search(vector_store, query, k=3)
    # 1. Query vector store
    # 2. Return top-k results
    # Returns: List[Document]

get_relevant_context(vector_store, objectives, k_per_objective=2)
    # 1. Search for each objective
    # 2. Deduplicate results
    # 3. Combine into string
    # Returns: str (combined context)
```

---

##### `question_generator.py` (179 lines)

**Responsibilities:**
1. Generate 3-5 assessment questions
2. Align with learning objectives
3. Parse LLM responses

**Key Methods:**

```python
generate_questions(checkpoint, context, num_questions=4)
    # 1. Create LLM prompt with objectives + context
    # 2. Generate questions with LLM
    # 3. Parse into structured format
    # Returns: List[Dict] with questions

_parse_questions(response, checkpoint)
    # Extract questions from LLM response
    # Returns: List[Dict]

_get_default_questions(checkpoint)
    # Fallback questions if LLM fails
    # Returns: List[Dict]
```

**Question Structure:**
```python
{
    'id': 1,
    'question': "What is the purpose of...?",
    'objective': "Understand XYZ",
    'difficulty': 'medium'
}
```

---

##### `understanding_verifier.py` (222 lines)

**Responsibilities:**
1. Score individual answers
2. Calculate average score
3. Apply 70% threshold
4. Identify weak concepts

**Key Methods:**

```python
evaluate_answers(questions, answers, context)
    # 1. Score each answer with LLM
    # 2. Calculate average
    # 3. Check >= 70% threshold
    # 4. Identify weak concepts (< 70%)
    # Returns: (avg_score, passed, weak_concepts)

_score_answer(question, answer, context)
    # 1. Create scoring prompt
    # 2. Get LLM score (0-100)
    # 3. Normalize to 0-1
    # Returns: float (0-1)
```

---

##### `feynman_teacher.py` (240 lines)

**Responsibilities:**
1. Generate simplified explanations
2. Use Feynman Technique principles
3. Create analogies and examples

**Key Methods:**

```python
generate_explanations(questions, answers, context, weak_concepts)
    # 1. Get unique weak concepts
    # 2. Find related Q&A pairs
    # 3. Generate simplified explanation for each
    # Returns: List[Dict] with explanations

_generate_simplified_explanation(concept, related_qa, context)
    # 1. Create Feynman-style prompt
    # 2. Generate explanation with LLM
    # 3. Include analogies + examples
    # Returns: str (explanation)
```

**Feynman Principles:**
- Simple language (12-year-old level)
- Analogies and metaphors
- Step-by-step breakdowns
- Concrete examples
- Address common mistakes

---

#### Utils Directory (`src/utils/`)

##### `llm_provider.py` (255 lines)

**Functions:**

```python
get_llm(model_name=None, temperature=0.7, max_tokens=None, provider=None)
    # Primary LLM for most tasks
    # Default: gemini-1.5-flash
    # Returns: ChatOpenAI instance

get_reasoning_llm()
    # Powerful LLM for complex reasoning
    # Default: gemini-1.5-pro
    # Returns: ChatOpenAI instance

get_validation_llm()
    # Fast LLM for validation tasks
    # Default: gemini-1.5-flash
    # Returns: ChatOpenAI instance
```

**Supported Providers:**
- Google Gemini (via langchain-google-genai)
- OpenAI (via langchain-openai)
- Azure OpenAI (via langchain-openai)
- Groq (optional)

---

##### `search_tools.py` (152 lines)

**Functions:**

```python
search_for_learning_content(topic, objectives, max_results=5)
    # 1. Try Tavily Search (preferred)
    # 2. Fallback to DuckDuckGo
    # 3. Optional: Google Search
    # Returns: List[Dict] with search results
```

**Result Structure:**
```python
{
    'url': "https://...",
    'title': "...",
    'snippet': "...",
    'content': "..."
}
```

---

##### `pdf_generator.py` (369 lines)

**Class:**

```python
class LearningReportGenerator:
    """Generate professional PDF reports"""
    
    generate_report(session_data)
        # Creates multi-page PDF with:
        # - Title page
        # - Executive summary
        # - Checkpoint details with scores
        # - Performance analytics
        # - Feynman explanations (if used)
        # - Personalized recommendations
        # Returns: BytesIO buffer
```

**Report Sections:**
1. **Title Page:** Session info, date, overall score
2. **Summary:** Key metrics, pass/fail status
3. **Checkpoints:** Detailed breakdown per checkpoint
4. **Analytics:** Charts and visualizations
5. **Feynman:** Explanations (if applicable)
6. **Recommendations:** Next steps based on performance

---

##### `database_manager.py` (296 lines)

**Class:**

```python
class SessionDatabase:
    """Manage SQLite database for history"""
    
    _init_database()
        # Create 4 tables:
        # - sessions
        # - checkpoints
        # - questions
        # - performance_metrics
    
    save_session(session_data)
        # Save complete session with all data
        # Returns: session_id
    
    get_session_history(limit=10)
        # Retrieve recent sessions
        # Returns: List[Dict]
    
    get_performance_stats()
        # Calculate statistics:
        # - Total sessions
        # - Average score
        # - Pass rate
        # - Total time
        # Returns: Dict
```

---

## ğŸ”— Module Dependencies

### Dependency Graph

```
app.py / main.py
    â”‚
    â”œâ”€â”€> src.models.checkpoint
    â”‚    â””â”€â”€ Checkpoint, GatheredContext
    â”‚
    â”œâ”€â”€> src.models.state
    â”‚    â””â”€â”€ LearningState, create_initial_state()
    â”‚
    â””â”€â”€> src.graph.learning_graph
         â””â”€â”€ LearningGraph
              â”‚
              â”œâ”€â”€> src.modules.context_manager
              â”‚    â””â”€â”€ ContextManager
              â”‚         â””â”€â”€> src.utils.llm_provider
              â”‚         â””â”€â”€> src.utils.search_tools
              â”‚
              â”œâ”€â”€> src.modules.vector_store_manager
              â”‚    â””â”€â”€ VectorStoreManager
              â”‚         â””â”€â”€> HuggingFace Embeddings
              â”‚
              â”œâ”€â”€> src.modules.question_generator
              â”‚    â””â”€â”€ QuestionGenerator
              â”‚         â””â”€â”€> src.utils.llm_provider
              â”‚
              â”œâ”€â”€> src.modules.understanding_verifier
              â”‚    â””â”€â”€ UnderstandingVerifier
              â”‚         â””â”€â”€> src.utils.llm_provider
              â”‚
              â””â”€â”€> src.modules.feynman_teacher
                   â””â”€â”€ FeynmanTeacher
                        â””â”€â”€> src.utils.llm_provider

app.py only:
    â”œâ”€â”€> src.utils.pdf_generator
    â”‚    â””â”€â”€ LearningReportGenerator
    â”‚
    â””â”€â”€> src.utils.database_manager
         â””â”€â”€ SessionDatabase
```

### Import Chain

```python
# Level 1: Models (no dependencies)
src.models.checkpoint
src.models.state

# Level 2: Utils (depend on external libs only)
src.utils.llm_provider
src.utils.search_tools

# Level 3: Modules (depend on utils + models)
src.modules.context_manager
src.modules.vector_store_manager
src.modules.question_generator
src.modules.understanding_verifier
src.modules.feynman_teacher

# Level 4: Graph (depends on everything)
src.graph.learning_graph

# Level 5: Applications (depend on graph)
app.py
main.py

# Level 5: Additional Utils (standalone)
src.utils.pdf_generator
src.utils.database_manager
```

---

## ğŸ“Š Data Flow Diagram

### Complete Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER INPUT                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Checkpoints     â”‚     â”‚   User Notes         â”‚     â”‚
â”‚  â”‚  (Topic +        â”‚     â”‚   (Learning          â”‚     â”‚
â”‚  â”‚   Objectives)    â”‚     â”‚    Materials)        â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                        â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  create_initial_state() â”‚
            â”‚  (LearningState)        â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LANGGRAPH WORKFLOW                         â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 1. Define Checkpoint                            â”‚   â”‚
â”‚  â”‚    Input:  all_checkpoints, current_index       â”‚   â”‚
â”‚  â”‚    Output: checkpoint                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚               â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 2. Gather Context                               â”‚   â”‚
â”‚  â”‚    Input:  checkpoint, user_notes               â”‚   â”‚
â”‚  â”‚    Process: Web search + text extraction        â”‚   â”‚
â”‚  â”‚    Output: gathered_contexts []                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚               â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 3. Validate Context                             â”‚   â”‚
â”‚  â”‚    Input:  gathered_contexts                    â”‚   â”‚
â”‚  â”‚    Process: LLM relevance scoring               â”‚   â”‚
â”‚  â”‚    Output: context_valid, scored_contexts       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚               â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 4. Process Context                              â”‚   â”‚
â”‚  â”‚    Input:  gathered_contexts                    â”‚   â”‚
â”‚  â”‚    Process: Chunking + FAISS embeddings         â”‚   â”‚
â”‚  â”‚    Output: context_chunks, vector_store         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚               â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 5. Generate Questions                           â”‚   â”‚
â”‚  â”‚    Input:  checkpoint, vector_store             â”‚   â”‚
â”‚  â”‚    Process: LLM question generation             â”‚   â”‚
â”‚  â”‚    Output: questions []                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚               â”‚                                         â”‚
â”‚               â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚        [WAIT FOR USER ANSWERS]                 â”‚    â”‚
â”‚  â”‚     (Streamlit UI / CLI input)                 â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚               â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 6. Evaluate Answers                             â”‚   â”‚
â”‚  â”‚    Input:  questions, answers, vector_store     â”‚   â”‚
â”‚  â”‚    Process: LLM answer scoring                  â”‚   â”‚
â”‚  â”‚    Output: understanding_score, passed,         â”‚   â”‚
â”‚  â”‚            weak_concepts                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚               â”‚                                         â”‚
â”‚          [Score >= 70%?]                                â”‚
â”‚               â”‚                                         â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚       YES            NO                                 â”‚
â”‚        â”‚              â”‚                                 â”‚
â”‚        â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚        â”‚    â”‚ 7. Feynman Teaching                 â”‚    â”‚
â”‚        â”‚    â”‚    Input:  weak_concepts, Q&A       â”‚    â”‚
â”‚        â”‚    â”‚    Process: Generate explanations   â”‚    â”‚
â”‚        â”‚    â”‚    Output: feynman_explanations     â”‚    â”‚
â”‚        â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚        â”‚              â”‚                                 â”‚
â”‚        â”‚         [Attempts < 3?]                       â”‚
â”‚        â”‚              â”‚                                 â”‚
â”‚        â”‚             YES                                â”‚
â”‚        â”‚              â”‚                                 â”‚
â”‚        â”‚              â””â”€â”€â–º Regenerate Questions        â”‚
â”‚        â”‚                                                â”‚
â”‚        â”‚                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ 8. Move to Next Checkpoint                     â”‚    â”‚
â”‚  â”‚    Input:  current_checkpoint_index            â”‚    â”‚
â”‚  â”‚    Process: Increment index                    â”‚    â”‚
â”‚  â”‚    Output: completed_checkpoints []            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚               â”‚                                         â”‚
â”‚       [More Checkpoints?]                              â”‚
â”‚               â”‚                                         â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚       YES            NO                                 â”‚
â”‚        â”‚              â”‚                                 â”‚
â”‚        â””â”€â”€â–º Define    â”‚                                 â”‚
â”‚          Checkpoint   â”‚                                 â”‚
â”‚                       â–¼                                 â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚                    â”‚    COMPLETE      â”‚                â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FINAL OUTPUT                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  LearningState   â”‚  â”‚  Session Data        â”‚       â”‚
â”‚  â”‚  (Complete)      â”‚  â”‚  (For Reporting)     â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                     â”‚
            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
            â”‚          â”‚          â”‚
       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”
       â”‚  UI   â”‚  â”‚  PDF   â”‚  â”‚Databaseâ”‚
       â”‚Displayâ”‚  â”‚ Report â”‚  â”‚ Save   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—‚ Code Organization

### Design Patterns Used

1. **Factory Pattern**
   - `create_initial_state()` - Creates LearningState
   - `create_learning_graph()` - Creates LearningGraph
   - `get_llm()` - Creates LLM instances

2. **Builder Pattern**
   - `LearningGraph.build_graph()` - Builds StateGraph
   - `LearningReportGenerator` - Builds PDF report

3. **Strategy Pattern**
   - `search_tools.py` - Multiple search strategies (Tavily/DuckDuckGo/Google)
   - `llm_provider.py` - Multiple LLM providers (Google/OpenAI/Groq)

4. **State Pattern**
   - `LearningState` - Maintains workflow state
   - State transitions managed by LangGraph

5. **Singleton Pattern**
   - Database connection in `SessionDatabase`
   - Vector store manager instances

### Code Style & Conventions

1. **Naming Conventions:**
   - Classes: `PascalCase` (e.g., `ContextManager`)
   - Functions: `snake_case` (e.g., `gather_context()`)
   - Constants: `UPPER_SNAKE_CASE` (e.g., `MAX_RETRIES`)
   - Private methods: `_leading_underscore` (e.g., `_score_answer()`)

2. **Documentation:**
   - All classes have docstrings
   - All public methods have docstrings
   - Type hints on function signatures
   - Inline comments for complex logic

3. **Error Handling:**
   - Try-except blocks in all nodes
   - Error state in LearningState
   - Graceful degradation (fallback questions, default values)

---

## ğŸ“ Summary

This project is organized into clear, modular components:

- **Models** define data structures
- **Graph** orchestrates the workflow
- **Modules** implement business logic
- **Utils** provide supporting functions
- **Applications** (app.py/main.py) provide user interfaces

Each component has a single responsibility and clear interfaces, making the codebase maintainable and extensible.

---

**End of Project Structure Guide**
