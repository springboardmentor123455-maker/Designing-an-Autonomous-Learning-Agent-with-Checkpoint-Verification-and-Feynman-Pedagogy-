{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a01cfa1-cc36-47ea-a79c-3bf75a61d0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Hugging Face API Token:  ········\n",
      "Enter LangSmith API Key:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Configured Successfully.\n"
     ]
    }
   ],
   "source": [
    "#cell1\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "def get_mandatory_env(var_name, prompt):\n",
    "    val = os.environ.get(var_name)\n",
    "    if not val:\n",
    "        val = getpass.getpass(prompt)\n",
    "        os.environ[var_name] = val\n",
    "    if not val:\n",
    "        raise ValueError(f\"{var_name} is MANDATORY. Please provide it.\")\n",
    "    return val\n",
    "\n",
    "# 1. Hugging Face Token \n",
    "get_mandatory_env(\"HUGGINGFACEHUB_API_TOKEN\", \"Enter Hugging Face API Token: \")\n",
    "\n",
    "# 2. LangSmith Configuration \n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Llama-Tutor-Agent\"\n",
    "get_mandatory_env(\"LANGCHAIN_API_KEY\", \"Enter LangSmith API Key: \")\n",
    "\n",
    "print(\"Environment Configured Successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40352286-26fe-4ca8-be8b-375c7ffda9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Chittesh\\anaconda3\\envs\\Agent_Project\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Model Ready: Qwen/Qwen2.5-72B-Instruct (Long Context Enabled)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Model Configuration\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace, HuggingFaceEmbeddings\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# MODEL CONFIGURATION\n",
    "MODEL_REPO = \"Qwen/Qwen2.5-72B-Instruct\" \n",
    "\n",
    "# 1. Initialize Endpoint\n",
    "llm_engine = HuggingFaceEndpoint(\n",
    "    repo_id=MODEL_REPO,\n",
    "    task=\"text-generation\",\n",
    "    # UPDATED: Increased to support 1000 words\n",
    "    max_new_tokens=2048,\n",
    "    do_sample=True,\n",
    "    temperature=0.3, # Slightly higher for creativity in long essays\n",
    "    streaming=False, \n",
    ")\n",
    "\n",
    "llm = ChatHuggingFace(llm=llm_engine)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "web_search = DuckDuckGoSearchRun()\n",
    "\n",
    "# Checkpoints remain the same...\n",
    "CHECKPOINTS = {\n",
    "    1: {\"topic\": \"Transformer Architecture\", \"objective\": \"Explain the Encoder-Decoder structure and Self-Attention mechanism.\"},\n",
    "    2: {\"topic\": \"Backpropagation\", \"objective\": \"Detail the chain rule and how gradients update weights in a neural network.\"},\n",
    "    3: {\"topic\": \"RAG Systems\", \"objective\": \"Explain Retrieval-Augmented Generation, vector databases, and semantic search.\"},\n",
    "    4: {\"topic\": \"Generative Adversarial Networks\", \"objective\": \"Explain the Generator vs Discriminator dynamic and training challenges\"},\n",
    "    5: {\"topic\": \"Convolutional Neural Networks\", \"objective\": \"Explain Filters, Pooling layers, and their application in image recognition.\"}\n",
    "}\n",
    "\n",
    "print(f\"Model Ready: {MODEL_REPO} (Long Context Enabled)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af54023e-97fd-42a8-9198-4ea1335cb058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT A LEARNING CHECKPOINT\n",
      "1. Transformer Architecture\n",
      "2. Backpropagation\n",
      "3. RAG Systems\n",
      "4. Generative Adversarial Networks\n",
      "5. Convolutional Neural Networks\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter choice (1-5):  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected: Convolutional Neural Networks\n",
      "Auto-detected file: notes.pdf\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: User Interaction \n",
    "import os\n",
    "\n",
    "DEFAULT_FILE = \"notes.pdf\" \n",
    "\n",
    "# 1. Select Checkpoint\n",
    "print(\"SELECT A LEARNING CHECKPOINT\")\n",
    "if 'CHECKPOINTS' not in globals():\n",
    "    print(\"Error: CHECKPOINTS dict missing. Please Run Cell 3 first.\")\n",
    "else:\n",
    "    for key, val in CHECKPOINTS.items():\n",
    "        print(f\"{key}. {val['topic']}\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            choice_input = input(\"Enter choice (1-5): \")\n",
    "            choice = int(choice_input)\n",
    "            if choice in CHECKPOINTS:\n",
    "                selected_checkpoint = CHECKPOINTS[choice]\n",
    "                print(f\"Selected: {selected_checkpoint['topic']}\")\n",
    "                break\n",
    "            print(\"Invalid choice.\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a number.\")\n",
    "\n",
    "    # 2. Auto-Detect Document\n",
    "    if os.path.exists(DEFAULT_FILE):\n",
    "        print(f\"Auto-detected file: {DEFAULT_FILE}\")\n",
    "        pdf_path = DEFAULT_FILE\n",
    "    else:\n",
    "        # Fallback if file isn't there\n",
    "        user_input = input(f\"File '{DEFAULT_FILE}' not found. Enter filename manually: \")\n",
    "        pdf_path = user_input if user_input else None\n",
    "\n",
    "    if pdf_path and not os.path.exists(pdf_path):\n",
    "        print(f\"Warning: File '{pdf_path}' not found. Agent will rely on Web Search.\")\n",
    "        pdf_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9866e3d8-bc1c-4d8b-8df5-0eed78a38ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell4\n",
    "from typing import TypedDict, Optional\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    topic: str\n",
    "    objective: str\n",
    "    file_path: Optional[str]\n",
    "    \n",
    "    # Content Storage\n",
    "    doc_context: str\n",
    "    web_context: str\n",
    "    \n",
    "    # Flags & Counters\n",
    "    needs_web_search: bool\n",
    "    retries: int\n",
    "    \n",
    "    # Output & Scoring\n",
    "    final_essay: str\n",
    "    relevance_score: int\n",
    "    validation_reasoning: str\n",
    "    \n",
    "    # Best Effort Memory\n",
    "    best_essay: str\n",
    "    best_score: int\n",
    "\n",
    "    # Milestone 2\n",
    "    quiz_questions: str      \n",
    "    user_answers: str\n",
    "    quiz_score: int\n",
    "    quiz_feedback: str\n",
    "    attempt_count: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee199a09-72c4-444d-8fdd-7b1e9273de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Document Processing Node \n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "def check_user_doc(state: AgentState):\n",
    "    print(\"CHECKING USER DOCUMENT\")\n",
    "    file_path = state[\"file_path\"]\n",
    "    topic = state[\"topic\"]\n",
    "    \n",
    "    # 1. Basic Check\n",
    "    if not file_path:\n",
    "        return {\"doc_context\": \"\", \"needs_web_search\": True}\n",
    "    \n",
    "    try:\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        docs = loader.load()\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        splits = splitter.split_documents(docs)\n",
    "        \n",
    "        if not splits:\n",
    "            return {\"doc_context\": \"\", \"needs_web_search\": True}\n",
    "        \n",
    "        # 2. Vector Search\n",
    "        vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n",
    "        retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "        retrieved_docs = retriever.invoke(topic)\n",
    "        context_text = \"\\n\\n\".join([d.page_content for d in retrieved_docs])\n",
    "        \n",
    "        # 3. LLM GRADED CHECK\n",
    "        grader_prompt = f\"\"\"\n",
    "        You are a Relevance Grader. \n",
    "        Topic: {topic}\n",
    "        Retrieved Text: {context_text[:2000]}\n",
    "        \n",
    "        Does the retrieved text contain a DETAILED explanation of the Topic?\n",
    "        If it only contains headers, unrelated topics, or placeholders like \"This chapter is blank\", answer NO.\n",
    "        \n",
    "        Answer only YES or NO.\n",
    "        \"\"\"\n",
    "        response = llm.invoke([HumanMessage(content=grader_prompt)])\n",
    "        grade = response.content.strip().upper()\n",
    "        \n",
    "        if \"NO\" in grade or len(context_text) < 200:\n",
    "            print(f\"Doc content found ({len(context_text)} chars) but graded INCOMPLETE. Enabling Web Search.\")\n",
    "            return {\"doc_context\": context_text, \"needs_web_search\": True}\n",
    "        \n",
    "        print(f\"Found relevant content in user doc. (Grader: {grade})\")\n",
    "        return {\"doc_context\": context_text, \"needs_web_search\": False}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading doc: {e}\")\n",
    "        return {\"doc_context\": \"\", \"needs_web_search\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3764eaa-df44-407a-936d-8a8bc2410d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell 6\n",
    "def perform_web_search(state: AgentState):\n",
    "    print(\"PERFORMING WEB SEARCH\")\n",
    "    \n",
    "    if not state.get(\"needs_web_search\"):\n",
    "        print(\"Skipping web search (User Doc sufficient).\")\n",
    "        return {\"web_context\": \"\"}\n",
    "        \n",
    "    topic = state[\"topic\"]\n",
    "    objective = state[\"objective\"]\n",
    "    \n",
    "    query = f\"{topic} {objective} detailed technical explanation\"\n",
    "    try:\n",
    "        search_results = web_search.invoke(query)\n",
    "        print(\"Web search completed.\")\n",
    "        return {\"web_context\": search_results}\n",
    "    except Exception as e:\n",
    "        print(f\"Search failed: {e}\")\n",
    "        return {\"web_context\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df91fbc9-c920-41c9-93ec-5d98b14e9cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Generation Node (750-1000 Words, Zero Math Notation)\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "def generate_essay(state):\n",
    "    print(\"GENERATING COMPREHENSIVE GUIDE (750-1000 Words)...\")\n",
    "    \n",
    "    # 1. Extract State\n",
    "    doc_text = state.get(\"doc_context\", \"\")\n",
    "    web_text = state.get(\"web_context\", \"\")\n",
    "    topic = state.get(\"topic\", \"\")\n",
    "    objective = state.get(\"objective\", \"\")\n",
    "    \n",
    "    # 2. STRICT \"NO MATH\" PROMPT\n",
    "    system_instruction = \"\"\"You are an expert Technical Writer who specializes in explaining complex AI concepts to non-mathematicians.\n",
    "    \n",
    "    YOUR TASK: Write a comprehensive 750 to 1000 word guide on the User's Topic.\n",
    "    \n",
    "    CRITICAL RULE: NO MATHEMATICAL NOTATION ALLOWED.\n",
    "    1. STRICTLY FORBIDDEN: LaTeX, symbols (∑, ∂, α, σ), standalone variables (x, y, w, b), or formulas.\n",
    "    2. REQUIRED FORMAT: You must describe mathematical relationships using ONLY descriptive sentences.\n",
    "    \n",
    "    --- EXAMPLES OF HOW TO WRITE ---\n",
    "    BAD: \"y = wx + b\"\n",
    "    GOOD: \"The neuron calculates its output by multiplying the input signal by a specific weight, adding a bias value, and then passing the result through an activation function.\"\n",
    "    \n",
    "    BAD: \"L = (y - ŷ)²\"\n",
    "    GOOD: \"The error is calculated by taking the difference between the predicted value and the actual target, and then squaring that difference to ensure the result is always positive.\"\n",
    "    \n",
    "    BAD: \"∂L/∂w\"\n",
    "    GOOD: \"The gradient represents how much the error would change if we slightly adjusted the weight.\"\n",
    "    ---------------------------------\n",
    "    \n",
    "    ADDITIONAL INSTRUCTIONS:\n",
    "    - Length: 750 - 1000 words (Go deep into the logic and mechanism).\n",
    "    - Structure: Use clear Sections, Headers, and Bullet Points.\n",
    "    - Tone: Professional, clear, and purely narrative.\n",
    "    - Citations: DO NOT use citations.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_content = f\"\"\"\n",
    "    TOPIC: {topic}\n",
    "    OBJECTIVE: {objective}\n",
    "    \n",
    "    SOURCE MATERIAL:\n",
    "    {doc_text[:5000]} \n",
    "    {web_text[:5000]}\n",
    "    \n",
    "    Start writing the guide now. Remember: Narrative explanation only, no formulas.\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        SystemMessage(content=system_instruction),\n",
    "        HumanMessage(content=user_content)\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response_msg = llm.invoke(messages)\n",
    "        return {\"final_essay\": response_msg.content}\n",
    "    except Exception as e:\n",
    "        print(f\"\\n GENERATION ERROR: {e}\\n\")\n",
    "        return {\"final_essay\": f\"Error generating essay: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3df67eae-ee8a-4df1-bb34-d7892673136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Validation Node\n",
    "import re\n",
    "import json\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def validate_output(state: AgentState):\n",
    "    print(\"VALIDATING OUTPUT\")\n",
    "    essay = state[\"final_essay\"]\n",
    "    objective = state[\"objective\"]\n",
    "    current_retries = state.get(\"retries\", 0)\n",
    "    best_score = state.get(\"best_score\", 0)\n",
    "    best_essay = state.get(\"best_essay\", \"\")\n",
    "    \n",
    "    if \"Error generating essay\" in essay:\n",
    "        score = 1\n",
    "        reason = \"Generation Failed\"\n",
    "    else:\n",
    "        # UPDATED CHECKLIST\n",
    "        prompt = f\"\"\"\n",
    "        Grade the following summary on a scale of 1-5 using this EXACT checklist:\n",
    "        \n",
    "        +1 Point: Is it relevant to \"{objective}\"?\n",
    "        +1 Point: Is it clear and concise?\n",
    "        +1 Point: Is it easy to understand?\n",
    "        +1 Point: Is the content technically accurate?\n",
    "        +1 Point: Is the structure clear?\n",
    "        \n",
    "        Total Score = Sum of points. (Max 5).\n",
    "        \n",
    "        Return ONLY valid JSON: {{\"score\": int, \"reasoning\": \"string\"}}\n",
    "        \n",
    "        SUMMARY START:\n",
    "        {essay[:1500]}...\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = llm.invoke([HumanMessage(content=prompt)])\n",
    "            json_match = re.search(r\"\\{.*\\}\", response.content, re.DOTALL)\n",
    "            if json_match:\n",
    "                data = json.loads(json_match.group(0))\n",
    "                score = data.get(\"score\", 0)\n",
    "                reason = data.get(\"reasoning\", \"No reasoning\")\n",
    "            else:\n",
    "                score = 4 \n",
    "                reason = \"JSON Parse Error, but content generated.\"\n",
    "        except Exception as e:\n",
    "            print(f\"Validation failed: {e}\")\n",
    "            score = 3\n",
    "            reason = \"Validation Exception\"\n",
    "\n",
    "    print(f\"Attempt {current_retries + 1} Score: {score}/5 | Reason: {reason}\")\n",
    "\n",
    "    if score > best_score:\n",
    "        print(f\"New High Score! ({score})\")\n",
    "        best_score = score\n",
    "        best_essay = essay\n",
    "\n",
    "    return {\n",
    "        \"relevance_score\": score, \n",
    "        \"validation_reasoning\": reason,\n",
    "        \"retries\": current_retries + 1,\n",
    "        \"best_score\": best_score,\n",
    "        \"best_essay\": best_essay\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39bd2ae2-6ca6-4eeb-bb07-f9f826e6b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell 9\n",
    "import time\n",
    "\n",
    "def check_retry(state: AgentState):\n",
    "    score = state[\"relevance_score\"]\n",
    "    retries = state[\"retries\"]\n",
    "    \n",
    "    # Success\n",
    "    if score >= 4:\n",
    "        print(\"Score meets threshold. Finishing.\")\n",
    "        return \"success\"\n",
    "    \n",
    "    # Max Retries\n",
    "    if retries >= 5:\n",
    "        print(\"Max retries reached. Accepting best effort.\")\n",
    "        return \"max_retries\"\n",
    "    \n",
    "    # Retry with Delay\n",
    "    print(\"Score too low. Retrying in 2 seconds...\")\n",
    "    time.sleep(2)\n",
    "    return \"retry\"\n",
    "\n",
    "def finalize_submission(state: AgentState):\n",
    "    print(\"FINALIZING SUBMISSION\")\n",
    "    return {\n",
    "        \"final_essay\": state[\"best_essay\"], \n",
    "        \"relevance_score\": state[\"best_score\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "665d24f8-da12-41b7-ab2f-156a14db4922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robust Learning Graph Compiled.\n"
     ]
    }
   ],
   "source": [
    "#cell 10\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add Nodes\n",
    "workflow.add_node(\"check_user_doc\", check_user_doc)\n",
    "workflow.add_node(\"perform_web_search\", perform_web_search)\n",
    "workflow.add_node(\"generate_essay\", generate_essay)\n",
    "workflow.add_node(\"validate_output\", validate_output)\n",
    "workflow.add_node(\"finalize_submission\", finalize_submission)\n",
    "\n",
    "# Set Entry Point\n",
    "workflow.set_entry_point(\"check_user_doc\")\n",
    "\n",
    "# Standard Edges\n",
    "workflow.add_edge(\"check_user_doc\", \"perform_web_search\")\n",
    "workflow.add_edge(\"perform_web_search\", \"generate_essay\")\n",
    "workflow.add_edge(\"generate_essay\", \"validate_output\")\n",
    "\n",
    "# Conditional Edges\n",
    "workflow.add_conditional_edges(\n",
    "    \"validate_output\",\n",
    "    check_retry,\n",
    "    {\n",
    "        \"success\": \"finalize_submission\",\n",
    "        \"max_retries\": \"finalize_submission\",\n",
    "        \"retry\": \"generate_essay\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"finalize_submission\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "print(\"Robust Learning Graph Compiled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dce8bbeb-95d0-4e3e-9a5f-22b32a5a1df6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Robust Agent for: Convolutional Neural Networks\n",
      "CHECKING USER DOCUMENT\n",
      "Doc content found (3851 chars) but graded INCOMPLETE. Enabling Web Search.\n",
      "PERFORMING WEB SEARCH\n",
      "Web search completed.\n",
      "GENERATING COMPREHENSIVE GUIDE (750-1000 Words)...\n",
      "VALIDATING OUTPUT\n",
      "Attempt 1 Score: 4/5 | Reason: The summary is relevant to explaining filters and their application in image recognition, and it provides a clear and concise explanation of how filters work. It is also easy to understand and technically accurate. However, the summary does not cover pooling layers, which are an important component of CNNs, so it loses one point for completeness.\n",
      "New High Score! (4)\n",
      "Score meets threshold. Finishing.\n",
      "FINALIZING SUBMISSION\n",
      "FINAL OUTPUT (Score: 4/5)\n",
      "# Comprehensive Guide to Convolutional Neural Networks (CNNs)\n",
      "\n",
      "Convolutional Neural Networks (CNNs) are a specialized type of deep learning model designed to process and analyze visual data, such as images and videos. They excel at recognizing patterns and features in grid-like data structures, making them highly effective for tasks like image classification, object detection, and image segmentation. This guide will delve into the core components of CNNs, focusing on filters, pooling layers, and their application in image recognition.\n",
      "\n",
      "## Understanding Filters\n",
      "\n",
      "### What Are Filters?\n",
      "\n",
      "Filters, also known as kernels or feature detectors, are small matrices that slide over the input image to detect specific features. Each filter is designed to identify a particular pattern, such as edges, lines, or textures. By applying multiple filters, a CNN can capture a wide range of features from the input image.\n",
      "\n",
      "### How Filters Work\n",
      "\n",
      "1. **Sliding Window**: The filter moves across the image in small steps, often referred to as strides. At each position, the filter performs a dot product with the corresponding region of the image.\n",
      "2. **Dot Product**: The dot product is a way of combining the values of the filter and the image region. It involves multiplying each element of the filter with the corresponding element of the image region and summing the results.\n",
      "3. **Feature Map**: The result of applying a filter to the entire image is a feature map, which highlights the presence of the specific feature the filter is designed to detect.\n",
      "\n",
      "### Example: Edge Detection\n",
      "\n",
      "Imagine a filter designed to detect vertical edges. As it slides over the image, it will produce high values in the feature map wherever there are strong vertical edges. This helps the network focus on the most relevant parts of the image for the task at hand.\n",
      "\n",
      "## Pooling Layers\n",
      "\n",
      "### What Are Pooling Layers?\n",
      "\n",
      "Pooling layers are used to reduce the spatial dimensions of the feature maps, making the network more computationally efficient and less prone to overfitting. They achieve this by summarizing the features in a local neighborhood.\n",
      "\n",
      "### Types of Pooling\n",
      "\n",
      "1. **Max Pooling**: This is the most common type of pooling. It selects the maximum value from a small region of the feature map. For example, if the region is a 2x2 grid, max pooling will choose the highest value from those four cells.\n",
      "2. **Average Pooling**: This type of pooling calculates the average value from the region. It tends to smooth out the feature map and can be useful in certain scenarios.\n",
      "\n",
      "### Benefits of Pooling\n",
      "\n",
      "- **Dimensionality Reduction**: By reducing the size of the feature maps, pooling layers decrease the number of parameters in the network, making it faster and more efficient.\n",
      "- **Translation Invariance**: Pooling helps the network become invariant to small translations of the input. This means that the network can recognize a feature regardless of its exact position in the image.\n",
      "\n",
      "## Application in Image Recognition\n",
      "\n",
      "### Step-by-Step Process\n",
      "\n",
      "1. **Input Layer**: The image is fed into the network as a grid of pixel values.\n",
      "2. **Convolutional Layers**: Multiple filters are applied to the image to create feature maps. Each filter detects a different feature, such as edges, corners, or textures.\n",
      "3. **Activation Function**: After each convolution, an activation function (like ReLU) is applied to introduce non-linearity. This helps the network learn more complex patterns.\n",
      "4. **Pooling Layers**: Pooling layers reduce the spatial dimensions of the feature maps, making the network more efficient and robust.\n",
      "5. **Fully Connected Layers**: The output from the convolutional and pooling layers is flattened and passed through fully connected layers. These layers perform the final classification by combining the learned features.\n",
      "6. **Output Layer**: The final layer produces the predicted class probabilities, which are used to determine the most likely class of the input image.\n",
      "\n",
      "### Example: Image Classification\n",
      "\n",
      "Consider a CNN trained to classify images of cats and dogs. The network might start by detecting simple features like edges and lines in the early layers. As the data progresses through deeper layers, the network learns to recognize more complex features, such as fur patterns and facial structures. The final fully connected layers combine these features to make a decision about whether the image shows a cat or a dog.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Convolutional Neural Networks are powerful tools for image recognition and other visual data processing tasks. By using filters to detect specific features and pooling layers to reduce dimensionality, CNNs can efficiently learn and generalize from large datasets. Understanding the mechanics of filters and pooling layers is crucial for designing and optimizing CNNs for various applications.\n",
      "\n",
      "In summary, filters help the network identify important features in the input image, while pooling layers ensure that the network remains computationally efficient and robust. Together, these components enable CNNs to achieve state-of-the-art performance in image recognition and related tasks.\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Execute Agent\n",
    "inputs = {\n",
    "    \"topic\": selected_checkpoint[\"topic\"],\n",
    "    \"objective\": selected_checkpoint[\"objective\"],\n",
    "    \"file_path\": pdf_path,\n",
    "    \"needs_web_search\": False, \n",
    "    \"doc_context\": \"\",\n",
    "    \"web_context\": \"\",\n",
    "    # Initialize counters\n",
    "    \"retries\": 0,\n",
    "    \"best_score\": 0,\n",
    "    \"best_essay\": \"\"\n",
    "}\n",
    "\n",
    "print(f\"Starting Robust Agent for: {inputs['topic']}\")\n",
    "\n",
    "# Run the agent ONLY ONCE\n",
    "result = app.invoke(inputs)\n",
    "\n",
    "print(f\"FINAL OUTPUT (Score: {result['relevance_score']}/5)\")\n",
    "print(result[\"final_essay\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0813c322-c93c-4073-b076-1a18d092308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Context Processing Node \n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "def process_context(state: AgentState):\n",
    "    print(\"PROCESSING CONTEXT\")\n",
    "    \n",
    "    # 1. PRIORITY: USE GENERATED CONTENT\n",
    "    # If the model has already written an essay, use THAT as the source.\n",
    "    if state.get(\"final_essay\") and len(state[\"final_essay\"]) > 100:\n",
    "        print(\"Using GENERATED ESSAY as the source for questions.\")\n",
    "        # We return the essay as 'doc_context' so the next node sees it as the source material.\n",
    "        return {\n",
    "            \"doc_context\": state[\"final_essay\"], \n",
    "            \"needs_web_search\": False\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79b7648e-9542-48ee-b67d-dbbe19a1a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Question Generation Node \n",
    "import re\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def generate_questions(state):\n",
    "    print(\"GENERATING QUIZ QUESTIONS (1-3)\")\n",
    "    \n",
    "    topic = state[\"topic\"]\n",
    "    lesson_text = state.get(\"final_essay\", \"\")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are an Examiner. Generate exactly 3 conceptual questions based on the text below.\n",
    "    \n",
    "    RULES:\n",
    "    1. Output a numbered list (1., 2., 3.).\n",
    "    2. No math, no formulas.\n",
    "    3. No answers or intro text.\n",
    "    \n",
    "    TEXT:\n",
    "    {lesson_text[:5000]}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "        \n",
    "        # Concise Parsing: Extract lines starting with a digit and dot\n",
    "        questions = [\n",
    "            re.sub(r'^\\d+\\.\\s*', '', line.strip()) \n",
    "            for line in response.content.split('\\n') \n",
    "            if re.match(r'^\\d+\\.', line.strip())\n",
    "        ]\n",
    "        \n",
    "        # Minimal Safety: Ensure exactly 3 questions exist\n",
    "        while len(questions) < 3:\n",
    "            questions.append(f\"Explain the core concept of {topic}.\")\n",
    "            \n",
    "        return {\"quiz_questions\": questions[:3]} # Fixed slice to match 3 questions\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating questions: {e}\")\n",
    "        return {\"quiz_questions\": [f\"Explain {topic}\"] * 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6708c2e-f0a3-4387-8639-9442abc37a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Grading Node\n",
    "import json\n",
    "import re\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def grade_answers(state):\n",
    "    print(\"GRADING ANSWERS\")\n",
    "    \n",
    "    topic = state[\"topic\"]\n",
    "    # Fallback to empty string if essay is missing\n",
    "    lesson_text = state.get(\"final_essay\", \"\")\n",
    "    questions = state[\"quiz_questions\"]\n",
    "    answers = state[\"user_answers\"]\n",
    "    \n",
    "    # Format Q&A for the LLM\n",
    "    qa_pairs = \"\"\n",
    "    for i in range(len(questions)):\n",
    "        # Handle cases where user might have skipped an answer\n",
    "        ans = answers[i] if i < len(answers) else \"No Answer\"\n",
    "        qa_pairs += f\"Q{i+1}: {questions[i]}\\nStudent Answer: {ans}\\n\\n\"\n",
    "        \n",
    "    prompt = f\"\"\"\n",
    "    You are an Academic Examiner. Grade the student's submission.\n",
    "    \n",
    "    TOPIC: {topic}\n",
    "    REFERENCE LESSON: {lesson_text[:5000]}\n",
    "    STUDENT SUBMISSION: {qa_pairs}\n",
    "    \n",
    "    GRADING RUBRIC:\n",
    "    1. Focus solely on CONCEPTUAL UNDERSTANDING.\n",
    "    2. Do not penalize for lack of mathematical precision since this is a theory exam.\n",
    "    3. In your feedback, DO NOT use equations. Explain corrections using plain English.\n",
    "    4. if there is no answer for that question or completely irrelevent answer is given, award zero marks for that answer.\n",
    "    \n",
    "    TASK:\n",
    "    1. Grade EACH answer out of 20 marks. (Total 60).\n",
    "    2. Provide a specific reason for the score in plain text.\n",
    "    \n",
    "    RETURN JSON FORMAT ONLY:\n",
    "    {{\n",
    "        \"detailed_reviews\": [\n",
    "            {{\n",
    "                \"question\": \"text\",\n",
    "                \"marks_awarded\": <int>,\n",
    "                \"reason\": \"explanation\"\n",
    "            }},\n",
    "            ...\n",
    "        ]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "        \n",
    "        # Parse JSON output\n",
    "        json_match = re.search(r\"\\{.*\\}\", response.content, re.DOTALL)\n",
    "        if json_match:\n",
    "            data = json.loads(json_match.group(0))\n",
    "            \n",
    "            # Calculate Total Score\n",
    "            total = sum([item['marks_awarded'] for item in data['detailed_reviews']])\n",
    "            feedback = \"Passed!\" if total >= 40 else \"Needs Improvement.\"\n",
    "            \n",
    "            # Return a FLAT dictionary with 'quiz_score' at the top level\n",
    "            return {\n",
    "                \"quiz_score\": total,\n",
    "                \"feedback\": feedback,\n",
    "                \"detailed_reviews\": data['detailed_reviews']\n",
    "            }\n",
    "        else:\n",
    "            print(\"Error: Could not parse JSON from grader response.\")\n",
    "            return {\"quiz_score\": 0, \"feedback\": \"Error parsing grades.\", \"detailed_reviews\": []}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during grading: {e}\")\n",
    "        return {\"quiz_score\": 0, \"feedback\": f\"Error: {str(e)}\", \"detailed_reviews\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3d8ed8e-800b-41b1-993b-d6fca92089c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15\n",
    "def check_pass_fail(state: AgentState):\n",
    "    score = state[\"quiz_score\"]\n",
    "    \n",
    "    if score >= 40:\n",
    "        print(\"PASSED (>40). Evaluation Successful.\")\n",
    "        return \"pass\"\n",
    "    else:\n",
    "        print(\"FAILED (<40). Routing to Remedial Node.\")\n",
    "        return \"fail\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc9ce5e0-2a32-44bd-ae06-f8e39824ae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Feynman Placeholder Node\n",
    "def feynman_placeholder(state: AgentState):\n",
    "    print(\"STOP: LEARNING HALTED\")\n",
    "    print(f\"Reason: Quiz Score ({state['quiz_score']}%) is below 80%.\")\n",
    "    print(\"Action: Triggering Feynman Technique (Placeholder).\")\n",
    "    \n",
    "    return {\"quiz_feedback\": \"HALTED: Remediation required.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51040768-2edf-44b6-9dfe-3cb6c54f571c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Re-Compiled for Interactive Mode.\n"
     ]
    }
   ],
   "source": [
    "# Cell 17: Re-Compile Graph\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "workflow_v2 = StateGraph(AgentState)\n",
    "\n",
    "# Add Nodes (We only need these three for the setup)\n",
    "workflow_v2.add_node(\"process_context\", process_context)\n",
    "workflow_v2.add_node(\"perform_web_search\", perform_web_search)\n",
    "workflow_v2.add_node(\"generate_questions\", generate_questions)\n",
    "\n",
    "# Set Entry Point\n",
    "workflow_v2.set_entry_point(\"process_context\")\n",
    "\n",
    "# Define Logic\n",
    "def check_search_requirement(state):\n",
    "    return \"perform_web_search\" if state.get(\"needs_web_search\") else \"generate_questions\"\n",
    "\n",
    "workflow_v2.add_conditional_edges(\n",
    "    \"process_context\",\n",
    "    check_search_requirement,\n",
    "    {\n",
    "        \"perform_web_search\": \"perform_web_search\",\n",
    "        \"generate_questions\": \"generate_questions\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow_v2.add_edge(\"perform_web_search\", \"generate_questions\")\n",
    "# CRITICAL CHANGE: Stop the graph here. Do not simulate answers.\n",
    "workflow_v2.add_edge(\"generate_questions\", END)\n",
    "\n",
    "app_v2 = workflow_v2.compile()\n",
    "print(\"Graph Re-Compiled for Interactive Mode.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c84edb1-7647-45d5-94d9-c82ce12a959f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATING QUIZ FOR: Convolutional Neural Networks...\n",
      "PROCESSING CONTEXT\n",
      "Using GENERATED ESSAY as the source for questions.\n",
      "GENERATING QUIZ QUESTIONS (1-3)\n",
      "QUIZ: CONVOLUTIONAL NEURAL NETWORKS\n",
      "\n",
      "Question 1: How do filters in a CNN contribute to the detection of specific features in an image?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Answer 1:  *Sliding Window**: The filter moves across the image in small steps, often referred to as strides. At each position, the filter performs a dot product with the corresponding region of the image. 2. **Dot Product**: The dot product is a way of combining the values of the filter and the image region. It involves multiplying each element of the filter with the corresponding element of the image region and summing the results. 3. **Feature Map**: The result of applying a filter to the entire image is a feature map, which highlights the presence of the specific feature the filter is designed to detect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 2: What is the primary benefit of using pooling layers in a CNN, and how do they achieve this?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Answer 2:  Pooling layers are used to reduce the spatial dimensions of the feature maps, making the network more computationally efficient and less prone to overfitting. They achieve this by summarizing the features in a local neighborhood.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 3: Explain the role of activation functions in the convolutional layers of a CNN and why they are necessary.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Answer 3:  *Activation Function**: After each convolution, an activation function (like ReLU) is applied to introduce non-linearity. This helps the network learn more complex patterns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting to Examiner...\n",
      "GRADING ANSWERS\n",
      "DETAILED FEEDBACK\n",
      "\n",
      "Q1: How do filters in a CNN contribute to the detection of specific features in an image?\n",
      "Your Answer: *Sliding Window**: The filter moves across the image in small steps, often referred to as strides. At each position, the filter performs a dot product with the corresponding region of the image. 2. **Dot Product**: The dot product is a way of combining the values of the filter and the image region. It involves multiplying each element of the filter with the corresponding element of the image region and summing the results. 3. **Feature Map**: The result of applying a filter to the entire image is a feature map, which highlights the presence of the specific feature the filter is designed to detect.\n",
      "Score: 18/20\n",
      "Feedback: The answer correctly explains the sliding window mechanism, the dot product operation, and the generation of feature maps. However, it could have provided a bit more context on what specific features filters can detect, such as edges, lines, or textures.\n",
      "\n",
      "Q2: What is the primary benefit of using pooling layers in a CNN, and how do they achieve this?\n",
      "Your Answer: Pooling layers are used to reduce the spatial dimensions of the feature maps, making the network more computationally efficient and less prone to overfitting. They achieve this by summarizing the features in a local neighborhood.\n",
      "Score: 19/20\n",
      "Feedback: The answer accurately describes the primary benefit of pooling layers, which is reducing the spatial dimensions of feature maps to make the network more computationally efficient and less prone to overfitting. It also correctly explains how pooling layers achieve this by summarizing features in a local neighborhood.\n",
      "\n",
      "Q3: Explain the role of activation functions in the convolutional layers of a CNN and why they are necessary.\n",
      "Your Answer: *Activation Function**: After each convolution, an activation function (like ReLU) is applied to introduce non-linearity. This helps the network learn more complex patterns.\n",
      "Score: 17/20\n",
      "Feedback: The answer correctly states that activation functions introduce non-linearity, which helps the network learn more complex patterns. However, it could have provided a bit more detail on why non-linearity is essential, such as enabling the network to model more complex relationships between inputs and outputs.\n",
      "\n",
      "FINAL SCORE: 54/60\n",
      "STATUS: PASSED\n"
     ]
    }
   ],
   "source": [
    "# Cell 18: Execute Agent & Start Interactive Quiz\n",
    "\n",
    "# 1. AUTO-DETECT TOPIC\n",
    "if 'selected_checkpoint' in globals():\n",
    "    current_topic = selected_checkpoint['topic']\n",
    "    current_objective = selected_checkpoint['objective']\n",
    "else:\n",
    "    current_topic = \"RAG Systems\"\n",
    "    current_objective = \"Explain Retrieval Augmented Generation\"\n",
    "\n",
    "previous_essay = result['final_essay'] if 'result' in globals() and 'final_essay' in result else \"\"\n",
    "\n",
    "# 2. PREPARE INPUTS\n",
    "inputs = {\n",
    "    \"topic\": current_topic,\n",
    "    \"objective\": current_objective,\n",
    "    \"file_path\": \"notes.pdf\",\n",
    "    \"final_essay\": previous_essay,\n",
    "    \"doc_context\": \"\", \n",
    "    \"web_context\": \"\", \n",
    "    \"quiz_questions\": [], \n",
    "    \"user_answers\": [],\n",
    "    \"quiz_score\": 0 \n",
    "}\n",
    "\n",
    "print(f\"GENERATING QUIZ FOR: {inputs['topic']}...\")\n",
    "\n",
    "# 3. RUN GRAPH (Generate Questions)\n",
    "result_v2 = app_v2.invoke(inputs)\n",
    "questions = result_v2['quiz_questions']\n",
    "\n",
    "# 4. INTERACTIVE QUIZ LOOP\n",
    "print(f\"QUIZ: {current_topic.upper()}\")\n",
    "\n",
    "user_answers = []\n",
    "\n",
    "if isinstance(questions, list) and len(questions) > 0:\n",
    "    for i, q in enumerate(questions, 1):\n",
    "        print(f\"\\nQuestion {i}: {q}\")\n",
    "        # Separate input box for each question\n",
    "        ans = input(f\"Answer {i}: \")\n",
    "        user_answers.append(ans)\n",
    "else:\n",
    "    print(\"Error: No questions were generated.\")\n",
    "    user_answers = [\"No Answer\"] * 3\n",
    "\n",
    "# 5. GRADE MANUALLY\n",
    "print(\"Submitting to Examiner...\")\n",
    "\n",
    "grading_state = {\n",
    "    \"topic\": result_v2[\"topic\"],\n",
    "    \"final_essay\": result_v2.get(\"final_essay\", previous_essay), \n",
    "    \"quiz_questions\": result_v2[\"quiz_questions\"],\n",
    "    \"user_answers\": user_answers  # Direct list mapping\n",
    "}\n",
    "\n",
    "final_grade = grade_answers(grading_state)\n",
    "\n",
    "# 6. SHOW DETAILED RESULTS\n",
    "print(\"DETAILED FEEDBACK\")\n",
    "\n",
    "reviews = final_grade.get('detailed_reviews', [])\n",
    "for i, review in enumerate(reviews, 1):\n",
    "    q_text = review.get('question', f'Question {i}')\n",
    "    score = review.get('marks_awarded', 0)\n",
    "    reason = review.get('reason', 'No feedback provided.')\n",
    "    \n",
    "    # Retrieve the specific answer the user typed for this question\n",
    "    user_ans = user_answers[i-1] if i-1 < len(user_answers) else \"N/A\"\n",
    "    \n",
    "    print(f\"\\nQ{i}: {q_text}\")\n",
    "    print(f\"Your Answer: {user_ans}\")\n",
    "    print(f\"Score: {score}/20\")\n",
    "    print(f\"Feedback: {reason}\")\n",
    "\n",
    "total_score = final_grade.get('quiz_score', 0)\n",
    "print(f\"\\nFINAL SCORE: {total_score}/60\")\n",
    "\n",
    "if total_score >= 40:\n",
    "    print(\"STATUS: PASSED\")\n",
    "else:\n",
    "    print(\"STATUS: FAILED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab6a157-9b77-46f8-89d7-f5fab39d9a17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
