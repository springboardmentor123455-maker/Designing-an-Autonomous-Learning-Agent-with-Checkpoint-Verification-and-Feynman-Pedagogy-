{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1pCkQHA6q36",
        "outputId": "abaf602e-d87f-4bec-ed56-664efb92ddaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBxBsUtv6t88",
        "outputId": "dc0a7bb3-70c0-4538-b7b5-b3dc5426971d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"YOUR TOKEN\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY6ozt2-80x_",
        "outputId": "81c8a824-6cf0-4909-b9c0-c8b53e344338"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-1.1.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting tavily-python\n",
            "  Downloading tavily_python-0.7.17-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.5)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting reportlab\n",
            "  Downloading reportlab-4.4.7-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.12/dist-packages (0.4.59)\n",
            "Collecting groq<1.0.0,>=0.30.0 (from langchain-groq)\n",
            "  Downloading groq-0.37.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-groq) (1.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from tavily-python) (2.32.4)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tavily-python) (0.12.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from tavily-python) (0.28.1)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.12.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from reportlab) (11.3.0)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from reportlab) (3.4.4)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith) (3.11.5)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langsmith) (25.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.12.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx->tavily-python) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->tavily-python) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx->tavily-python) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-groq) (1.33)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-groq) (9.1.2)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python) (2.5.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.5.1->tavily-python) (2025.11.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Downloading langchain_groq-1.1.1-py3-none-any.whl (19 kB)\n",
            "Downloading tavily_python-0.7.17-py3-none-any.whl (18 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading reportlab-4.4.7-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-0.37.1-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: reportlab, PyPDF2, tavily-python, groq, langchain-groq\n",
            "Successfully installed PyPDF2-3.0.1 groq-0.37.1 langchain-groq-1.1.1 reportlab-4.4.7 tavily-python-0.7.17\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-groq tavily-python langgraph PyPDF2 reportlab sentence-transformers langsmith\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcwT_uQERTqq",
        "outputId": "db4a90c8-7157-4669-e487-53af6e34ba6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting backend.py\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "%%writefile backend.py\n",
        "\n",
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"YOUR TOKEN\"\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"YOUR TOKEN\"\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = \"YOUR TOKEN\"\n",
        "import os, re, json, datetime, html, time, hashlib\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional, TypedDict\n",
        "from pathlib import Path\n",
        "import importlib\n",
        "\n",
        "from functools import lru_cache\n",
        "from langgraph.graph import StateGraph, END\n",
        "from IPython.display import Markdown, display\n",
        "os.environ['EMBEDDING_DEBUG'] = '0'\n",
        "\n",
        "# Global buffer for ALL raw LLM logs\n",
        "\n",
        "GLOBAL_RAW_LOG: List[str] = []\n",
        "\n",
        "#  LangSmith tracing\n",
        "\n",
        "try:\n",
        "    from langsmith import traceable\n",
        "except ImportError:\n",
        "    # No-op decorator if langsmith not installed\n",
        "    def traceable(*targs, **tkwargs):\n",
        "        def decorator(fn):\n",
        "            return fn\n",
        "        return decorator\n",
        "\n",
        "# API Keys (Groq + Tavily)\n",
        "\n",
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\", \"\").strip()\n",
        "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\", \"\").strip()\n",
        "\n",
        "if not GROQ_API_KEY or not TAVILY_API_KEY:\n",
        "    raise SystemExit(\n",
        "        \"ERROR: GROQ_API_KEY and TAVILY_API_KEY must be set in environment.\\n\"\n",
        "        \"In Colab, run:\\n\"\n",
        "        \"import os\\n\"\n",
        "        \"os.environ['GROQ_API_KEY'] = 'your_groq_key'\\n\"\n",
        "        \"os.environ['TAVILY_API_KEY'] = 'your_tavily_key'\"\n",
        "    )\n",
        "\n",
        "\n",
        "# External clients & PDF lib (reading)\n",
        "\n",
        "try:\n",
        "    from tavily import TavilyClient\n",
        "except Exception:\n",
        "    raise RuntimeError(\"Missing tavily library. Install with: pip install tavily-python\")\n",
        "\n",
        "# PDF lib for reading user PDFs\n",
        "_pdf_lib = None\n",
        "if importlib.util.find_spec(\"PyPDF2\"):\n",
        "    import PyPDF2 as _pdf_lib\n",
        "else:\n",
        "    _pdf_lib = None  # PDF ingestion will error if not installed\n",
        "\n",
        "tavily_client = TavilyClient(api_key=TAVILY_API_KEY)\n",
        "\n",
        "\n",
        "# PDF writer for saving raw LLM outputs\n",
        "\n",
        "try:\n",
        "    from reportlab.pdfgen import canvas\n",
        "    from reportlab.lib.pagesizes import letter\n",
        "    _pdf_writer_available = True\n",
        "except ImportError:\n",
        "    _pdf_writer_available = False\n",
        "\n",
        "\n",
        "def save_raw_to_pdf(text: str, filename: str):\n",
        "    if not _pdf_writer_available:\n",
        "        print(\"[PDF] reportlab not installed; skipping PDF save.\")\n",
        "        return\n",
        "    try:\n",
        "        c = canvas.Canvas(filename, pagesize=letter)\n",
        "        width, height = letter\n",
        "        x_margin = 40\n",
        "        y = height - 50\n",
        "        max_width_chars = 110\n",
        "        for line in text.split(\"\\n\"):\n",
        "            while len(line) > max_width_chars:\n",
        "                chunk = line[:max_width_chars]\n",
        "                line = line[max_width_chars:]\n",
        "                if y < 40:\n",
        "                    c.showPage()\n",
        "                    y = height - 50\n",
        "                c.drawString(x_margin, y, chunk)\n",
        "                y -= 15\n",
        "            if y < 40:\n",
        "                c.showPage()\n",
        "                y = height - 50\n",
        "            c.drawString(x_margin, y, line)\n",
        "            y -= 15\n",
        "        c.save()\n",
        "        print(f\"[PDF Saved] {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[PDF ERROR] Failed to save PDF '{filename}': {e}\")\n",
        "\n",
        "\n",
        "def save_all_raw_to_one_pdf(filename: str = \"all_llm_raw_output.pdf\"):\n",
        "    if not GLOBAL_RAW_LOG:\n",
        "        print(\"[PDF] No raw LLM data to save.\")\n",
        "        return\n",
        "    full_text = \"\\n\".join(GLOBAL_RAW_LOG)\n",
        "    save_raw_to_pdf(full_text, filename)\n",
        "\n",
        "\n",
        "\n",
        "# Groq LLM via LangChain\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "GROQ_MODEL = os.getenv(\"GROQ_MODEL\", \"llama-3.1-8b-instant\")\n",
        "_LLM_CACHE_PATH = Path(\"/tmp/groq_inference_cache.json\")\n",
        "try:\n",
        "    _LLM_CACHE = json.load(open(_LLM_CACHE_PATH)) if _LLM_CACHE_PATH.exists() else {}\n",
        "except Exception:\n",
        "    _LLM_CACHE = {}\n",
        "\n",
        "\n",
        "def _save_llm_cache():\n",
        "    try:\n",
        "        json.dump(_LLM_CACHE, open(_LLM_CACHE_PATH, \"w\"), indent=2, ensure_ascii=False)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "\n",
        "def _prompt_key(prompt: str) -> str:\n",
        "    return hashlib.sha256(prompt.encode(\"utf-8\")).hexdigest()\n",
        "\n",
        "\n",
        "groq_llm = ChatGroq(\n",
        "    model=GROQ_MODEL,\n",
        "    temperature=0.3,\n",
        "    max_tokens=800,\n",
        "    groq_api_key=GROQ_API_KEY,\n",
        ")\n",
        "\n",
        "\n",
        "@traceable(name=\"groq_llm_call\")\n",
        "def groq_chat(\n",
        "    prompt: str,\n",
        "    *,\n",
        "    use_cache: bool = True,\n",
        "    max_retries: int = 3,\n",
        "    max_new_tokens: int = 800,\n",
        "    timeout: int = 60,\n",
        ") -> str:\n",
        "\n",
        "    key = _prompt_key(prompt)\n",
        "\n",
        "    # ‚úÖ Optional cache usage\n",
        "    if use_cache and key in _LLM_CACHE:\n",
        "        txt = _LLM_CACHE[key]\n",
        "        GLOBAL_RAW_LOG.append(\n",
        "            f\"\\n\\n=== CACHED LLM CALL ===\\n\"\n",
        "            f\"Timestamp: {datetime.datetime.now(datetime.timezone.utc).isoformat()}\\n\"\n",
        "            f\"Prompt:\\n{prompt}\\n\\nResponse:\\n{txt}\\n\"\n",
        "        )\n",
        "        return txt\n",
        "\n",
        "    # ---- real LLM call ----\n",
        "    try:\n",
        "        resp = groq_llm.invoke(prompt)\n",
        "    except Exception as e:\n",
        "        print(f\"Groq LLM error: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "    if hasattr(resp, \"content\"):\n",
        "        if isinstance(resp.content, str):\n",
        "            txt = resp.content\n",
        "        elif isinstance(resp.content, list):\n",
        "            txt = \"\".join(str(p) for p in resp.content)\n",
        "        else:\n",
        "            txt = str(resp.content)\n",
        "    else:\n",
        "        txt = str(resp)\n",
        "\n",
        "    txt = (txt or \"\").strip()\n",
        "\n",
        "    # ‚úÖ Save only if cache is enabled\n",
        "    if use_cache:\n",
        "        _LLM_CACHE[key] = txt\n",
        "        _save_llm_cache()\n",
        "\n",
        "    GLOBAL_RAW_LOG.append(\n",
        "        f\"\\n\\n=== RAW LLM CALL ===\\n\"\n",
        "        f\"Timestamp: {datetime.datetime.now(datetime.timezone.utc).isoformat()}\\n\"\n",
        "        f\"Prompt:\\n{prompt}\\n\\nResponse:\\n{txt}\\n\"\n",
        "    )\n",
        "\n",
        "    return txt\n",
        "\n",
        "@lru_cache(maxsize=4096)\n",
        "def cached_grade(prompt: str) -> int:\n",
        "    raw = groq_chat(prompt)\n",
        "    try:\n",
        "        return int(json.loads(re.search(r\"\\{.*\\}\", raw).group())[\"score\"])\n",
        "    except Exception:\n",
        "        return 0\n",
        "\n",
        "\n",
        "\n",
        "# Checkpoint structure\n",
        "\n",
        "@dataclass\n",
        "class Checkpoint:\n",
        "    id: str\n",
        "    topic: str\n",
        "    objectives: List[str]\n",
        "    success_criteria: str\n",
        "\n",
        "CHECKPOINTS = [\n",
        "\n",
        "    # ==================================================\n",
        "    # CP1 ‚Äî Neural Network Basics\n",
        "    # ==================================================\n",
        "    Checkpoint(\n",
        "        id=\"cp1\",\n",
        "        topic=\"Basics of Neural Networks\",\n",
        "        objectives=[\n",
        "            \"Explain how an artificial neuron combines inputs using weights and a bias\",\n",
        "            \"Describe the roles of input layers hidden layers and output layers\",\n",
        "            \"Explain how data moves forward through a neural network during prediction\",\n",
        "        ],\n",
        "        success_criteria=(\n",
        "            \"Learner can verbally explain how a simple feedforward neural network \"\n",
        "            \"processes inputs to produce an output.\"\n",
        "        ),\n",
        "    ),\n",
        "\n",
        "    # ==================================================\n",
        "    # CP2 ‚Äî Loss Functions\n",
        "    # ==================================================\n",
        "    Checkpoint(\n",
        "        id=\"cp2\",\n",
        "        topic=\"Loss Functions\",\n",
        "        objectives=[\n",
        "            \"Explain why a loss function is needed to measure prediction error\",\n",
        "            \"Describe the difference between low loss and high loss\",\n",
        "            \"Identify a suitable loss function for a simple regression or classification task\",\n",
        "        ],\n",
        "        success_criteria=(\n",
        "            \"Learner can explain how loss functions quantify model error \"\n",
        "            \"and why minimizing loss is important.\"\n",
        "        ),\n",
        "    ),\n",
        "\n",
        "    # ==================================================\n",
        "    # CP3 ‚Äî Gradient Descent\n",
        "    # ==================================================\n",
        "    Checkpoint(\n",
        "        id=\"cp3\",\n",
        "        topic=\"Gradient Descent\",\n",
        "        objectives=[\n",
        "            \"Explain why minimizing a loss function improves model performance\",\n",
        "            \"Describe the gradient as the direction and size of the steepest loss change\",\n",
        "            \"Explain how weights are updated step by step using the gradient\",\n",
        "        ],\n",
        "        success_criteria=(\n",
        "            \"Learner can explain how gradient descent reduces error \"\n",
        "            \"through repeated weight updates.\"\n",
        "        ),\n",
        "    ),\n",
        "\n",
        "    # ==================================================\n",
        "    # CP4 ‚Äî Learning Rate\n",
        "    # ==================================================\n",
        "    Checkpoint(\n",
        "        id=\"cp4\",\n",
        "        topic=\"Learning Rate\",\n",
        "        objectives=[\n",
        "            \"Explain what the learning rate controls during training\",\n",
        "            \"Describe what happens when the learning rate is too high or too low\",\n",
        "            \"Explain why choosing an appropriate learning rate matters\",\n",
        "        ],\n",
        "        success_criteria=(\n",
        "            \"Learner can explain the effect of learning rate \"\n",
        "            \"on training stability and convergence speed.\"\n",
        "        ),\n",
        "    ),\n",
        "\n",
        "    # ==================================================\n",
        "    # CP5 ‚Äî Activation Functions\n",
        "    # ==================================================\n",
        "    Checkpoint(\n",
        "        id=\"cp5\",\n",
        "        topic=\"Activation Functions\",\n",
        "        objectives=[\n",
        "            \"Explain why activation functions are needed in neural networks\",\n",
        "            \"Describe the behavior of sigmoid tanh and relu functions\",\n",
        "            \"Choose an activation function for a simple task and justify the choice\",\n",
        "        ],\n",
        "        success_criteria=(\n",
        "            \"Learner can select and justify an activation function \"\n",
        "            \"for a given problem.\"\n",
        "        ),\n",
        "    ),\n",
        "\n",
        "    # ==================================================\n",
        "    # CP6 ‚Äî Backpropagation\n",
        "    # ==================================================\n",
        "    Checkpoint(\n",
        "        id=\"cp6\",\n",
        "        topic=\"Backpropagation\",\n",
        "        objectives=[\n",
        "            \"Explain how the chain rule connects gradients across network layers\",\n",
        "            \"Describe how prediction error flows backward from output to hidden layers\",\n",
        "            \"Explain why backpropagation enables efficient weight updates\",\n",
        "        ],\n",
        "        success_criteria=(\n",
        "            \"Learner can explain backpropagation intuitively without equations \"\n",
        "            \"using a simple neural network example.\"\n",
        "        ),\n",
        "    ),\n",
        "\n",
        "    # ==================================================\n",
        "    # CP7 ‚Äî Overfitting and Generalization\n",
        "    # ==================================================\n",
        "    Checkpoint(\n",
        "        id=\"cp7\",\n",
        "        topic=\"Overfitting and Generalization\",\n",
        "        objectives=[\n",
        "            \"Explain what overfitting means in machine learning\",\n",
        "            \"Describe the difference between training performance and test performance\",\n",
        "            \"Identify common signs that a model is overfitting\",\n",
        "        ],\n",
        "        success_criteria=(\n",
        "            \"Learner can explain why a model that performs well on training data \"\n",
        "            \"may fail on unseen data.\"\n",
        "        ),\n",
        "    ),\n",
        "\n",
        "    # ==================================================\n",
        "    # CP8 ‚Äî Train Validation and Test Data\n",
        "    # ==================================================\n",
        "    Checkpoint(\n",
        "        id=\"cp8\",\n",
        "        topic=\"Train Validation and Test Data\",\n",
        "        objectives=[\n",
        "            \"Explain why data is split into training validation and test sets\",\n",
        "            \"Describe the role of each dataset during model development\",\n",
        "            \"Explain how validation data helps improve model decisions\",\n",
        "        ],\n",
        "        success_criteria=(\n",
        "            \"Learner can explain the purpose of each data split \"\n",
        "            \"and how they prevent misleading performance evaluation.\"\n",
        "        ),\n",
        "    ),\n",
        "\n",
        "    # ==================================================\n",
        "    # CP9 ‚Äî Weight Initialization\n",
        "    # ==================================================\n",
        "    Checkpoint(\n",
        "        id=\"cp9\",\n",
        "        topic=\"Weight Initialization\",\n",
        "        objectives=[\n",
        "            \"Explain why initial weights affect neural network training\",\n",
        "            \"Describe problems caused by very large or very small initial weights\",\n",
        "            \"Explain how good initialization helps gradients flow during training\",\n",
        "        ],\n",
        "        success_criteria=(\n",
        "            \"Learner can explain why proper weight initialization \"\n",
        "            \"improves training stability and convergence.\"\n",
        "        ),\n",
        "    ),\n",
        "\n",
        "    # ==================================================\n",
        "    # CP10 ‚Äî Regularization Techniques\n",
        "    # ==================================================\n",
        "    Checkpoint(\n",
        "        id=\"cp10\",\n",
        "        topic=\"Regularization Techniques\",\n",
        "        objectives=[\n",
        "            \"Explain why regularization is used to reduce overfitting\",\n",
        "            \"Describe how L1 L2 and dropout regularization affect model training\",\n",
        "            \"Choose a regularization technique for a simple scenario and justify it\",\n",
        "        ],\n",
        "        success_criteria=(\n",
        "            \"Learner can explain how regularization improves generalization \"\n",
        "            \"and select an appropriate technique for a given problem.\"\n",
        "        ),\n",
        "    ),\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Agent State\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    cp_id: str\n",
        "    checkpoint: Optional[Checkpoint]\n",
        "    user_notes: str\n",
        "    user_pdfs: List[str]\n",
        "    gathered_context: str\n",
        "    context_sources: List[str]\n",
        "    relevance_score_model: Optional[int]\n",
        "    refetch_attempted: bool\n",
        "    score_meta: Optional[dict]\n",
        "\n",
        "    processed_chunks: List[str]\n",
        "    questions: List[str]\n",
        "    learner_answers: List[str]\n",
        "\n",
        "    score_percent: Optional[float]\n",
        "    pass_threshold_met: Optional[bool]\n",
        "\n",
        "    question_scores: Optional[List[dict]]   # ‚úÖ ADD THIS\n",
        "\n",
        "    temp_vector_store: Optional[dict]\n",
        "    feynman_explanation: Optional[str]\n",
        "    feynman_rounds: int\n",
        "    focus_concepts: Optional[List[str]]\n",
        "    failed_objectives: List[str]\n",
        "\n",
        "\n",
        "_score_re = re.compile(r\"\\b([1-5])\\b\")\n",
        "\n",
        "\n",
        "def parse_score_from_text(raw: str) -> int:\n",
        "    if not raw:\n",
        "        return 3\n",
        "    m = _score_re.search(raw)\n",
        "    return int(m.group(1)) if m else 3\n",
        "\n",
        "\n",
        "\n",
        "# PDF extraction helpers\n",
        "\n",
        "def extract_text_from_pdf(path: str) -> str:\n",
        "    if not _pdf_lib:\n",
        "        raise RuntimeError(\"PyPDF2 not installed. `pip install PyPDF2` to enable PDF ingestion.\")\n",
        "    text = []\n",
        "    with open(path, \"rb\") as f:\n",
        "        reader = _pdf_lib.PdfReader(f)\n",
        "        for p in reader.pages:\n",
        "            try:\n",
        "                page_text = p.extract_text() or \"\"\n",
        "            except Exception:\n",
        "                page_text = \"\"\n",
        "            if page_text:\n",
        "                text.append(page_text)\n",
        "    return \"\\n\".join(text)\n",
        "\n",
        "\n",
        "def gather_texts_from_pdfs(paths: List[str]) -> str:\n",
        "    out = \"\"\n",
        "    for p in paths:\n",
        "        try:\n",
        "            t = extract_text_from_pdf(p)\n",
        "            if t.strip():\n",
        "                out += f\"\\n--- PDF: {os.path.basename(p)} ---\\n{t}\\n\"\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to read PDF {p}: {e}\")\n",
        "    return out\n",
        "\n",
        "def expand_text(text: str, cp: Checkpoint) -> str:\n",
        "    if not text.strip():\n",
        "        return text\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a technical instructor.\n",
        "\n",
        "Write a DETAILED and STRUCTURED explanation strictly for learning purposes.\n",
        "\n",
        "TOPIC:\n",
        "{cp.topic}\n",
        "\n",
        "LEARNING OBJECTIVES:\n",
        "{json.dumps(cp.objectives, ensure_ascii=False)}\n",
        "\n",
        "STYLE RULES:\n",
        "- Be factual and instructional\n",
        "- Use clear headings for each objective\n",
        "- Explain concepts step by step\n",
        "- Use simple technical examples only\n",
        "- Avoid metaphors stories or creative analogies\n",
        "- Avoid unnecessary verbosity\n",
        "- Do NOT oversimplify\n",
        "- Do NOT be conversational\n",
        "- Write like a concise textbook or lecture note\n",
        "\n",
        "DEPTH REQUIREMENTS:\n",
        "- Each objective must have at least 2‚Äì3 clear paragraphs\n",
        "- Explain key terms explicitly\n",
        "- Maintain logical flow\n",
        "- Target ~700‚Äì1000 words total\n",
        "\n",
        "SOURCE MATERIAL:\n",
        "\\\"\\\"\\\"{text[:8000]}\\\"\\\"\\\"\n",
        "\n",
        "Write the explanation:\n",
        "\"\"\"\n",
        "    return groq_chat(prompt, use_cache=False).strip()\n",
        "\n",
        "\n",
        "\n",
        "# Summarizer (uses Groq)\n",
        "\n",
        "def summarize_text(text: str) -> str:\n",
        "    if not text.strip():\n",
        "        return text\n",
        "    prompt = f\"\"\"\n",
        "Summarize the following text into a focused explanation matching the learning objectives.\n",
        "Keep it concise, clean, and relevant.\n",
        "\n",
        "Text:\n",
        "\\\"\\\"\\\"{text[:5000]}\\\"\\\"\\\"\\n\n",
        "Summary:\n",
        "\"\"\"\n",
        "    summary = groq_chat(prompt)\n",
        "    return summary.strip() or text[:5000]\n",
        "\n",
        "\n",
        "\n",
        "# Tavily wrapper with rate limiting (< 10 searches/min)\n",
        "\n",
        "_search_timestamps: List[float] = []\n",
        "\n",
        "\n",
        "def _enforce_search_rate_limit():\n",
        "    global _search_timestamps\n",
        "    now = time.time()\n",
        "    _search_timestamps = [t for t in _search_timestamps if now - t < 60]\n",
        "    if len(_search_timestamps) >= 9:\n",
        "        oldest = min(_search_timestamps)\n",
        "        wait = 60 - (now - oldest)\n",
        "        if wait > 0:\n",
        "            print(f\"[Rate Limit] Tavily search rate reached. Waiting {wait:.1f}s to stay under 10/min...\")\n",
        "            time.sleep(wait)\n",
        "        now = time.time()\n",
        "        _search_timestamps = [t for t in _search_timestamps if now - t < 60]\n",
        "    _search_timestamps.append(time.time())\n",
        "\n",
        "\n",
        "@traceable(name=\"tavily_search\")\n",
        "def search_tavily(query: str, max_results: int = 5) -> List[dict]:\n",
        "    _enforce_search_rate_limit()\n",
        "    try:\n",
        "        res = tavily_client.search(query=query, max_results=max_results)\n",
        "        return res.get(\"results\", []) if isinstance(res, dict) else []\n",
        "    except Exception as e:\n",
        "        print(\"Tavily search failed:\", e)\n",
        "        return []\n",
        "\n",
        "\n",
        "\n",
        "# Evidence cleaning & user JSON helpers\n",
        "\n",
        "def clean_evidence(raw: str) -> str:\n",
        "    if not raw:\n",
        "        return \"\"\n",
        "    s = raw\n",
        "    s = re.sub(r\"```.*?```\", \"\", s, flags=re.DOTALL)\n",
        "    s = re.sub(r\"\\s*\\\\n\\s*\", \" \", s)\n",
        "    s = re.sub(r'^\\s*\\{.*?\"evidence\"\\s*:\\s*', \"\", s, flags=re.DOTALL)\n",
        "    s = s.replace('\"covered\":', \"\")\n",
        "    s = s.replace(\"{\", \"\").replace(\"}\", \"\")\n",
        "    s = s.replace('\"\"\"', \"\").replace(\"'''\", \"\")\n",
        "    s = s.strip()\n",
        "    s = re.sub(r'^\\s*[\"\\']?evidence[\"\\']?\\s*[:\\-]?\\s*', \"\", s, flags=re.I)\n",
        "    s = html.unescape(s).strip()\n",
        "    if len(s) > 300:\n",
        "        s = s[:300].rsplit(\" \", 1)[0] + \"...\"\n",
        "    return s\n",
        "\n",
        "\n",
        "def simplify_score_meta_for_user(score_meta: Optional[dict]):\n",
        "    if not score_meta:\n",
        "        return None\n",
        "    covered = score_meta.get(\"covered_count\", 0)\n",
        "    total = score_meta.get(\"total\", 1)\n",
        "    objectives = []\n",
        "    for d in score_meta.get(\"details\", []):\n",
        "        objectives.append(\n",
        "            {\n",
        "                \"objective\": d.get(\"objective\"),\n",
        "                \"covered\": True if str(d.get(\"covered\", \"no\")).lower() == \"yes\" else False,\n",
        "                \"evidence\": clean_evidence(d.get(\"evidence\", \"\")),\n",
        "            }\n",
        "        )\n",
        "    coverage_percent = int(round((covered / total) * 100))\n",
        "    summary = f\"{covered}/{total} objectives covered\"\n",
        "    explain = f\"{coverage_percent}% ‚Äî {summary}\"\n",
        "    return {\n",
        "        \"coverage_percent\": coverage_percent,\n",
        "        \"summary\": summary,\n",
        "        \"explain\": explain,\n",
        "        \"objective_reports\": objectives,\n",
        "    }\n",
        "\n",
        "\n",
        "# Embeddings + Temporary in-memory vector store (Milestone 2)\n",
        "\n",
        "_emb_model = None\n",
        "_np = None\n",
        "_EMBEDDING_DEBUG = os.getenv(\"EMBEDDING_DEBUG\", \"0\") in (\"1\", \"true\", \"True\")\n",
        "\n",
        "# Chunking configuration\n",
        "CHUNK_SIZE = 1200\n",
        "CHUNK_OVERLAP = 250\n",
        "MIN_CHUNK_LENGTH = 300\n",
        "\n",
        "try:\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    import numpy as np\n",
        "\n",
        "    try:\n",
        "        print(\"[Embedding] Loading SentenceTransformer 'all-MiniLM-L6-v2' ... (this may take a few seconds)\")\n",
        "        _emb_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "        _np = np\n",
        "        print(\"[Embedding] Model loaded:all-MiniLM-L6-v2\")\n",
        "    except Exception as e:\n",
        "        print(f\"[Embedding] Failed to load SentenceTransformer model: {e}\")\n",
        "        _emb_model = None\n",
        "        _np = None\n",
        "except Exception:\n",
        "    _emb_model = None\n",
        "    try:\n",
        "        import numpy as np\n",
        "        _np = np\n",
        "    except Exception:\n",
        "        _np = None\n",
        "\n",
        "\n",
        "def is_context_relevant_semantically(\n",
        "    context: str,\n",
        "    cp,\n",
        "    threshold: float = 0.35\n",
        ") -> bool:\n",
        "    \"\"\"\n",
        "    Embedding-based semantic relevance check.\n",
        "    Returns False if context is unrelated to checkpoint topic/objectives.\n",
        "    \"\"\"\n",
        "    if not context.strip():\n",
        "        return False\n",
        "\n",
        "    # If embeddings unavailable, don't block pipeline\n",
        "    if _emb_model is None or _np is None:\n",
        "        return True\n",
        "\n",
        "    reference_text = cp.topic + \" \" + \" \".join(cp.objectives)\n",
        "\n",
        "    try:\n",
        "        ctx_vec = _emb_model.encode([context[:2000]], convert_to_numpy=True)\n",
        "        ref_vec = _emb_model.encode([reference_text], convert_to_numpy=True)\n",
        "\n",
        "        ctx_vec = ctx_vec / (_np.linalg.norm(ctx_vec, axis=1, keepdims=True) + 1e-12)\n",
        "        ref_vec = ref_vec / (_np.linalg.norm(ref_vec, axis=1, keepdims=True) + 1e-12)\n",
        "\n",
        "        similarity = float(ctx_vec @ ref_vec.T)\n",
        "\n",
        "        if _EMBEDDING_DEBUG:\n",
        "            print(f\"[Semantic Relevance] similarity={similarity:.3f}\")\n",
        "\n",
        "        return similarity >= threshold\n",
        "\n",
        "    except Exception:\n",
        "        return True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def build_temp_vector_store(chunks: List[str]):\n",
        "    \"\"\"\n",
        "    Build temporary in-memory vector store for this session.\n",
        "    Returns dict: { 'chunks': [...], 'vectors': np.array or None, 'meta': {...} }\n",
        "    \"\"\"\n",
        "    if not chunks:\n",
        "        return {\"chunks\": [], \"vectors\": None, \"meta\": {\"embeddings_used\": False}}\n",
        "    if _emb_model and _np is not None:\n",
        "        try:\n",
        "            vecs = _emb_model.encode(chunks, convert_to_numpy=True, show_progress_bar=False)\n",
        "            # normalize vectors for cosine sim\n",
        "            norms = _np.linalg.norm(vecs, axis=1, keepdims=True) + 1e-12\n",
        "            vecs = vecs / norms\n",
        "            store = {\"chunks\": chunks, \"vectors\": vecs, \"meta\": {\"embeddings_used\": True}}\n",
        "            if _EMBEDDING_DEBUG:\n",
        "                print(f\"[Embedding] Built vector store: vectors shape = {vecs.shape}\")\n",
        "            return store\n",
        "        except Exception as e:\n",
        "            print(f\"[Embedding] Exception while encoding chunks: {e}\")\n",
        "            pass\n",
        "    # fallback: no embeddings (vectors=None) ‚Äî token-overlap will be used\n",
        "    if _EMBEDDING_DEBUG:\n",
        "        print(\"[Embedding] No embedding model available; using token-overlap fallback.\")\n",
        "    return {\"chunks\": chunks, \"vectors\": None, \"meta\": {\"embeddings_used\": False}}\n",
        "\n",
        "\n",
        "def embedding_debug_print(store, label: str = \"\"):\n",
        "    try:\n",
        "        emb_used = bool(store and store.get(\"vectors\") is not None)\n",
        "        if emb_used:\n",
        "            vecs = store[\"vectors\"]\n",
        "            shape = getattr(vecs, \"shape\", None)\n",
        "            print(f\"[Embedding Confirm] {label} embeddings used: True | vector shape: {shape}\")\n",
        "            # print a tiny sample: first vector first 6 values\n",
        "            sample = vecs[0][:6].tolist() if hasattr(vecs[0], \"tolist\") else list(vecs[0][:6])\n",
        "            print(f\"[Embedding Confirm] sample vec[0][:6] ~ {sample}\")\n",
        "        else:\n",
        "            print(f\"[Embedding Confirm] {label} embeddings used: False\")\n",
        "    except Exception as e:\n",
        "        print(f\"[Embedding Confirm] Error during debug print: {e}\")\n",
        "\n",
        "\n",
        "def retrieve_top_k(store, query: str, k: int = 3) -> List[str]:\n",
        "    chunks = store.get(\"chunks\", []) or []\n",
        "    vectors = store.get(\"vectors\", None)\n",
        "\n",
        "    if not chunks:\n",
        "        return []\n",
        "\n",
        "    if vectors is not None and _emb_model is not None and _np is not None:\n",
        "        try:\n",
        "            qv = _emb_model.encode([query], convert_to_numpy=True, show_progress_bar=False)\n",
        "            qv = qv / (_np.linalg.norm(qv, axis=1, keepdims=True) + 1e-12)\n",
        "\n",
        "            sims = vectors @ qv.T\n",
        "            sims = sims.reshape(-1)   # ‚úÖ CRITICAL FIX\n",
        "\n",
        "            idx_sorted = sims.argsort()[::-1][:k]\n",
        "            top_chunks = [chunks[i] for i in idx_sorted if i < len(chunks)]\n",
        "\n",
        "            if _EMBEDDING_DEBUG:\n",
        "                top_info = [(int(i), float(sims[i])) for i in idx_sorted]\n",
        "                print(f\"[Retrieve Debug] top-k indices+sim: {top_info}\")\n",
        "\n",
        "            return top_chunks\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[Retrieve] Embedding retrieval failed: {e}\")\n",
        "\n",
        "    # ---- fallback: token overlap ----\n",
        "    q_words = set(re.findall(r\"\\w+\", query.lower()))\n",
        "    scored = []\n",
        "    for i, c in enumerate(chunks):\n",
        "        c_words = set(re.findall(r\"\\w+\", c.lower()))\n",
        "        scored.append((len(q_words & c_words), i))\n",
        "\n",
        "    scored.sort(reverse=True)\n",
        "    return [chunks[i] for s, i in scored[:k] if s > 0] or chunks[:k]\n",
        "\n",
        "    if top:\n",
        "        if _EMBEDDING_DEBUG:\n",
        "            print(f\"[Retrieve Debug] token-overlap scores (top): {scored[:k]}\")\n",
        "        return top\n",
        "    # last fallback: first k chunks\n",
        "    return chunks[:k]\n",
        "\n",
        "\n",
        "\n",
        "# LangGraph Nodes\n",
        "\n",
        "def get_checkpoint_by_id(cp_id: str) -> Checkpoint:\n",
        "    for cp in CHECKPOINTS:\n",
        "        if cp.id == cp_id:\n",
        "            return cp\n",
        "    raise ValueError(f\"Checkpoint {cp_id} not found\")\n",
        "\n",
        "def create_custom_checkpoint(topic: str) -> Checkpoint:\n",
        "    return Checkpoint(\n",
        "        id=\"__custom__\",\n",
        "        topic=topic.strip(),\n",
        "        objectives=[\n",
        "            f\"Explain the core principles of {topic}\",\n",
        "            f\"Describe key laws or rules related to {topic}\",\n",
        "            f\"Apply {topic} concepts to simple examples\",\n",
        "        ],\n",
        "        success_criteria=f\"Learner can clearly explain and apply {topic} concepts.\"\n",
        "    )\n",
        "def start_checkpoint(state: AgentState) -> AgentState:\n",
        "    state = dict(state)\n",
        "\n",
        "    # ======================================================\n",
        "    # 1Ô∏è‚É£ Resolve checkpoint (predefined OR custom)\n",
        "    # ======================================================\n",
        "    if state.get(\"cp_id\") == \"__custom__\":\n",
        "        topic = (state.get(\"custom_topic\") or \"\").strip()\n",
        "        if not topic:\n",
        "            raise ValueError(\"Custom topic provided but empty.\")\n",
        "\n",
        "        # ‚úÖ USE SINGLE SOURCE OF TRUTH\n",
        "        cp = create_custom_checkpoint(topic)\n",
        "\n",
        "        # üîπ OPTIONAL: AI-enhanced objectives\n",
        "        try:\n",
        "            prompt = f\"\"\"\n",
        "Generate exactly 3 beginner-friendly learning objectives for the topic:\n",
        "{topic}\n",
        "\n",
        "Rules:\n",
        "- Conceptual, not mathematical\n",
        "- Simple sentences\n",
        "- No numbering\n",
        "- No extra text\n",
        "\n",
        "Return JSON only:\n",
        "{{ \"objectives\": [\"...\", \"...\", \"...\"] }}\n",
        "\"\"\"\n",
        "            raw = groq_chat(prompt, use_cache=True)\n",
        "            import json, re\n",
        "            m = re.search(r\"\\{.*\\}\", raw, re.DOTALL)\n",
        "            if m:\n",
        "                data = json.loads(m.group(0))\n",
        "                if isinstance(data.get(\"objectives\"), list) and len(data[\"objectives\"]) >= 3:\n",
        "                    cp.objectives = data[\"objectives\"][:3]\n",
        "        except Exception:\n",
        "            pass  # fallback stays intact\n",
        "\n",
        "    else:\n",
        "        cp = get_checkpoint_by_id(state[\"cp_id\"])\n",
        "\n",
        "    # ======================================================\n",
        "    # 2Ô∏è‚É£ Core reset\n",
        "    # ======================================================\n",
        "    state[\"checkpoint\"] = cp\n",
        "    state[\"gathered_context\"] = \"\"\n",
        "    state[\"context_sources\"] = []\n",
        "    state[\"score_meta\"] = None\n",
        "\n",
        "    # ======================================================\n",
        "    # 3Ô∏è‚É£ Context processing reset\n",
        "    # ======================================================\n",
        "    state[\"processed_chunks\"] = []\n",
        "    state[\"temp_vector_store\"] = None\n",
        "\n",
        "    # ======================================================\n",
        "    # 4Ô∏è‚É£ Assessment reset\n",
        "    # ======================================================\n",
        "    state[\"questions\"] = []\n",
        "    state[\"learner_answers\"] = []\n",
        "    state[\"score_percent\"] = None\n",
        "    state[\"pass_threshold_met\"] = None\n",
        "    state[\"question_scores\"] = []\n",
        "\n",
        "    state[\"refetch_attempted\"] = False\n",
        "\n",
        "    # ======================================================\n",
        "    # 5Ô∏è‚É£ üîí Feynman HARD RESET (CRITICAL)\n",
        "    # ======================================================\n",
        "    state[\"feynman_explanation\"] = None\n",
        "    state[\"feynman_rounds\"] = 0\n",
        "    state[\"focus_concepts\"] = None\n",
        "    state[\"failed_objectives\"] = []\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "@traceable(name=\"gather_context_node\")\n",
        "def gather_context(state: AgentState) -> AgentState:\n",
        "    cp = state[\"checkpoint\"]\n",
        "    notes = state[\"user_notes\"]\n",
        "    pdfs = state.get(\"user_pdfs\", [])\n",
        "\n",
        "    sources = []\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 1Ô∏è‚É£ USER NOTES (COLLECT, DO NOT DOMINATE)\n",
        "    # -------------------------------------------------\n",
        "    user_notes = notes.strip() if notes.strip() else \"\"\n",
        "    if user_notes:\n",
        "        sources.append(\"user_notes\")\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 2Ô∏è‚É£ AUTO-GENERATED CONTEXT (PDF + WEB ALWAYS)\n",
        "    # -------------------------------------------------\n",
        "    auto_context = \"\"\n",
        "\n",
        "    if pdfs:\n",
        "        pdf_text = gather_texts_from_pdfs(pdfs)\n",
        "        if pdf_text.strip():\n",
        "            auto_context += pdf_text + \"\\n\"\n",
        "            sources.append(\"pdf_upload\")\n",
        "\n",
        "    # ALWAYS fetch web content (even if notes exist)\n",
        "    query = f\"{cp.topic} - \" + \"; \".join(cp.objectives)\n",
        "    results = search_tavily(query=query)\n",
        "\n",
        "    for item in results:\n",
        "        content = item.get(\"content\")\n",
        "        if content:\n",
        "            auto_context += content + \"\\n\"\n",
        "\n",
        "    if auto_context.strip():\n",
        "        sources.append(\"web_search\")\n",
        "        auto_context = expand_text(auto_context, cp)\n",
        "\n",
        "    # Summarize ONLY auto content if large\n",
        "    if len(auto_context) > 5000:\n",
        "        auto_context = summarize_text(auto_context)\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 3Ô∏è‚É£ MERGE USER NOTES + GENERATED CONTENT\n",
        "    # -------------------------------------------------\n",
        "    if user_notes and auto_context.strip():\n",
        "        merge_prompt = f\"\"\"\n",
        "You are an expert tutor.\n",
        "\n",
        "Merge the USER NOTES with the GENERATED CONTENT into ONE clear explanation.\n",
        "\n",
        "RULES:\n",
        "- Keep all correct technical information\n",
        "- If user notes are correct, integrate them naturally\n",
        "- If user notes are incomplete, enrich them\n",
        "- If user notes are incorrect, silently correct them\n",
        "- Do NOT mention notes or sources\n",
        "- Write a clean instructional explanation\n",
        "- Stay strictly within the topic\n",
        "\n",
        "TOPIC:\n",
        "{cp.topic}\n",
        "\n",
        "LEARNING OBJECTIVES:\n",
        "{json.dumps(cp.objectives, ensure_ascii=False)}\n",
        "\n",
        "USER NOTES:\n",
        "\\\"\\\"\\\"{user_notes}\\\"\\\"\\\"\n",
        "\n",
        "GENERATED CONTENT:\n",
        "\\\"\\\"\\\"{auto_context[:6000]}\\\"\\\"\\\"\n",
        "\n",
        "FINAL EXPLANATION:\n",
        "\"\"\"\n",
        "        final_context = groq_chat(merge_prompt, use_cache=False).strip()\n",
        "    else:\n",
        "        # No notes ‚Üí pure generated content\n",
        "        final_context = auto_context\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 4Ô∏è‚É£ SAVE FINAL CONTEXT\n",
        "    # -------------------------------------------------\n",
        "    state = dict(state)\n",
        "    state[\"gathered_context\"] = final_context\n",
        "    state[\"context_sources\"] = list(dict.fromkeys(sources))  # dedupe\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(f\"[Merged Context] Source(s): {', '.join(state['context_sources']) if sources else 'None'}\")\n",
        "    print(\"-\" * 80)\n",
        "    print(final_context[:3000] if final_context.strip() else \"[No context gathered]\")\n",
        "    print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "@traceable(name=\"validate_context_node\")\n",
        "def validate_context(state: AgentState) -> AgentState:\n",
        "    cp = state[\"checkpoint\"]\n",
        "    context = state[\"gathered_context\"]\n",
        "    refetch = state.get(\"refetch_attempted\", False)\n",
        "\n",
        "    #  SEMANTIC FILTER\n",
        "    is_relevant = is_context_relevant_semantically(context, cp)\n",
        "\n",
        "    if not is_relevant and not refetch:\n",
        "        print(\"[Semantic Filter] Context is unrelated. Refetching from web...\")\n",
        "\n",
        "        query = f\"{cp.topic} for beginners; \" + \"; \".join(cp.objectives)\n",
        "        results = search_tavily(query=query)\n",
        "\n",
        "        new_context = \"\"\n",
        "        for item in results:\n",
        "            c = item.get(\"content\")\n",
        "            if c:\n",
        "                new_context += c + \"\\n\"\n",
        "\n",
        "        if new_context.strip():\n",
        "            new_context = summarize_text(new_context)\n",
        "\n",
        "        context = new_context\n",
        "        refetch = True\n",
        "\n",
        "\n",
        "    def score_ctx_objectives_only(ctx: str):\n",
        "        objectives = cp.objectives\n",
        "        covered = 0\n",
        "        details = []\n",
        "\n",
        "        for obj in objectives:\n",
        "            prompt = f\"\"\"\n",
        "You must respond with a single valid JSON object and NOTHING else.\n",
        "\n",
        "Keys:\n",
        "- \"covered\": either \"yes\" or \"no\"\n",
        "- \"evidence\": one short sentence (<=30 words) quoting or paraphrasing the CONTEXT\n",
        "\n",
        "OBJECTIVE:\n",
        "\\\"\\\"\\\"{obj}\\\"\\\"\\\"\\n\n",
        "CONTEXT:\n",
        "\\\"\\\"\\\"{ctx[:8000]}\\\"\\\"\\\"\\n\n",
        "Return only JSON like: {{ \"covered\": \"yes\", \"evidence\": \"...\" }}\n",
        "\"\"\"\n",
        "            raw = groq_chat(prompt).strip()\n",
        "\n",
        "            cov = \"no\"\n",
        "            evidence = \"\"\n",
        "\n",
        "            try:\n",
        "                import json as _json, re as _re\n",
        "                m = _re.search(r\"\\{.*\\}\", raw, _re.DOTALL)\n",
        "                if m:\n",
        "                    parsed = _json.loads(m.group(0))\n",
        "                    cov = str(parsed.get(\"covered\", \"no\")).lower()\n",
        "                    evidence = str(parsed.get(\"evidence\", \"\")).strip()\n",
        "                    if cov not in (\"yes\", \"no\"):\n",
        "                        cov = \"no\"\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "            if cov == \"yes\":\n",
        "                covered += 1\n",
        "\n",
        "            details.append({\n",
        "                \"objective\": obj,\n",
        "                \"covered\": cov,\n",
        "                \"evidence\": evidence\n",
        "            })\n",
        "\n",
        "        total = len(objectives) or 1\n",
        "        base_score = round((covered / total) * 5)\n",
        "        score = min(5, max(1, base_score))\n",
        "\n",
        "        meta = {\n",
        "            \"covered_count\": covered,\n",
        "            \"total\": total,\n",
        "            \"details\": details\n",
        "        }\n",
        "        return score, meta\n",
        "\n",
        "    score, score_meta = score_ctx_objectives_only(context)\n",
        "\n",
        "    if score <= 2 and not refetch:\n",
        "        print(\"Low relevance detected. Refetching...\")\n",
        "        query = f\"{cp.topic} for beginners; \" + \"; \".join(cp.objectives)\n",
        "        results = search_tavily(query=query)\n",
        "\n",
        "        new_context = \"\"\n",
        "        for item in results:\n",
        "            c = item.get(\"content\")\n",
        "            if c:\n",
        "                new_context += c + \"\\n\"\n",
        "\n",
        "        if new_context.strip():\n",
        "            new_context = summarize_text(new_context)\n",
        "\n",
        "        score, score_meta = score_ctx_objectives_only(new_context)\n",
        "        context = new_context\n",
        "        refetch = True\n",
        "\n",
        "    state = dict(state)\n",
        "    state[\"gathered_context\"] = context\n",
        "    state[\"relevance_score_model\"] = score\n",
        "    state[\"refetch_attempted\"] = refetch\n",
        "    state[\"score_meta\"] = score_meta\n",
        "\n",
        "    if refetch and \"web_search\" not in state[\"context_sources\"]:\n",
        "        state[\"context_sources\"].append(\"web_search\")\n",
        "\n",
        "    print(f\"Score for {cp.id}: {score} ({score_meta['covered_count']}/{score_meta['total']} objectives covered)\")\n",
        "    for d in score_meta[\"details\"]:\n",
        "        print(f\" - Obj: {d['objective'][:60]}... => {d['covered']} | evidence: {clean_evidence(d['evidence'])[:140]}\")\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "\n",
        "# Milestone 2: Context processing (chunking) + build temp vector store\n",
        "\n",
        "@traceable(name=\"process_context_node\")\n",
        "def process_context(state: AgentState) -> AgentState:\n",
        "    context = (state.get(\"gathered_context\") or \"\").strip()\n",
        "    chunks: List[str] = []\n",
        "\n",
        "    if context:\n",
        "        start = 0\n",
        "        text_len = len(context)\n",
        "\n",
        "        while start < text_len:\n",
        "            end = start + CHUNK_SIZE\n",
        "            chunk = context[start:end].strip()\n",
        "\n",
        "            if len(chunk) >= MIN_CHUNK_LENGTH:\n",
        "                chunks.append(chunk)\n",
        "\n",
        "            # move forward with overlap\n",
        "            start = end - CHUNK_OVERLAP\n",
        "            if start < 0:\n",
        "                start = 0\n",
        "\n",
        "            # stop infinite loop\n",
        "            if start >= text_len:\n",
        "                break\n",
        "\n",
        "    # Fallback safety\n",
        "    if not chunks and context:\n",
        "        chunks = [context]\n",
        "\n",
        "    state = dict(state)\n",
        "    state[\"processed_chunks\"] = chunks\n",
        "\n",
        "    # Build temporary vector store (Milestone 2 requirement)\n",
        "    store = build_temp_vector_store(chunks)\n",
        "    state[\"temp_vector_store\"] = store\n",
        "\n",
        "    # Debug confirmation\n",
        "    if _EMBEDDING_DEBUG:\n",
        "        print(f\"[Chunking] Produced {len(chunks)} chunks \"\n",
        "              f\"(size={CHUNK_SIZE}, overlap={CHUNK_OVERLAP})\")\n",
        "        embedding_debug_print(store, label=f\"cp={state.get('cp_id')}\")\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "\n",
        "@traceable(name=\"generate_questions_node\")\n",
        "def generate_questions(state: AgentState) -> AgentState:\n",
        "    import time, random\n",
        "\n",
        "    cp = state[\"checkpoint\"]\n",
        "    chunks = state.get(\"processed_chunks\") or []\n",
        "    store = state.get(\"temp_vector_store\") or {\n",
        "        \"chunks\": chunks,\n",
        "        \"vectors\": None,\n",
        "        \"meta\": {\"embeddings_used\": False},\n",
        "    }\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # Attempt-aware variation\n",
        "    # -------------------------------------------------\n",
        "    attempt = state.get(\"feynman_rounds\", 0)\n",
        "\n",
        "    QUESTION_STYLES = [\n",
        "        \"role\",\n",
        "        \"process\",\n",
        "        \"why\",\n",
        "        \"analogy\",\n",
        "        \"application\",\n",
        "    ]\n",
        "    style = QUESTION_STYLES[attempt % len(QUESTION_STYLES)]\n",
        "\n",
        "    # üî• TRUE ENTROPY\n",
        "    nonce = f\"{attempt}-{int(time.time()*1000)}-{random.randint(1000,9999)}\"\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # Weak concepts\n",
        "    # -------------------------------------------------\n",
        "    focus_concepts = state.get(\"focus_concepts\") or cp.objectives\n",
        "    query = \" \".join(focus_concepts)\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # Retrieve top-k chunks\n",
        "    # -------------------------------------------------\n",
        "    focus_for_generation = \"\"\n",
        "    if chunks:\n",
        "        top_chunks = retrieve_top_k(store, query=query, k=3)\n",
        "        focus_for_generation = \"\\n\\n\".join(top_chunks)\n",
        "\n",
        "    base_context = (focus_for_generation or \"\\n\\n\".join(chunks))[:3000]\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # LLM prompt (18 WORD LIMIT)\n",
        "    # -------------------------------------------------\n",
        "    prompt = f\"\"\"\n",
        "You are an adaptive AI tutor.\n",
        "\n",
        "SYSTEM NONCE: {nonce}\n",
        "\n",
        "ATTEMPT NUMBER: {attempt}\n",
        "QUESTION STYLE: {style}\n",
        "\n",
        "Generate EXACTLY 3 SHORT questions.\n",
        "\n",
        "STRICT FORMAT RULES:\n",
        "- ONE sentence only\n",
        "- MAXIMUM 18 words ‚¨ÖÔ∏è UPDATED\n",
        "- NO commas\n",
        "- NO chained clauses\n",
        "- MUST end with ?\n",
        "- SIMPLE beginner language\n",
        "- Focus ONLY on weak concepts\n",
        "- DIFFERENT from previous attempts\n",
        "- DO NOT start with: \"What is\", \"Define\", \"Explain\"\n",
        "\n",
        "WEAK CONCEPTS:\n",
        "{json.dumps(focus_concepts, ensure_ascii=False)}\n",
        "\n",
        "Return ONLY valid JSON:\n",
        "{{ \"questions\": [\"Q1\", \"Q2\", \"Q3\"] }}\n",
        "\"\"\"\n",
        "\n",
        "    raw = groq_chat(prompt, use_cache=False).strip()\n",
        "\n",
        "    questions = []\n",
        "    try:\n",
        "        m = re.search(r\"\\{.*\\}\", raw, re.DOTALL)\n",
        "        if m:\n",
        "            data = json.loads(m.group(0))\n",
        "            qlist = data.get(\"questions\", [])\n",
        "            if isinstance(qlist, list):\n",
        "                questions = [q.strip() for q in qlist if isinstance(q, str)]\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # Final safety trimming (18 words)\n",
        "    # -------------------------------------------------\n",
        "    clean_questions = []\n",
        "    for q in questions:\n",
        "        q = re.sub(r\",.*\", \"\", q)\n",
        "        q = \" \".join(q.split()[:18])        # ‚¨ÖÔ∏è UPDATED\n",
        "        if not q.endswith(\"?\"):\n",
        "            q += \"?\"\n",
        "        clean_questions.append(q)\n",
        "\n",
        "    state = dict(state)\n",
        "    state[\"questions\"] = clean_questions[:3]\n",
        "\n",
        "    print(f\"[Question Generation] attempt={attempt}, style={style}, nonce={nonce}\")\n",
        "    for q in state[\"questions\"]:\n",
        "        print(\" -\", q)\n",
        "\n",
        "    return state\n",
        "\n",
        "def keyword_overlap_ratio(answer: str, context: str) -> float:\n",
        "    if not answer or not context:\n",
        "        return 0.0\n",
        "\n",
        "    a_words = set(re.findall(r\"\\b[a-zA-Z]{4,}\\b\", answer.lower()))\n",
        "    c_words = set(re.findall(r\"\\b[a-zA-Z]{4,}\\b\", context.lower()))\n",
        "\n",
        "    if not a_words:\n",
        "        return 0.0\n",
        "\n",
        "    return len(a_words & c_words) / len(a_words)\n",
        "\n",
        "def verify_understanding(state: AgentState) -> AgentState:\n",
        "\n",
        "    cp = state[\"checkpoint\"]\n",
        "    questions = state.get(\"questions\") or []\n",
        "    answers = state.get(\"learner_answers\") or []\n",
        "\n",
        "    store = state.get(\"temp_vector_store\") or {\n",
        "        \"chunks\": state.get(\"processed_chunks\", []),\n",
        "        \"vectors\": None,\n",
        "        \"meta\": {\"embeddings_used\": False},\n",
        "    }\n",
        "\n",
        "    if not questions or not answers:\n",
        "        print(f\"No questions or learner answers for {cp.id}; skipping verification.\")\n",
        "        state[\"score_percent\"] = None\n",
        "        state[\"pass_threshold_met\"] = None\n",
        "        return state\n",
        "\n",
        "    n = min(len(questions), len(answers))\n",
        "    if n == 0:\n",
        "        state[\"score_percent\"] = None\n",
        "        state[\"pass_threshold_met\"] = None\n",
        "        return state\n",
        "\n",
        "    scores = []\n",
        "    question_scores = []\n",
        "    failed_objectives = set()\n",
        "\n",
        "    for i in range(n):\n",
        "        q = questions[i]\n",
        "        a = (answers[i] or \"\").strip()\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # 1Ô∏è‚É£ SHORT ANSWER CHECK\n",
        "        # -------------------------------------------------\n",
        "        if len(a) < 30:\n",
        "            score_val = 0\n",
        "            scores.append(score_val)\n",
        "            question_scores.append({\n",
        "                \"question\": q,\n",
        "                \"answer\": a,\n",
        "                \"score\": score_val,\n",
        "            })\n",
        "            failed_objectives.add(q)\n",
        "            print(f\"[Verify] {cp.id} Q{i+1} ‚Üí score 0 (answer too short)\")\n",
        "            continue\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # CONTEXT FOR GRADING\n",
        "        # -------------------------------------------------\n",
        "        top_chunks = retrieve_top_k(store, query=q, k=3)\n",
        "        context_for_grading = \"\\n\\n\".join(top_chunks)[:4000]\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # 2Ô∏è‚É£ KEYWORD OVERLAP GUARD\n",
        "        # -------------------------------------------------\n",
        "        overlap = keyword_overlap_ratio(a, context_for_grading)\n",
        "\n",
        "        if overlap < 0.05:\n",
        "            score_val = 0\n",
        "            scores.append(score_val)\n",
        "            question_scores.append({\n",
        "                \"question\": q,\n",
        "                \"answer\": a,\n",
        "                \"score\": score_val,\n",
        "            })\n",
        "            failed_objectives.add(q)\n",
        "            print(f\"[Verify] {cp.id} Q{i+1} ‚Üí score 0 (unrelated answer)\")\n",
        "            continue\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # 3Ô∏è‚É£ DETERMINISTIC BUCKETED SCORING\n",
        "        # -------------------------------------------------\n",
        "        prompt = f\"\"\"\n",
        "Return ONLY valid JSON.\n",
        "\n",
        "CONTEXT:\n",
        "\\\"\\\"\\\"{context_for_grading}\\\"\\\"\\\"\n",
        "\n",
        "QUESTION:\n",
        "{q}\n",
        "\n",
        "LEARNER ANSWER:\n",
        "{a}\n",
        "\n",
        "Choose EXACTLY ONE score from:\n",
        "[0, 40, 70, 100]\n",
        "\n",
        "Scoring rules:\n",
        "- 0 ‚Üí wrong or unrelated\n",
        "- 40 ‚Üí partial understanding\n",
        "- 70 ‚Üí correct with minor gaps\n",
        "- 100 ‚Üí fully correct\n",
        "\n",
        "Return:\n",
        "{{ \"score\": number }}\n",
        "\"\"\"\n",
        "\n",
        "        score_val = cached_grade(prompt)\n",
        "\n",
        "        if score_val not in (0, 40, 70, 100):\n",
        "            score_val = 0\n",
        "\n",
        "        scores.append(score_val)\n",
        "        question_scores.append({\n",
        "            \"question\": q,\n",
        "            \"answer\": a,\n",
        "            \"score\": score_val,\n",
        "        })\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # 4Ô∏è‚É£ FAILURE TRACKING\n",
        "        # -------------------------------------------------\n",
        "        if score_val < 70:\n",
        "            failed_objectives.add(q)\n",
        "\n",
        "        print(f\"[Verify] {cp.id} Q{i+1} score: {score_val}\")\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 5Ô∏è‚É£ STRICT PASS LOGIC\n",
        "    # -------------------------------------------------\n",
        "    passed = all(s >= 70 for s in scores)\n",
        "\n",
        "    avg_score = sum(scores) / len(scores)\n",
        "\n",
        "    state[\"score_percent\"] = avg_score\n",
        "    state[\"pass_threshold_met\"] = passed\n",
        "    state[\"question_scores\"] = question_scores\n",
        "    state[\"failed_objectives\"] = list(failed_objectives)\n",
        "\n",
        "    print(f\"\\nOverall quiz score for {cp.id}: {avg_score:.1f}% | passed={passed}\")\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "\n",
        "@traceable(name=\"feynman_node\")\n",
        "def feynman_node(state: AgentState) -> AgentState:\n",
        "\n",
        "    cp = state[\"checkpoint\"]\n",
        "    weak_concepts = state.get(\"failed_objectives\") or cp.objectives\n",
        "\n",
        "    store = state.get(\"temp_vector_store\") or {\n",
        "        \"chunks\": state.get(\"processed_chunks\", []),\n",
        "        \"vectors\": None,\n",
        "    }\n",
        "\n",
        "    supporting_chunks = retrieve_top_k(\n",
        "        store,\n",
        "        query=\" \".join(weak_concepts),\n",
        "        k=3\n",
        "    )\n",
        "\n",
        "    support_context = \"\\n\\n\".join(supporting_chunks)[:2500]\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are teaching using the Feynman Technique.\n",
        "\n",
        "TOPIC:\n",
        "{cp.topic}\n",
        "\n",
        "FAILED CONCEPTS:\n",
        "{json.dumps(weak_concepts, ensure_ascii=False)}\n",
        "\n",
        "TRUSTED CONTEXT:\n",
        "\\\"\\\"\\\"{support_context}\\\"\\\"\\\"\n",
        "\n",
        "Rules:\n",
        "- Explain ONLY the failed concepts\n",
        "- Stay strictly within the topic\n",
        "- Use simple language\n",
        "- Use ONE real-life analogy per concept\n",
        "- Step-by-step\n",
        "- Assume zero prior knowledge\n",
        "- Do NOT introduce new topics\n",
        "- Make this explanation DIFFERENT from previous attempts\n",
        "\"\"\"\n",
        "\n",
        "    explanation = groq_chat(prompt, use_cache=False).strip()\n",
        "\n",
        "    state = dict(state)\n",
        "\n",
        "\n",
        "\n",
        "    state[\"feynman_explanation\"] = explanation\n",
        "    state[\"focus_concepts\"] = weak_concepts\n",
        "    state[\"feynman_rounds\"] += 1\n",
        "\n",
        "    # Reset assessment state\n",
        "\n",
        "\n",
        "    state[\"learner_answers\"] = []\n",
        "    state[\"score_percent\"] = None\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üß† FEYNMAN TEACHING MODE\")\n",
        "    print(\"Topic:\", cp.topic)\n",
        "    print(\"Weak concepts:\", weak_concepts)\n",
        "    print(\"=\" * 80)\n",
        "    print(explanation)\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "\n",
        "def route_after_verification(state: AgentState) -> str:\n",
        "    passed = state.get(\"pass_threshold_met\", False)\n",
        "    attempts = state.get(\"feynman_rounds\", 0)\n",
        "\n",
        "    if passed:\n",
        "        return \"pass\"\n",
        "\n",
        "    if attempts < 2:\n",
        "        return \"feynman\"\n",
        "\n",
        "    return \"pass\"\n",
        "\n",
        "\n",
        "def run_checkpoint_with_answers(cp_id: str, answers: List[str], prev_state=None):\n",
        "    \"\"\"\n",
        "    Runs ONE checkpoint with provided answers.\n",
        "    Used by Streamlit UI.\n",
        "    \"\"\"\n",
        "\n",
        "    graph = build_graph()\n",
        "\n",
        "    if prev_state is None:\n",
        "        state: AgentState = {\n",
        "            \"cp_id\": cp_id,\n",
        "            \"checkpoint\": None,\n",
        "            \"user_notes\": \"\",\n",
        "            \"user_pdfs\": [],\n",
        "            \"gathered_context\": \"\",\n",
        "            \"context_sources\": [],\n",
        "            \"relevance_score_model\": None,\n",
        "            \"refetch_attempted\": False,\n",
        "            \"score_meta\": None,\n",
        "            \"processed_chunks\": [],\n",
        "            \"questions\": [],\n",
        "            \"learner_answers\": [],\n",
        "            \"score_percent\": None,\n",
        "            \"pass_threshold_met\": None,\n",
        "            \"temp_vector_store\": None,\n",
        "            \"feynman_explanation\": None,\n",
        "            \"feynman_rounds\": 0,\n",
        "            \"focus_concepts\": None,\n",
        "        }\n",
        "    else:\n",
        "        state = prev_state\n",
        "\n",
        "    # Inject learner answers\n",
        "    state[\"learner_answers\"] = answers\n",
        "\n",
        "    final_state = graph.invoke(state)\n",
        "    return final_state\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def build_graph():\n",
        "    g = StateGraph(AgentState)\n",
        "\n",
        "    g.add_node(\"start_checkpoint\", start_checkpoint)\n",
        "    g.add_node(\"gather_context\", gather_context)\n",
        "    g.add_node(\"validate_context\", validate_context)\n",
        "    g.add_node(\"process_context\", process_context)\n",
        "    g.add_node(\"generate_questions\", generate_questions)\n",
        "    g.add_node(\"verify_understanding\", verify_understanding)\n",
        "    g.add_node(\"feynman_node\", feynman_node)\n",
        "\n",
        "    g.set_entry_point(\"start_checkpoint\")\n",
        "\n",
        "    g.add_edge(\"start_checkpoint\", \"gather_context\")\n",
        "    g.add_edge(\"gather_context\", \"validate_context\")\n",
        "    g.add_edge(\"validate_context\", \"process_context\")\n",
        "    g.add_edge(\"process_context\", \"generate_questions\")\n",
        "    g.add_edge(\"generate_questions\", \"verify_understanding\")\n",
        "\n",
        "    # üîÅ Decision point\n",
        "    g.add_conditional_edges(\n",
        "        \"verify_understanding\",\n",
        "        route_after_verification,\n",
        "        {\n",
        "            \"pass\": END,\n",
        "            \"feynman\": \"feynman_node\",\n",
        "        },\n",
        "    )\n",
        "\n",
        "    # üîÅ Loop back after teaching\n",
        "    g.add_edge(\"feynman_node\", \"generate_questions\")\n",
        "\n",
        "    return g.compile()\n",
        "\n",
        "\n",
        "\n",
        "graph = build_graph()\n",
        "\n",
        "\n",
        "\n",
        "# Helper: read multi-line input (end with an 'END' line)\n",
        "\n",
        "def read_multiline(prompt_msg: str) -> str:\n",
        "    print(prompt_msg)\n",
        "    print(\"Enter/Paste your text. End with a single line containing only: END\")\n",
        "    lines = []\n",
        "    while True:\n",
        "        try:\n",
        "            line = input()\n",
        "        except EOFError:\n",
        "            break\n",
        "        if line.strip() == \"END\":\n",
        "            break\n",
        "        lines.append(line)\n",
        "    return \"\\n\".join(lines).strip()\n",
        "\n",
        "\n",
        "def all_objectives_mastered(state: AgentState) -> bool:\n",
        "    \"\"\"\n",
        "    Returns True only if ALL objectives are marked as covered=yes\n",
        "    \"\"\"\n",
        "    meta = state.get(\"score_meta\")\n",
        "    if not meta:\n",
        "        return False\n",
        "\n",
        "    return all(\n",
        "        item.get(\"covered\") == \"yes\"\n",
        "        for item in meta.get(\"details\", [])\n",
        "    )\n",
        "\n",
        "def run_single_checkpoint_interactive(cp_id: str) -> dict:\n",
        "    cp = get_checkpoint_by_id(cp_id)\n",
        "    print(f\"\\n--- Checkpoint {cp.id}: {cp.topic} ---\")\n",
        "\n",
        "    notes = read_multiline(\"Provide user notes for this checkpoint (or leave blank and type END):\")\n",
        "    pdfs_input = input(\"Enter comma-separated PDF paths for this checkpoint (or leave blank): \").strip()\n",
        "    pdfs = [p.strip() for p in pdfs_input.split(\",\") if p.strip()]\n",
        "\n",
        "    # ---------------------------\n",
        "    # INITIAL STATE\n",
        "    # ---------------------------\n",
        "    state: AgentState = {\n",
        "        \"cp_id\": cp_id,\n",
        "        \"checkpoint\": None,\n",
        "        \"user_notes\": notes,\n",
        "        \"user_pdfs\": pdfs,\n",
        "        \"gathered_context\": \"\",\n",
        "        \"context_sources\": [],\n",
        "        \"relevance_score_model\": None,\n",
        "        \"refetch_attempted\": False,\n",
        "        \"score_meta\": None,\n",
        "        \"processed_chunks\": [],\n",
        "        \"questions\": [],\n",
        "        \"learner_answers\": [],\n",
        "        \"score_percent\": None,\n",
        "        \"pass_threshold_met\": None,\n",
        "        \"temp_vector_store\": None,\n",
        "        \"feynman_explanation\": None,\n",
        "        \"feynman_rounds\": 0,\n",
        "        \"focus_concepts\": None,\n",
        "    }\n",
        "\n",
        "    # ---------------------------\n",
        "    # INITIAL PIPELINE (RUN ONCE)\n",
        "    # ---------------------------\n",
        "    state = start_checkpoint(state)\n",
        "    state = gather_context(state)\n",
        "    state = validate_context(state)\n",
        "    state = process_context(state)\n",
        "\n",
        "    MAX_REASSESSMENTS = 3\n",
        "\n",
        "    # ===========================\n",
        "    # üîÅ TEACH‚ÄìASSESS LOOP\n",
        "    # ===========================\n",
        "    while True:\n",
        "\n",
        "        # 1Ô∏è‚É£ Generate questions\n",
        "        state = generate_questions(state)\n",
        "\n",
        "        print(\"\\nGenerated Questions:\")\n",
        "        for i, q in enumerate(state[\"questions\"], 1):\n",
        "            print(f\"{i}. {q}\")\n",
        "\n",
        "        # 2Ô∏è‚É£ Collect answers\n",
        "        answers = []\n",
        "        for i, q in enumerate(state[\"questions\"], 1):\n",
        "            ans = read_multiline(f\"\\nAnswer for Q{i}: {q}\")\n",
        "            answers.append(ans)\n",
        "\n",
        "        state[\"learner_answers\"] = answers\n",
        "\n",
        "        # 3Ô∏è‚É£ Verify understanding\n",
        "        state = verify_understanding(state)\n",
        "\n",
        "        # 4Ô∏è‚É£ STRICT EXIT CONDITION\n",
        "        if state.get(\"pass_threshold_met\") and all_objectives_mastered(state):\n",
        "            print(\"\\n‚úÖ Passed! All concepts mastered.\")\n",
        "            break\n",
        "\n",
        "        # 5Ô∏è‚É£ Stop if max reteaching reached\n",
        "        if state.get(\"feynman_rounds\", 0) >= MAX_REASSESSMENTS:\n",
        "            print(\"\\n‚õî Maximum re-teaching attempts reached.\")\n",
        "            break\n",
        "\n",
        "        # 6Ô∏è‚É£ Feynman remediation\n",
        "        print(\"\\n‚ùå Score below threshold ‚Äî entering Feynman teaching mode\\n\")\n",
        "        state = feynman_node(state)\n",
        "\n",
        "        # 7Ô∏è‚É£ Re-process context so explanation affects next questions\n",
        "        state = process_context(state)\n",
        "\n",
        "        print(\"\\nüîÅ Re-attempting questions...\\n\")\n",
        "\n",
        "    # ---------------------------\n",
        "    # FINAL RESULT\n",
        "    # ---------------------------\n",
        "    return {\n",
        "        \"cp_id\": cp_id,\n",
        "        \"topic\": cp.topic,\n",
        "        \"context_score\": state.get(\"relevance_score_model\"),\n",
        "        \"quiz_score\": state.get(\"score_percent\"),\n",
        "        \"passed\": state.get(\"pass_threshold_met\") and all_objectives_mastered(state),\n",
        "        \"sources\": state.get(\"context_sources\"),\n",
        "        \"questions\": state.get(\"questions\"),\n",
        "        \"answers\": state.get(\"learner_answers\"),\n",
        "    }\n",
        "\n",
        "\n",
        "# Evaluation suite (automated tests for Q relevance & scoring)\n",
        "\n",
        "def _generate_good_answer_for_question(context: str, question: str) -> str:\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Use the CONTEXT below to write a concise, correct, and focused answer to the QUESTION.\n",
        "Answer must be at least 25 words (to avoid short-answer penalties) and at most 80 words.\n",
        "Keep it factual and directly relevant to the question.\n",
        "\n",
        "CONTEXT:\n",
        "\\\"\\\"\\\"{context[:3500]}\\\"\\\"\\\"\\n\n",
        "\n",
        "QUESTION:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "    raw = groq_chat(prompt)\n",
        "    txt = raw.strip()\n",
        "    words = re.findall(r\"\\w+\", txt)\n",
        "    if len([w for w in words if len(w) > 2]) < 15:\n",
        "        fallback = f\"Provide a direct, explanatory answer (>=25 words) to: {question}\\nUsing: {context[:800]}\"\n",
        "        raw2 = groq_chat(fallback)\n",
        "        txt = raw2.strip() or txt\n",
        "    return txt\n",
        "\n",
        "\n",
        "def run_evaluation_suite():\n",
        "    \"\"\"\n",
        "    Runs automated evaluation across all CHECKPOINTS.\n",
        "    For each checkpoint:\n",
        "      - gather/process/generate questions\n",
        "      - create 'good' answers via LLM (ensured to be long enough)\n",
        "      - create 'bad' answers (short/off-topic)\n",
        "      - run verify_understanding for both sets and record metrics\n",
        "    \"\"\"\n",
        "    overall = []\n",
        "    print(\"Running automated evaluation suite for all checkpoints...\\n\")\n",
        "    for cp in CHECKPOINTS:\n",
        "        # initialize state\n",
        "        state: AgentState = {\n",
        "            \"cp_id\": cp.id,\n",
        "            \"checkpoint\": None,\n",
        "            \"user_notes\": \"\",  # no notes; will use web search fallback\n",
        "            \"user_pdfs\": [],\n",
        "            \"gathered_context\": \"\",\n",
        "            \"context_sources\": [],\n",
        "            \"relevance_score_model\": None,\n",
        "            \"refetch_attempted\": False,\n",
        "            \"score_meta\": None,\n",
        "            \"processed_chunks\": [],\n",
        "            \"questions\": [],\n",
        "            \"learner_answers\": [],\n",
        "            \"score_percent\": None,\n",
        "            \"pass_threshold_met\": None,\n",
        "            \"temp_vector_store\": None,\n",
        "        }\n",
        "\n",
        "        state = start_checkpoint(state)\n",
        "        state = gather_context(state)\n",
        "        state = validate_context(state)\n",
        "        state = process_context(state)\n",
        "        state = generate_questions(state)\n",
        "\n",
        "        questions = state.get(\"questions\") or []\n",
        "        context_text = state.get(\"gathered_context\") or \"\\n\".join(state.get(\"processed_chunks\", [])) or \"\"\n",
        "        store = state.get(\"temp_vector_store\") or {\"chunks\": [], \"vectors\": None, \"meta\": {\"embeddings_used\": False}}\n",
        "\n",
        "        # Double-confirm embedding usage for this checkpoint\n",
        "        emb_used = bool(store.get(\"vectors\") is not None)\n",
        "        print(f\"[Eval] Checkpoint {cp.id} embeddings_used = {emb_used}\")\n",
        "        if emb_used:\n",
        "            try:\n",
        "                embedding_debug_print(store, label=f\"eval-cp={cp.id}\")\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # Build 'good' answers using the LLM (ensured to be long enough)\n",
        "        good_answers = []\n",
        "        for q in questions:\n",
        "            ans = _generate_good_answer_for_question(context_text, q)\n",
        "            if len(re.findall(r\"\\w+\", ans)) < 30:\n",
        "                ans = ans + \" \" + (\"This answer expands on the main points to ensure full coverage of the objective. \" * 2)\n",
        "            good_answers.append(ans)\n",
        "\n",
        "        # Build 'bad' answers (short/off-topic)\n",
        "        bad_answers = [\"I don't know.\" for _ in questions]\n",
        "\n",
        "        # Evaluate good answers\n",
        "        state_good = dict(state)\n",
        "        state_good[\"learner_answers\"] = good_answers\n",
        "        state_good = verify_understanding(state_good)\n",
        "        good_score = state_good.get(\"score_percent\") or 0.0\n",
        "        good_pass = state_good.get(\"pass_threshold_met\") or False\n",
        "\n",
        "        # Evaluate bad answers\n",
        "        state_bad = dict(state)\n",
        "        state_bad[\"learner_answers\"] = bad_answers\n",
        "        state_bad = verify_understanding(state_bad)\n",
        "        bad_score = state_bad.get(\"score_percent\") or 0.0\n",
        "        bad_pass = state_bad.get(\"pass_threshold_met\") or False\n",
        "\n",
        "        q_rel = 1.0 if questions else 0.0\n",
        "\n",
        "        overall.append({\n",
        "            \"cp_id\": cp.id,\n",
        "            \"topic\": cp.topic,\n",
        "            \"num_questions\": len(questions),\n",
        "            \"q_rel\": q_rel,\n",
        "            \"context_score\": state.get(\"relevance_score_model\"),\n",
        "            \"good_score\": good_score,\n",
        "            \"good_pass\": good_pass,\n",
        "            \"bad_score\": bad_score,\n",
        "            \"bad_pass\": bad_pass,\n",
        "            \"embeddings_used\": emb_used,\n",
        "        })\n",
        "\n",
        "    # Print summary\n",
        "    print(\"\\n=== Evaluation Summary ===\\n\")\n",
        "    total_q_rel = 0.0\n",
        "    good_pass_count = 0\n",
        "    bad_fail_count = 0\n",
        "    emb_used_count = 0\n",
        "    for r in overall:\n",
        "        print(f\"Checkpoint: {r['cp_id']} - {r['topic']}\")\n",
        "        print(f\"  Questions: {r['num_questions']}, Q-rel: {r['q_rel']:.2f}\")\n",
        "        print(f\"  Context score (1-5): {r['context_score']}\")\n",
        "        print(f\"  Good answers -> score: {r['good_score']:.1f}%, pass: {r['good_pass']}\")\n",
        "        print(f\"  Bad answers  -> score: {r['bad_score']:.1f}%, pass: {r['bad_pass']}\")\n",
        "        print(f\"  Embeddings used: {r.get('embeddings_used')}\")\n",
        "        print()\n",
        "        total_q_rel += r['q_rel']\n",
        "        if r['good_pass']:\n",
        "            good_pass_count += 1\n",
        "        if not r['bad_pass']:\n",
        "            bad_fail_count += 1\n",
        "        if r.get('embeddings_used'):\n",
        "            emb_used_count += 1\n",
        "\n",
        "    n = len(overall) or 1\n",
        "    print(\"--- Overall Metrics ---\")\n",
        "    print(f\"Average question relevance (fraction): {total_q_rel / n:.3f}\")\n",
        "    print(f\"Good answers pass-rate (should be high): {good_pass_count / n * 100:.1f}%\")\n",
        "    print(f\"Bad answers fail-rate (should be high): {bad_fail_count / n * 100:.1f}%\")\n",
        "    print(f\"Embeddings used in checkpoints: {emb_used_count}/{n}\\n\")\n",
        "\n",
        "    return overall\n",
        "\n",
        "\n",
        "\n",
        "# Interactive run for multiple checkpoints\n",
        "\n",
        "def interactive_run():\n",
        "    print(\"Interactive Milestone 2 runner.\")\n",
        "    print(\"Available checkpoints:\")\n",
        "    for cp in CHECKPOINTS:\n",
        "        print(f\" - {cp.id}: {cp.topic}\")\n",
        "\n",
        "    chosen = input(\"Enter comma-separated checkpoint ids to run (or 'all'): \").strip()\n",
        "    if chosen.lower() == \"all\" or not chosen:\n",
        "        ids = [cp.id for cp in CHECKPOINTS]\n",
        "    else:\n",
        "        ids = [c.strip() for c in chosen.split(\",\") if c.strip()]\n",
        "\n",
        "    results = []\n",
        "    for cp_id in ids:\n",
        "        try:\n",
        "            res = run_single_checkpoint_interactive(cp_id)\n",
        "            results.append(res)\n",
        "        except Exception as e:\n",
        "            print(f\"Error running {cp_id}: {e}\")\n",
        "\n",
        "    # Build markdown summary table\n",
        "    lines = []\n",
        "    lines.append(\"### Summary Table\\n\")\n",
        "    lines.append(\"| Topic | Objectives | Sources | Context Score (1‚Äì5) | Quiz Score (%) | Pass (>=70%) |\")\n",
        "    lines.append(\"|-------|------------|---------|---------------------|----------------|--------------|\")\n",
        "    for r in results:\n",
        "        cp = get_checkpoint_by_id(r[\"cp_id\"])\n",
        "        obj_list = [f\"- {o}\" for o in cp.objectives]\n",
        "        objectives_str = \"<br>\".join(obj_list)\n",
        "        sources_str = \", \".join(r[\"sources\"]) if r[\"sources\"] else \"None\"\n",
        "        context_score = r[\"context_score\"]\n",
        "        quiz_score = r[\"quiz_score\"]\n",
        "        quiz_display = \"-\" if quiz_score is None else f\"{quiz_score:.1f}\"\n",
        "        passed = r[\"passed\"]\n",
        "        passed_str = \"‚úÖ\" if passed else (\"‚ùå\" if passed is not None else \"-\")\n",
        "        lines.append(f\"| {r['topic']} | {objectives_str} | {sources_str} | {context_score} | {quiz_display} | {passed_str} |\")\n",
        "\n",
        "    table_md = \"\\n\".join(lines)\n",
        "    try:\n",
        "        display(Markdown(table_md))\n",
        "    except Exception:\n",
        "        print(table_md)\n",
        "\n",
        "    # Save ALL raw LLM prompt+response logs into ONE PDF\n",
        "    save_all_raw_to_one_pdf(\"all_llm_raw_output.pdf\")\n",
        "\n",
        "\n",
        "# Main\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Milestone 1 & 2 runner\")\n",
        "    print(\"Options:\\n  1) interactive run (generate questions & answer interactively)\\n  2) run evaluation suite (automated tests for Q relevance & scoring)\")\n",
        "    choice = input(\"Enter 1 or 2 (default 1): \").strip() or \"1\"\n",
        "    if choice == \"2\":\n",
        "        run_evaluation_suite()\n",
        "    else:\n",
        "        interactive_run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOSycZrLf0-m"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqJy5F3lopcE",
        "outputId": "0bcd4315-9c27-4bdf-d88f-3851619850c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "from backend import (\n",
        "    CHECKPOINTS,\n",
        "    get_checkpoint_by_id,\n",
        "    start_checkpoint,\n",
        "    gather_context,\n",
        "    validate_context,\n",
        "    process_context,\n",
        "    generate_questions,\n",
        "    verify_understanding,\n",
        "    feynman_node,\n",
        ")\n",
        "\n",
        "# ======================================================\n",
        "# CONFIG\n",
        "# ======================================================\n",
        "st.set_page_config(page_title=\"Adaptive AI Tutor\", layout=\"wide\")\n",
        "\n",
        "MAX_FEYNMAN_ROUNDS = 3  # maximum attempts\n",
        "\n",
        "# ======================================================\n",
        "# GLOBAL STYLES\n",
        "# ======================================================\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "html, body {\n",
        "    background-color: #0b0f19;\n",
        "    color: #e5e7eb;\n",
        "    font-family: Inter, system-ui, sans-serif;\n",
        "}\n",
        ".card {\n",
        "    background: rgba(255,255,255,0.05);\n",
        "    padding: 1.5rem;\n",
        "    border-radius: 14px;\n",
        "    margin-bottom: 1.2rem;\n",
        "}\n",
        ".good { box-shadow: 0 0 25px rgba(34,197,94,0.85); }\n",
        ".bad  { box-shadow: 0 0 25px rgba(239,68,68,0.85); }\n",
        ".title { font-size: 2rem; font-weight: 700; }\n",
        ".subtitle { color: #9ca3af; }\n",
        ".score-big { font-size: 3rem; font-weight: 800; }\n",
        ".attempts {\n",
        "    font-size: 0.95rem;\n",
        "    color: #fbbf24;\n",
        "    margin-top: 0.5rem;\n",
        "}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# ======================================================\n",
        "# SESSION STATE\n",
        "# ======================================================\n",
        "if \"phase\" not in st.session_state:\n",
        "    st.session_state.phase = \"context\"\n",
        "\n",
        "if \"state\" not in st.session_state:\n",
        "    st.session_state.state = None\n",
        "\n",
        "if \"questions\" not in st.session_state:\n",
        "    st.session_state.questions = []\n",
        "\n",
        "if \"answers\" not in st.session_state:\n",
        "    st.session_state.answers = []\n",
        "\n",
        "if \"attempt_id\" not in st.session_state:\n",
        "    st.session_state.attempt_id = 0\n",
        "\n",
        "# ======================================================\n",
        "# SIDEBAR\n",
        "# ======================================================\n",
        "st.sidebar.markdown(\"## üß≠ Learning Path\")\n",
        "\n",
        "checkpoint_options = [\"__custom__\"] + [c.id for c in CHECKPOINTS]\n",
        "\n",
        "cp_id = st.sidebar.selectbox(\n",
        "    \"Checkpoint\",\n",
        "    checkpoint_options,\n",
        "    format_func=lambda x: (\n",
        "        \"‚ûï Custom Topic\"\n",
        "        if x == \"__custom__\"\n",
        "        else f\"{x} ‚Äî {get_checkpoint_by_id(x).topic}\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n",
        "if st.sidebar.button(\"üîÑ Reset Session\"):\n",
        "    st.session_state.clear()\n",
        "    st.rerun()\n",
        "\n",
        "cp = None\n",
        "if cp_id != \"__custom__\":\n",
        "    cp = get_checkpoint_by_id(cp_id)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "custom_topic = None\n",
        "if cp_id == \"__custom__\":\n",
        "    custom_topic = st.sidebar.text_input(\n",
        "        \"Enter topic name\",\n",
        "        placeholder=\"e.g. Newton's Laws of Motion\",\n",
        "    )\n",
        "# ======================================================\n",
        "# HEADER\n",
        "# ======================================================\n",
        "st.markdown(f\"\"\"\n",
        "<div class=\"card\">\n",
        "  <div class=\"title\">üß† Adaptive AI Tutor</div>\n",
        "  <div class=\"subtitle\">\n",
        "    {custom_topic if (cp_id == \"__custom__\" and custom_topic) else (cp.topic if cp else \"\")}\n",
        "\n",
        "</div>\n",
        "\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# ======================================================\n",
        "# OBJECTIVES\n",
        "# ======================================================\n",
        "with st.expander(\"üéØ Learning Objectives\", expanded=True):\n",
        "    st.markdown(\"<div class='card'>\", unsafe_allow_html=True)\n",
        "\n",
        "    if cp_id != \"__custom__\":\n",
        "        for o in cp.objectives:\n",
        "            st.markdown(f\"- {o}\")\n",
        "    else:\n",
        "        generated_cp = st.session_state.state.get(\"checkpoint\") if st.session_state.state else None\n",
        "        if generated_cp and getattr(generated_cp, \"objectives\", None):\n",
        "            for o in generated_cp.objectives:\n",
        "                st.markdown(f\"- {o}\")\n",
        "        else:\n",
        "            st.markdown(\"- Objectives will be generated automatically\")\n",
        "\n",
        "    st.markdown(\"</div>\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "# ======================================================\n",
        "# PHASE 1 ‚Äî CONTEXT\n",
        "# ======================================================\n",
        "if st.session_state.phase == \"context\":\n",
        "\n",
        "    notes = st.text_area(\"Your notes (optional)\", height=160)\n",
        "\n",
        "    load_disabled = (cp_id == \"__custom__\" and not custom_topic)\n",
        "    if cp_id == \"__custom__\" and not custom_topic:\n",
        "      st.warning(\"‚ö†Ô∏è Please enter a topic name to load content\")\n",
        "\n",
        "    if st.button(\"üìö Load Content\", disabled=load_disabled):\n",
        "\n",
        "        state = {\n",
        "            \"cp_id\": cp_id,\n",
        "            \"custom_topic\": custom_topic,\n",
        "            \"checkpoint\": None,\n",
        "            \"user_notes\": notes,\n",
        "            \"user_pdfs\": [],\n",
        "            \"gathered_context\": \"\",\n",
        "            \"context_sources\": [],\n",
        "            \"processed_chunks\": [],\n",
        "            \"questions\": [],\n",
        "            \"learner_answers\": [],\n",
        "            \"score_percent\": None,\n",
        "            \"pass_threshold_met\": None,\n",
        "            \"question_scores\": [],\n",
        "            \"temp_vector_store\": None,\n",
        "            \"feynman_explanation\": None,\n",
        "            \"feynman_rounds\": 0,\n",
        "            \"focus_concepts\": None,\n",
        "            \"failed_objectives\": [],\n",
        "            \"refetch_attempted\": False,\n",
        "        }\n",
        "\n",
        "        state = start_checkpoint(state)\n",
        "        state = gather_context(state)\n",
        "        state = validate_context(state)\n",
        "        state = process_context(state)\n",
        "\n",
        "        st.session_state.state = state\n",
        "        st.session_state.attempt_id = 0\n",
        "        st.rerun()\n",
        "\n",
        "    if st.session_state.state and st.session_state.state.get(\"gathered_context\"):\n",
        "        st.markdown(\"<div class='card'>\", unsafe_allow_html=True)\n",
        "        st.text_area(\n",
        "            \"Learning Content\",\n",
        "            st.session_state.state[\"gathered_context\"],\n",
        "            height=380,\n",
        "        )\n",
        "        st.markdown(\"</div>\", unsafe_allow_html=True)\n",
        "\n",
        "        if st.button(\"üìù Take Test\"):\n",
        "            s = generate_questions(st.session_state.state)\n",
        "            st.session_state.state = s\n",
        "            st.session_state.questions = s[\"questions\"]\n",
        "            st.session_state.answers = [\"\"] * len(s[\"questions\"])\n",
        "            st.session_state.phase = \"test\"\n",
        "            st.rerun()\n",
        "\n",
        "# ======================================================\n",
        "# PHASE 2 ‚Äî TEST\n",
        "# ======================================================\n",
        "if st.session_state.phase == \"test\":\n",
        "\n",
        "    s = st.session_state.state\n",
        "    attempts_left = max(0, MAX_FEYNMAN_ROUNDS - s.get(\"feynman_rounds\", 0))  # ‚≠ê NEW\n",
        "\n",
        "    st.markdown(\n",
        "        f\"<div class='card attempts'>üîÅ Attempts left: <b>{attempts_left}</b></div>\",\n",
        "        unsafe_allow_html=True\n",
        "    )\n",
        "\n",
        "    for i, q in enumerate(st.session_state.questions):\n",
        "        st.markdown(\n",
        "            f\"<div class='card'>‚ùì <b>Q{i+1}</b>: {q}</div>\",\n",
        "            unsafe_allow_html=True\n",
        "        )\n",
        "        st.session_state.answers[i] = st.text_area(\n",
        "            \"\",\n",
        "            key=f\"a{st.session_state.attempt_id}_{i}\",\n",
        "            height=120,\n",
        "        )\n",
        "\n",
        "    if st.button(\"‚úÖ Submit Answers\"):\n",
        "        state = dict(st.session_state.state)\n",
        "        state[\"learner_answers\"] = st.session_state.answers\n",
        "\n",
        "        state = verify_understanding(state)\n",
        "        if not state.get(\"pass_threshold_met\"):\n",
        "          state[\"last_attempt_score\"] = state.get(\"score_percent\")\n",
        "        if (\n",
        "            not state.get(\"pass_threshold_met\")\n",
        "            and state.get(\"feynman_rounds\", 0) < MAX_FEYNMAN_ROUNDS\n",
        "        ):\n",
        "            state = feynman_node(state)\n",
        "\n",
        "        st.session_state.state = state\n",
        "        st.session_state.phase = \"result\"\n",
        "        st.rerun()\n",
        "\n",
        "# ======================================================\n",
        "# PHASE 3 ‚Äî RESULT\n",
        "# ======================================================\n",
        "if st.session_state.phase == \"result\":\n",
        "\n",
        "    s = st.session_state.state\n",
        "    overall = (\n",
        "    s.get(\"score_percent\")\n",
        "    if s.get(\"score_percent\") is not None\n",
        "    else s.get(\"last_attempt_score\", 0)\n",
        ")\n",
        "\n",
        "    q_scores = s.get(\"question_scores\") or []\n",
        "    attempts_left = max(0, MAX_FEYNMAN_ROUNDS - s.get(\"feynman_rounds\", 0))  # ‚≠ê NEW\n",
        "\n",
        "    passed = bool(s.get(\"pass_threshold_met\"))\n",
        "    glow = \"good\" if passed else \"bad\"\n",
        "    emoji = \"üéâüòÑ\" if passed else \"üòï‚ùå\"\n",
        "\n",
        "    st.markdown(f\"\"\"\n",
        "    <div class=\"card {glow}\">\n",
        "        <div class=\"score-big\">{overall:.1f}%</div>\n",
        "        <div>{emoji} Overall Performance</div>\n",
        "        <div class=\"attempts\">üîÅ Attempts left: <b>{attempts_left}</b></div>\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"### üìä Question-wise Feedback\")\n",
        "    for i, qs in enumerate(q_scores, 1):\n",
        "        score = qs[\"score\"]\n",
        "        st.markdown(\n",
        "            f\"<div class='card'><b>Q{i}:</b> {score}% {'‚úÖ' if score >= 70 else '‚ùå'}</div>\",\n",
        "            unsafe_allow_html=True\n",
        "        )\n",
        "\n",
        "    if not passed and attempts_left > 0:\n",
        "        st.markdown(\"### üß† Simplified Explanation\")\n",
        "        st.info(s.get(\"feynman_explanation\", \"Explanation unavailable.\"))\n",
        "\n",
        "        if st.button(\"üîÅ Try Again\"):\n",
        "            st.session_state.attempt_id += 1\n",
        "\n",
        "            retry_state = dict(s)\n",
        "\n",
        "            # üî• REQUIRED RESET\n",
        "            retry_state[\"feynman_explanation\"] = None\n",
        "\n",
        "\n",
        "\n",
        "            retry_state = generate_questions(retry_state)\n",
        "\n",
        "            st.session_state.state = retry_state\n",
        "            st.session_state.questions = retry_state[\"questions\"]\n",
        "            st.session_state.answers = [\"\"] * len(retry_state[\"questions\"])\n",
        "            st.session_state.phase = \"test\"\n",
        "            st.rerun()\n",
        "\n",
        "\n",
        "    elif not passed:\n",
        "        st.error(\"‚õî No attempts left. Please reset or move on.\")\n",
        "\n",
        "    else:\n",
        "        st.balloons()\n",
        "        st.success(\"üéâ Mastered! You passed this checkpoint.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "1sB3Z1947Pre"
      },
      "outputs": [],
      "source": [
        "!nohup streamlit run app.py \\\n",
        "  --server.port 8501 \\\n",
        "  --server.address 0.0.0.0 \\\n",
        "  > /content/streamlit.log 2>&1 &\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZQlcskQiSJx",
        "outputId": "22e04fbe-6603-42fb-8e77-d1d6a48e253d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "COMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n",
            "streamlit 484 root    6u  IPv4  29171      0t0  TCP *:8501 (LISTEN)\n"
          ]
        }
      ],
      "source": [
        "!lsof -i :8501\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "WeceIQxqa3Hz"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.kill()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3D4-_mchvCQ",
        "outputId": "2cfcfbf8-272b-4054-f059-3d39bb063a0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üåç Streamlit Public URL: NgrokTunnel: \"https://unflushed-hailee-unaccorded.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"üåç Streamlit Public URL:\", public_url)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
