{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a01cfa1-cc36-47ea-a79c-3bf75a61d0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Groq API Key:  ········\n",
      "Enter LangSmith API Key:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Configured successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "# 1. Groq API \n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter Groq API Key: \")\n",
    "\n",
    "# 2. LangSmith\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"AI-Tutor-Groq\"\n",
    "\n",
    "if \"LANGCHAIN_API_KEY\" not in os.environ:\n",
    "    key_input = getpass.getpass(\"Enter LangSmith API Key: \")\n",
    "    if key_input:\n",
    "        os.environ[\"LANGCHAIN_API_KEY\"] = key_input\n",
    "\n",
    "print(\"Environment Configured successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40352286-26fe-4ca8-be8b-375c7ffda9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Chittesh\\anaconda3\\envs\\Agent_Project\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Model Configured: llama-3.3-70b-versatile (via Groq)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, TypedDict, Optional\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# MODEL CONFIGURATION\n",
    "MODEL_NAME = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=MODEL_NAME,\n",
    "    temperature=0.3,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "web_search = DuckDuckGoSearchRun()\n",
    "\n",
    "# DATA SCHEMA\n",
    "class Checkpoint(BaseModel):\n",
    "    id: int = Field(description=\"The checkpoint number (1-5)\")\n",
    "    topic: str = Field(description=\"The main title of the sub-topic\")\n",
    "    objective: str = Field(description=\"A concise learning objective for this checkpoint\")\n",
    "\n",
    "class StudyPlan(BaseModel):\n",
    "    topic: str = Field(description=\"The main subject requested by the user\")\n",
    "    checkpoints: List[Checkpoint] = Field(description=\"List of 5 generated learning checkpoints\")\n",
    "\n",
    "# STATE DEFINITION\n",
    "class AgentState(TypedDict):\n",
    "    main_topic: str\n",
    "    file_path: Optional[str]\n",
    "    study_plan: List[dict]\n",
    "    current_checkpoint: dict\n",
    "    topic: str\n",
    "    objective: str\n",
    "\n",
    "    # Document & Context Storage\n",
    "    documents: List[Document]\n",
    "    doc_context: str\n",
    "    web_context: str\n",
    "    \n",
    "    # Logic Flags\n",
    "    source: str\n",
    "    validation_status: str\n",
    "    needs_web_search: bool\n",
    "\n",
    "    # Quiz & Adaptation Logic\n",
    "    quiz_questions: List[str]\n",
    "    user_answers: List[str]\n",
    "    quiz_results: List[dict]    \n",
    "    failed_concepts: List[str]  \n",
    "    quiz_score: int            \n",
    "\n",
    "    # Output Storage\n",
    "    final_essay: str\n",
    "    quiz_feedback: str\n",
    "\n",
    "    # Retry & Evaluation\n",
    "    retries: int\n",
    "    best_score: int\n",
    "    best_essay: str\n",
    "\n",
    "print(f\"Model Configured: {MODEL_NAME} (via Groq)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af54023e-97fd-42a8-9198-4ea1335cb058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Curriculum Planning Node\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "def plan_curriculum(state: AgentState):\n",
    "    print(f\"GENERATING STUDY PLAN FOR: {state['main_topic']}\")\n",
    "    \n",
    "    parser = PydanticOutputParser(pydantic_object=StudyPlan)\n",
    "    \n",
    "    # Check if we have a document context loaded in the state\n",
    "    doc_context = state.get(\"doc_context\", \"\")\n",
    "    context_instruction = \"\"\n",
    "    \n",
    "    # Only verify doc usage if actual text exists\n",
    "    if doc_context and len(doc_context) > 10: \n",
    "        context_instruction = (\n",
    "            \"CONTEXT FROM USER DOCUMENT:\\n\"\n",
    "            f\"{doc_context[:1500]}\\n\" \n",
    "            \"INSTRUCTION: Base the checkpoints strictly on the structure/chapters \"\n",
    "            \"provided in the context above.\"\n",
    "        )\n",
    "    else:\n",
    "        context_instruction = \"Generate the plan based on general web knowledge.\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert Curriculum Designer.\n",
    "    Create a structured 5-part study plan for the topic: \"{state['main_topic']}\".\n",
    "    \n",
    "    {context_instruction}\n",
    "    \n",
    "    REQUIREMENTS:\n",
    "    1. Break the topic into exactly 5 logical progression steps (Checkpoints).\n",
    "    2. For each checkpoint, provide a Title and a specific Learning Objective.\n",
    "    3. Ensure the difficulty increases from Checkpoint 1 to 5.\n",
    "    \n",
    "    FORMAT INSTRUCTION:\n",
    "    {parser.get_format_instructions()}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "        parsed_plan = parser.parse(response.content)\n",
    "        \n",
    "        # Convert Pydantic models to regular dicts for state storage\n",
    "        plan_dicts = [cp.dict() for cp in parsed_plan.checkpoints]\n",
    "        return {\"study_plan\": plan_dicts}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating plan: {e}\")\n",
    "        # Fallback Plan if LLM fails\n",
    "        return {\"study_plan\": [\n",
    "            {\"id\": 1, \"topic\": f\"{state['main_topic']} Basics\", \"objective\": \"Introduction to core concepts\"},\n",
    "            {\"id\": 2, \"topic\": \"Key Mechanisms\", \"objective\": \"Understanding how it works\"},\n",
    "            {\"id\": 3, \"topic\": \"Advanced Concepts\", \"objective\": \"Deep dive into complexities\"},\n",
    "            {\"id\": 4, \"topic\": \"Applications\", \"objective\": \"Real-world use cases\"},\n",
    "            {\"id\": 5, \"topic\": \"Current State & Future\", \"objective\": \"State of the art analysis\"}\n",
    "        ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9866e3d8-bc1c-4d8b-8df5-0eed78a38ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What do you want to learn?  deep learning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document detected: notes.pdf\n",
      "Loading content into memory...\n",
      "Successfully loaded 3312 characters.\n",
      "\n",
      "Consulting Curriculum Designer...\n",
      "GENERATING STUDY PLAN FOR: deep learning\n",
      "\n",
      "STUDY PLAN FOR: DEEP LEARNING\n",
      "1. Introduction to Artificial Neural Networks\n",
      "   Objective: Understand the basic architecture and components of Artificial Neural Networks, including input, hidden, and output layers.\n",
      "2. Forward and Backward Propagation in ANNs\n",
      "   Objective: Learn how forward propagation calculates the output and backward propagation updates weights to minimize loss in Artificial Neural Networks.\n",
      "3. Introduction to Convolutional Neural Networks\n",
      "   Objective: Comprehend the basic structure and key components of Convolutional Neural Networks, including convolutional layers and their application to grid-like data.\n",
      "4. Advanced Concepts in Convolutional Neural Networks\n",
      "   Objective: Delve deeper into the specifics of Convolutional Neural Networks, including the role of filters, kernels, and the preservation of spatial relationships in image processing.\n",
      "5. Applying Deep Learning Concepts to Real-World Problems\n",
      "   Objective: Apply knowledge of Artificial Neural Networks and Convolutional Neural Networks to solve complex, real-world problems, including image classification and pattern recognition tasks.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select a Checkpoint to start (1-5):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected: Introduction to Convolutional Neural Networks\n"
     ]
    }
   ],
   "source": [
    "# Cell 4\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\".*The `dict` method is deprecated.*\")\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 1. GET USER INPUT\n",
    "main_topic_input = input(\"What do you want to learn? \")\n",
    "\n",
    "# DETECT AND LOAD DOCUMENT\n",
    "documents_loaded = []\n",
    "full_text = \"\" \n",
    "file_input = None\n",
    "\n",
    "if os.path.exists(\"notes.pdf\"):\n",
    "    file_input = \"notes.pdf\"\n",
    "    print(f\"Document detected: {file_input}\")\n",
    "    \n",
    "    try:\n",
    "        print(\"Loading content into memory...\")\n",
    "        loader = PyPDFLoader(file_input)\n",
    "        pages = loader.load()\n",
    "        \n",
    "        full_text = \"\\n\\n\".join([p.page_content for p in pages])\n",
    "        \n",
    "        documents_loaded = [Document(page_content=full_text, metadata={\"source\": \"user_upload\"})]\n",
    "        print(f\"Successfully loaded {len(full_text)} characters.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF: {e}\")\n",
    "else:\n",
    "    print(\"No 'notes.pdf' found. Proceeding without document.\")\n",
    "\n",
    "initial_state = {\n",
    "    \"main_topic\": main_topic_input,\n",
    "    \"file_path\": file_input, \n",
    "    \"documents\": documents_loaded, \n",
    "    \n",
    "    \"study_plan\": [],\n",
    "    \"current_checkpoint\": {},\n",
    "    \"topic\": \"\", \n",
    "    \"objective\": \"\", \n",
    "    \n",
    "    \"doc_context\": full_text, \n",
    "    \n",
    "    \"web_context\": \"\", \n",
    "    \"final_essay\": \"\", \n",
    "    \"quiz_questions\": [], \n",
    "    \"user_answers\": [], \n",
    "    \"quiz_score\": 0, \n",
    "    \"quiz_feedback\": \"\",\n",
    "    \"needs_web_search\": False, \n",
    "    \"retries\": 0, \n",
    "    \"best_score\": 0, \n",
    "    \"best_essay\": \"\",\n",
    "    \"source\": \"\", \n",
    "    \"validation_status\": \"\",\n",
    "    \"failed_concepts\": []\n",
    "}\n",
    "\n",
    "# 2. GENERATE THE PLAN\n",
    "print(\"\\nConsulting Curriculum Designer...\")\n",
    "plan_result = plan_curriculum(initial_state)\n",
    "study_plan = plan_result[\"study_plan\"]\n",
    "\n",
    "# 3. DISPLAY & SELECT\n",
    "print(f\"\\nSTUDY PLAN FOR: {main_topic_input.upper()}\")\n",
    "for cp in study_plan:\n",
    "    print(f\"{cp['id']}. {cp['topic']}\")\n",
    "    print(f\"   Objective: {cp['objective']}\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        choice = int(input(\"Select a Checkpoint to start (1-5): \"))\n",
    "        if 1 <= choice <= 5:\n",
    "            selected_cp = study_plan[choice-1]\n",
    "            print(f\"\\nSelected: {selected_cp['topic']}\")\n",
    "            \n",
    "            # UPDATE STATE FOR THE REST OF THE APP\n",
    "            initial_state[\"topic\"] = selected_cp[\"topic\"]\n",
    "            initial_state[\"objective\"] = selected_cp[\"objective\"]\n",
    "            initial_state[\"study_plan\"] = study_plan\n",
    "            initial_state[\"current_checkpoint\"] = selected_cp\n",
    "            break\n",
    "        print(\"Invalid choice. Please enter 1-5.\")\n",
    "    except ValueError:\n",
    "        print(\"Please enter a number.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee199a09-72c4-444d-8fdd-7b1e9273de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5\n",
    "import json\n",
    "import re\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def check_user_doc_and_grade(state):\n",
    "    topic = state.get('topic', 'Unknown')\n",
    "    objective = state.get('objective', 'General understanding')\n",
    "    documents = state.get(\"documents\", [])\n",
    "    \n",
    "    print(f\"CHECKING USER DOCUMENT FOR TOPIC: {topic}\")\n",
    "\n",
    "    # 1. INSTANT FAIL: No documents uploaded\n",
    "    if not documents:\n",
    "        print(\"No user document found. Proceeding to Web Search.\")\n",
    "        return {\n",
    "            \"source\": \"web_search\", \n",
    "            \"validation_status\": \"needs_search\"\n",
    "        }\n",
    "\n",
    "    # 2. PREPARE CONTENT FOR GRADING\n",
    "    doc_snippet = documents[0].page_content[:3000]\n",
    "    \n",
    "    # 3. LLM GRADING PROMPT\n",
    "    prompt = f\"\"\"\n",
    "    You are a Teacher's Assistant. Grade the relevance of the following document excerpt.\n",
    "    \n",
    "    STUDENT TOPIC: \"{topic}\"\n",
    "    LEARNING OBJECTIVE: \"{objective}\"\n",
    "    \n",
    "    DOCUMENT EXCERPT:\n",
    "    {doc_snippet}...\n",
    "    \n",
    "    TASK:\n",
    "    Determine if this document contains SUFFICIENT information to teach the topic.\n",
    "    \n",
    "    CRITERIA:\n",
    "    - SUFFICIENT: The document covers the topic well. No web search needed.\n",
    "    - INCOMPLETE: The document mentions the topic but lacks detail/depth. Needs web search to fill gaps.\n",
    "    - IRRELEVANT: The document is about something else entirely. Needs full web search.\n",
    "    \n",
    "    Return JSON ONLY: {{\"status\": \"SUFFICIENT\" | \"INCOMPLETE\" | \"IRRELEVANT\"}}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "        \n",
    "        # Parse JSON output\n",
    "        json_match = re.search(r\"\\{.*\\}\", response.content, re.DOTALL)\n",
    "        if json_match:\n",
    "            data = json.loads(json_match.group(0))\n",
    "            status = data.get(\"status\", \"IRRELEVANT\").upper()\n",
    "        else:\n",
    "            status = \"IRRELEVANT\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   -> Grading Error: {e}. Defaulting to Search.\")\n",
    "        status = \"IRRELEVANT\"\n",
    "\n",
    "    # 4. DECISION LOGIC\n",
    "    print(f\"Document Grade: {status}\")\n",
    "\n",
    "    if status == \"SUFFICIENT\":\n",
    "        print(\"Document is sufficient. Skipping Web Search.\")\n",
    "        return {\n",
    "            \"source\": \"user_doc\", \n",
    "            \"validation_status\": \"relevant\"\n",
    "        }\n",
    "        \n",
    "    elif status == \"INCOMPLETE\":\n",
    "        print(\"Document is incomplete. Will use Web Search to supplement.\")\n",
    "        # 'mixed' source tells the generator to use both PDF and Web results\n",
    "        return {\n",
    "            \"source\": \"mixed\", \n",
    "            \"validation_status\": \"needs_search\"\n",
    "        }\n",
    "        \n",
    "    else: # IRRELEVANT\n",
    "        print(\"Document is irrelevant. Will perform fresh Web Search.\")\n",
    "        return {\n",
    "            \"source\": \"web_search\", \n",
    "            \"validation_status\": \"needs_search\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3764eaa-df44-407a-936d-8a8bc2410d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Web Search\n",
    "def perform_web_search(state):\n",
    "    topic = state.get('topic', 'Unknown')\n",
    "    current_source = state.get('source', 'web_search')\n",
    "    print(f\"SEARCHING WEB FOR: {topic} (Mode: {current_source})\")\n",
    "    \n",
    "    try:\n",
    "        # Perform the search\n",
    "        search_result_text = web_search.invoke(topic)\n",
    "        print(\"Search completed successfully.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Search failed: {e}\")\n",
    "        search_result_text = \"Web search failed or returned no results.\"\n",
    "\n",
    "    return {\"web_context\": search_result_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df91fbc9-c920-41c9-93ec-5d98b14e9cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Generate Essay\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def generate_essay(state):\n",
    "    topic = state.get(\"topic\")\n",
    "    objective = state.get(\"objective\")\n",
    "    source_mode = state.get(\"source\", \"web_search\")\n",
    "    \n",
    "    # 1. CONTEXT SELECTION LOGIC\n",
    "    user_text = state.get(\"doc_context\", \"\")\n",
    "    web_text = state.get(\"web_context\", \"\")\n",
    "    final_context = \"\"\n",
    "\n",
    "    if source_mode == \"user_doc\":\n",
    "        print(\"GENERATOR: Using strictly User Document.\")\n",
    "        final_context = f\"SOURCE MATERIAL (User Notes):\\n{user_text[:15000]}\" \n",
    "        \n",
    "    elif source_mode == \"web_search\":\n",
    "        print(\"GENERATOR: Using strictly Web Search.\")\n",
    "        final_context = f\"SOURCE MATERIAL (Web Search):\\n{web_text}\"\n",
    "        \n",
    "    elif source_mode == \"mixed\":\n",
    "        print(\"GENERATOR: Using Hybrid Context (User Notes + Web).\")\n",
    "        final_context = (\n",
    "            f\"PRIMARY SOURCE (User Notes):\\n{user_text[:10000]}\\n\\n\"\n",
    "            f\"SUPPLEMENTARY SOURCE (Web Search):\\n{web_text}\"\n",
    "        )\n",
    "    \n",
    "    # 2. GENERATE ESSAY\n",
    "    print(f\"GENERATING ESSAY FOR: {topic}\")\n",
    "    essay_prompt = f\"\"\"\n",
    "    You are an expert tutor teaching: \"{topic}\"\n",
    "    Objective: \"{objective}\"\n",
    "    \n",
    "    INSTRUCTIONS:\n",
    "    Write a comprehensive, clear, and engaging educational guide (approx 400-600 words).\n",
    "    Base your teaching STRICTLY on the Source Material provided below.\n",
    "    If the User Notes are unclear, use the Web Search context to clarify, but prioritize user notes.\n",
    "    \n",
    "    {final_context}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        essay_response = llm.invoke([HumanMessage(content=essay_prompt)])\n",
    "        essay_content = essay_response.content\n",
    "    except Exception as e:\n",
    "        print(f\"Essay Gen Error: {e}\")\n",
    "        essay_content = \"Error generating content.\"\n",
    "\n",
    "    return {\n",
    "        \"final_essay\": essay_content\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3df67eae-ee8a-4df1-bb34-d7892673136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8\n",
    "import re\n",
    "import json\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def grade_essay(state):\n",
    "    print(\"GRADING ESSAY AGAINST OBJECTIVE\")\n",
    "    \n",
    "    essay = state.get(\"final_essay\", \"\")\n",
    "    topic = state.get(\"topic\", \"\")\n",
    "    objective = state.get(\"objective\", \"\")\n",
    "    current_retries = state.get(\"retries\", 0)\n",
    "    best_score_so_far = state.get(\"best_score\", 0)\n",
    "    \n",
    "    if \"Error generating essay\" in essay or len(essay) < 100:\n",
    "        print(\"Generation failed or extremely short.\")\n",
    "        return {\n",
    "            \"best_score\": best_score_so_far,\n",
    "            \"retries\": current_retries + 1,\n",
    "        }\n",
    "\n",
    "    # Validator Prompt\n",
    "    prompt = f\"\"\"\n",
    "    You are a Quality Control Editor.\n",
    "    \n",
    "    TARGET TOPIC: {topic}\n",
    "    REQUIRED OBJECTIVE: {objective}\n",
    "    \n",
    "    DRAFT LESSON:\n",
    "    {essay[:2000]}... [truncated]\n",
    "    \n",
    "    EVALUATION CHECKLIST (0-5 Score):\n",
    "    1. Does it explain the specific TOPIC? (+1)\n",
    "    2. Does it meet the specific OBJECTIVE? (+1)\n",
    "    3. Is it FREE of complex math notation (No LaTeX/Formulas)? (+1)\n",
    "    4. Is it clear and beginner-friendly? (+1)\n",
    "    5. Is the depth and length appropriate for the topic's complexity? (+1)\n",
    "    \n",
    "    Return JSON ONLY: {{\"score\": int, \"reasoning\": \"string\"}}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "        # Parse JSON\n",
    "        json_match = re.search(r\"\\{.*\\}\", response.content, re.DOTALL)\n",
    "        if json_match:\n",
    "            data = json.loads(json_match.group(0))\n",
    "            score = data.get(\"score\", 0)\n",
    "            reason = data.get(\"reasoning\", \"No reasoning provided.\")\n",
    "        else:\n",
    "            score = 3\n",
    "            reason = \"Could not parse validation JSON.\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Validation error: {e}\")\n",
    "        score = 3\n",
    "        reason = f\"Exception: {e}\"\n",
    "\n",
    "    print(f\"Score: {score}/5 | Reason: {reason}\")\n",
    "\n",
    "    updates = {\n",
    "        \"retries\": current_retries + 1\n",
    "    }\n",
    "    \n",
    "    if score >= best_score_so_far:\n",
    "        updates[\"best_score\"] = score\n",
    "        updates[\"best_essay\"] = essay\n",
    "        print(\"New best essay saved.\")\n",
    "    \n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39bd2ae2-6ca6-4eeb-bb07-f9f826e6b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Graph Routing & Logic Edges\n",
    "\n",
    "def route_source_check(state):\n",
    "    \"\"\"\n",
    "    EDGE LOGIC: Determines path after Cell 5 (Relevance Check).\n",
    "    Reads 'validation_status' set by the Router.\n",
    "    \"\"\"\n",
    "    status = state.get(\"validation_status\", \"needs_search\")\n",
    "    print(f\"ROUTING DECISION: {status}\")\n",
    "    \n",
    "    if status == \"relevant\":\n",
    "        return \"skip_search\"  \n",
    "    else:\n",
    "        return \"perform_search\"\n",
    "\n",
    "def check_quality_gate(state):\n",
    "    \"\"\"\n",
    "    EDGE LOGIC: Determines path after Cell 8 (Grading).\n",
    "    Checks if essay needs refinement or is ready for Quiz.\n",
    "    \"\"\"\n",
    "    score = state.get(\"best_score\", 0)\n",
    "    retries = state.get(\"retries\", 0)\n",
    "    \n",
    "    print(f\"QUALITY CHECK: Score={score}, Retries={retries}\")\n",
    "\n",
    "    # 1. Success (High Score)\n",
    "    if score >= 4:\n",
    "        print(\">> QUALITY PASS. Proceeding to Quiz.\")\n",
    "        return \"pass\"\n",
    "    \n",
    "    # 2. Max Retries Reached \n",
    "    if retries >= 3:\n",
    "        print(\">> MAX RETRIES. Proceeding with current draft.\")\n",
    "        return \"pass\"\n",
    "    \n",
    "    # 3. Fail (Low Score)\n",
    "    print(\">> QUALITY FAIL. Retrying Generation.\")\n",
    "    return \"retry\"\n",
    "\n",
    "def finalize_submission(state):\n",
    "    \"\"\"\n",
    "    NODE: Final cleanup. Ensures 'final_essay' holds the best version.\n",
    "    \"\"\"\n",
    "    print(\"FINALIZING CHECKPOINT...\")\n",
    "    best = state.get(\"best_essay\")\n",
    "    current = state.get(\"final_essay\")\n",
    "    \n",
    "    final = best if best and len(best) > len(current) else current\n",
    "    \n",
    "    return {\"final_essay\": final}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "665d24f8-da12-41b7-ab2f-156a14db4922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic Study Graph Compiled Successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Compile Generator Graph\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Initialize Graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# 1. ADD NODES\n",
    "workflow.add_node(\"check_user_doc\", check_user_doc_and_grade) \n",
    "workflow.add_node(\"perform_web_search\", perform_web_search)  \n",
    "workflow.add_node(\"generate_essay\", generate_essay)            \n",
    "workflow.add_node(\"grade_essay\", grade_essay) \n",
    "workflow.add_node(\"finalize_submission\", finalize_submission) \n",
    "\n",
    "\n",
    "# 2. DEFINE FLOW\n",
    "\n",
    "workflow.set_entry_point(\"check_user_doc\")\n",
    "\n",
    "def route_source_check(state):\n",
    "    return state.get(\"validation_status\", \"needs_search\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_user_doc\",\n",
    "    route_source_check,\n",
    "    {\n",
    "        \"relevant\": \"generate_essay\",        \n",
    "        \"needs_search\": \"perform_web_search\" \n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"perform_web_search\", \"generate_essay\")\n",
    "\n",
    "workflow.add_edge(\"generate_essay\", \"grade_essay\")\n",
    "\n",
    "# Retry Loop\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_essay\",\n",
    "    check_quality_gate, \n",
    "    {\n",
    "        \"pass\": \"finalize_submission\", \n",
    "        \"retry\": \"generate_essay\"     \n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"finalize_submission\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "print(\"Dynamic Study Graph Compiled Successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dce8bbeb-95d0-4e3e-9a5f-22b32a5a1df6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXECUTING LESSON PLAN: Introduction to Convolutional Neural Networks\n",
      "OBJECTIVE: Comprehend the basic structure and key components of Convolutional Neural Networks, including convolutional layers and their application to grid-like data.\n",
      "CHECKING USER DOCUMENT FOR TOPIC: Introduction to Convolutional Neural Networks\n",
      "Document Grade: SUFFICIENT\n",
      "Document is sufficient. Skipping Web Search.\n",
      "GENERATOR: Using strictly User Document.\n",
      "GENERATING ESSAY FOR: Introduction to Convolutional Neural Networks\n",
      "GRADING ESSAY AGAINST OBJECTIVE\n",
      "Score: 5/5 | Reason: The draft lesson effectively explains the topic of Convolutional Neural Networks, meeting the specific objective of comprehending the basic structure and key components of CNNs. It is free of complex math notation, making it accessible to beginners. The language used is clear and beginner-friendly, providing a concise introduction to the subject. The depth and length of the lesson are appropriate for the topic's complexity, covering the essential concepts and components of CNNs without overwhelming the reader.\n",
      "New best essay saved.\n",
      "QUALITY CHECK: Score=5, Retries=1\n",
      ">> QUALITY PASS. Proceeding to Quiz.\n",
      "FINALIZING CHECKPOINT...\n",
      "LESSON COMPLETE: Introduction to Convolutional Neural Networks\n",
      "QUALITY SCORE: 5/5\n",
      "**Introduction to Convolutional Neural Networks**\n",
      "\n",
      "Welcome to this educational guide on Convolutional Neural Networks (CNNs), a fundamental concept in deep learning. In this guide, we will delve into the basic structure and key components of CNNs, exploring their application to grid-like data, such as images.\n",
      "\n",
      "**Artificial Neural Networks (ANNs) Overview**\n",
      "\n",
      "Before diving into CNNs, let's briefly review the foundational architecture of deep learning: Artificial Neural Networks (ANNs). An ANN consists of three main types of layers:\n",
      "\n",
      "1. **Input Layer**: Receives raw data from the dataset, passing it to the next layer without computation.\n",
      "2. **Hidden Layers**: Apply weighted sums, biases, and activation functions to learn complex patterns.\n",
      "3. **Output Layer**: Produces the prediction or classification.\n",
      "\n",
      "The learning process involves forward propagation and backpropagation, using optimizers like gradient descent to minimize loss.\n",
      "\n",
      "**Convolutional Neural Networks (CNNs)**\n",
      "\n",
      "CNNs are specialized neural networks designed for processing grid-like data, such as images. They preserve the spatial relationship between pixels, making them distinct from standard ANNs. Key components of CNNs include:\n",
      "\n",
      "1. **Convolutional Layer**: Applies learnable filters (kernels) to the input image, creating a \"feature map\" that detects specific features like edges, textures, or shapes.\n",
      "2. **Pooling Layer**: Reduces the dimensionality of feature maps while retaining important information, making the model more robust to variations in feature positions.\n",
      "3. **Fully Connected Layer**: Flattens the data into a vector and feeds it into a standard dense network for final classification.\n",
      "\n",
      "**How CNNs Work**\n",
      "\n",
      "CNNs work by applying convolutional and pooling layers to extract features from the input image. The convolutional layer detects local features, while the pooling layer reduces the spatial dimensions of the feature maps. This process is repeated multiple times, allowing the network to learn complex patterns and features. Finally, the fully connected layer classifies the input image based on the extracted features.\n",
      "\n",
      "**Applications of CNNs**\n",
      "\n",
      "CNNs have revolutionized computer vision, powering technologies like:\n",
      "\n",
      "* Facial recognition\n",
      "* Medical image analysis\n",
      "* Self-driving cars\n",
      "\n",
      "In conclusion, Convolutional Neural Networks are a powerful tool for processing grid-like data, such as images. By understanding the basic structure and key components of CNNs, you can unlock the potential of deep learning in computer vision and other applications. Remember, CNNs are a type of neural network that preserves spatial relationships between pixels, making them ideal for image classification and other computer vision tasks.\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Execute Selected Checkpoint\n",
    "\n",
    "if 'initial_state' not in globals() or not initial_state.get(\"topic\"):\n",
    "    print(\"ERROR: No checkpoint selected. Please Run Cell 4 first to generate a plan.\")\n",
    "else:\n",
    "    print(f\"EXECUTING LESSON PLAN: {initial_state['topic']}\")\n",
    "    print(f\"OBJECTIVE: {initial_state['objective']}\")\n",
    "    \n",
    "    # Run the Graph\n",
    "    result = app.invoke(initial_state)\n",
    "    \n",
    "    # Display Result\n",
    "    print(f\"LESSON COMPLETE: {result.get('topic', 'Unknown Topic')}\")\n",
    "    \n",
    "    print(f\"QUALITY SCORE: {result.get('best_score', 0)}/5\") \n",
    "    \n",
    "    print(result.get(\"final_essay\", \"No essay generated.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0813c322-c93c-4073-b076-1a18d092308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Context Processing Node \n",
    "\n",
    "def process_context(state: AgentState):\n",
    "    print(\"PROCESSING CONTEXT FOR QUIZ...\")\n",
    "    \n",
    "    # 1. PRIORITY: USE GENERATED CONTENT\n",
    "    if state.get(\"final_essay\") and len(state[\"final_essay\"]) > 100:\n",
    "        print(\"Using GENERATED ESSAY as the source for questions.\")\n",
    "        \n",
    "        return {\n",
    "            \"doc_context\": state[\"final_essay\"], \n",
    "            \"needs_web_search\": False\n",
    "        }\n",
    "    else:\n",
    "        print(\"No essay found. Logic Error. Triggering Fallback.\")\n",
    "        return {\"needs_web_search\": True, \"doc_context\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79b7648e-9542-48ee-b67d-dbbe19a1a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Strict Context-Based Quiz Generator (Targeted Re-Quiz)\n",
    "import json\n",
    "import re\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def generate_quiz(state):\n",
    "    topic = state.get(\"topic\")\n",
    "    failed_concepts = state.get(\"failed_concepts\", [])\n",
    "    \n",
    "    # 1. GET CONTENT\n",
    "    context_text = (state.get(\"final_essay\") or \"\").strip()\n",
    "    \n",
    "    if len(context_text) < 100:\n",
    "        context_text = (state.get(\"doc_context\") or \"\").strip()\n",
    "\n",
    "    print(f\"QUIZ GENERATOR CONTEXT LENGTH: {len(context_text)} chars ---\")\n",
    "    \n",
    "    # 2. PREPARE PROMPT\n",
    "    if failed_concepts:\n",
    "        print(f\"Generating 5 Targeted Questions for Weak Areas: {failed_concepts}\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are a strict Exam Setter.\n",
    "        \n",
    "        SOURCE TEXT (Contains Original Lesson + Remedial Explanations):\n",
    "        {context_text[:8000]}\n",
    "        \n",
    "        TASK:\n",
    "        The student failed specific concepts: {failed_concepts}.\n",
    "        Generate 5 new conceptual questions that focus **EXCLUSIVELY** on these weak concepts.\n",
    "        \n",
    "        STRICT RULES:\n",
    "        1. **Scope:** Ask questions ONLY about {failed_concepts}. Do not ask about topics the student already mastered.\n",
    "        2. **Synthesis:** Use BOTH the original technical content AND the \"Remedial Explanation\" analogies in the source text to frame your questions.\n",
    "        3. **Variety:** If there is only 1 weak concept, ask 5 different questions testing that single concept from different angles (definition, application, analogy, comparison).\n",
    "        4. **Source:** Answers must be derivable from the Source Text provided.\n",
    "        \n",
    "        FORMAT: Return a JSON List of strings: [\"Question 1\", \"Question 2\", \"Question 3\", \"Question 4\", \"Question 5\"]\n",
    "        \"\"\"\n",
    "    else:\n",
    "        # CASE B: FRESH QUIZ\n",
    "        prompt = f\"\"\"\n",
    "        You are a strict Exam Setter.\n",
    "        \n",
    "        SOURCE TEXT:\n",
    "        {context_text[:6000]}\n",
    "        \n",
    "        TASK:\n",
    "        Generate 5 conceptual questions based EXCLUSIVELY on the Source Text above.\n",
    "        \n",
    "        STRICT RULES:\n",
    "        1. Every question MUST be answerable using strictly the provided text.\n",
    "        2. Do NOT ask generic questions like \"What is {topic}?\". Ask specific details found in the text.\n",
    "        3. Cover 5 distinct sub-topics found in the text.\n",
    "        \n",
    "        FORMAT: Return a JSON List of strings: [\"Question 1\", \"Question 2\", \"Question 3\", \"Question 4\", \"Question 5\"]\n",
    "        \"\"\"\n",
    "\n",
    "    # 3. EXECUTE\n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "        \n",
    "        json_match = re.search(r\"\\[.*\\]\", response.content, re.DOTALL)\n",
    "        if json_match:\n",
    "            questions = json.loads(json_match.group(0))\n",
    "        else:\n",
    "            questions = [f\"Based on the text, explain {topic}.\"]\n",
    "            \n",
    "        return {\"quiz_questions\": questions}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Quiz Gen Error: {e}\")\n",
    "        return {\"quiz_questions\": [f\"What is {topic}?\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6708c2e-f0a3-4387-8639-9442abc37a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Strict Quiz Grading Node \n",
    "\n",
    "import json\n",
    "import re\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def grade_quiz(state):\n",
    "    print(\"GRADING QUIZ ANSWERS...\")\n",
    "    \n",
    "    questions = state.get(\"quiz_questions\", [])\n",
    "    answers = state.get(\"user_answers\", [])\n",
    "    topic = state.get(\"topic\", \"\")\n",
    "    \n",
    "    # Combine Q & A for the LLM\n",
    "    qa_pairs = []\n",
    "    for i, (q, a) in enumerate(zip(questions, answers)):\n",
    "        qa_pairs.append(f\"Q{i+1}: {q}\\nA{i+1}: {a}\")\n",
    "    \n",
    "    qa_text = \"\\n\\n\".join(qa_pairs)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are a strict Academic Examiner.\n",
    "    Topic: {topic}\n",
    "    \n",
    "    Evaluate these 5 Question-Answer pairs.\n",
    "    \n",
    "    TASK:\n",
    "    1. Assign a score out of 20 for EACH answer.\n",
    "    2. Provide a brief FEEDBACK for each answer and ways to improve that answer.\n",
    "    \n",
    "    STRICT GRADING RULES:\n",
    "    - 20 Marks: Perfect. Comprehensive, accurate, and uses correct terminology.\n",
    "    - 15-19 Marks: Strong answer. Concept is correct, but has minor phrasing issues or misses a small nuance/example.\n",
    "    - 10-14 Marks: Partially correct. Core concept is visible but missing key details or terminology.\n",
    "    - 1-9 Marks: Weak. Contains significant errors, vague guessing, or major omissions.\n",
    "    - 0 Marks: Completely incorrect, irrelevant, \"I don't know\", or just repeating the question.\n",
    "    \n",
    "    Do NOT give points for effort. Be objective.\n",
    "    \n",
    "    INPUT:\n",
    "    {qa_text}\n",
    "    \n",
    "    OUTPUT FORMAT (JSON ONLY):\n",
    "    {{\n",
    "        \"results\": [\n",
    "            {{\n",
    "                \"question_index\": 1, \n",
    "                \"score\": 0, \n",
    "                \"feedback\": \"Feedback text here...\",\n",
    "                \"concept_topic\": \"Topic Name\"\n",
    "            }},\n",
    "            ...\n",
    "        ]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "        \n",
    "        # Parse JSON\n",
    "        json_match = re.search(r\"\\{.*\\}\", response.content, re.DOTALL)\n",
    "        if json_match:\n",
    "            data = json.loads(json_match.group(0))\n",
    "            results = data.get(\"results\", [])\n",
    "        else:\n",
    "            results = [{\"score\": 0, \"feedback\": \"Error parsing\", \"concept_topic\": \"Unknown\"} for _ in range(5)]\n",
    "\n",
    "        # ANALYZE SCORES\n",
    "        total_score_raw = 0\n",
    "        failed_concepts = []\n",
    "        \n",
    "        for res in results:\n",
    "            score = res.get(\"score\", 0)\n",
    "            total_score_raw += score\n",
    "            \n",
    "            if score < 15:\n",
    "                concept = res.get(\"concept_topic\", \"General Concept\")\n",
    "                failed_concepts.append(concept)\n",
    "        \n",
    "        final_percentage = int(total_score_raw) \n",
    "        \n",
    "        return {\n",
    "            \"quiz_results\": results,\n",
    "            \"quiz_score\": final_percentage, \n",
    "            \"failed_concepts\": failed_concepts\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Grading Error: {e}\")\n",
    "        return {\"quiz_score\": 0, \"failed_concepts\": [\"Error in grading\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3d8ed8e-800b-41b1-993b-d6fca92089c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15\n",
    "def check_pass_fail(state: AgentState):\n",
    "    score = state[\"quiz_score\"]\n",
    "    \n",
    "    if score >= 70:\n",
    "        print(\"PASSED (>70). Evaluation Successful.\")\n",
    "        return \"pass\"\n",
    "    else:\n",
    "        print(\"FAILED (<70). Routing to Remedial Node.\")\n",
    "        return \"fail\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc9ce5e0-2a32-44bd-ae06-f8e39824ae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Feynman Remedial Node \n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def generate_feynman_explanation(state):\n",
    "    print(\"\\nFEYNMAN MODE ACTIVATED (Score < 70%)\")\n",
    "    \n",
    "    topic = state.get(\"topic\", \"\")\n",
    "    \n",
    "    # 1. RETRIEVE FAILED CONCEPTS\n",
    "    failed_concepts = state.get(\"failed_concepts\", [])\n",
    "    \n",
    "    if not failed_concepts:\n",
    "        failed_concepts = [f\"Core concepts of {topic}\"]\n",
    "\n",
    "    print(f\"Feynman is preparing a lesson on: {failed_concepts}\")\n",
    "\n",
    "    # 2. FEYNMAN PROMPT\n",
    "    prompt = f\"\"\"\n",
    "    You are Richard Feynman, the Great Explainer. \n",
    "    The student is struggling to understand the following specific concepts related to \"{topic}\":\n",
    "    \n",
    "    WEAK CONCEPTS:\n",
    "    {failed_concepts}\n",
    "    \n",
    "    YOUR TASK:\n",
    "    1. Ignore previous quiz questions. Focus on explaining these CONCEPTS from scratch.\n",
    "    2. Use **SIMPLE ANALOGIES** and plain English (e.g., comparing data structures to trains, bookshelves, buckets, traffic).\n",
    "    3. Be encouraging, but ensure the technical depth is sufficient to answer exam questions.\n",
    "    4. Explain it clearly and concisely (maximum 500 words).\n",
    "    \n",
    "    Write the remedial explanation now.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "        feynman_text = response.content\n",
    "        \n",
    "        print(\"\\nGenerated Remedial Explanation.\")\n",
    "        \n",
    "        return {\n",
    "            \"feynman_explanation\": feynman_text,\n",
    "            \"final_essay\": state.get(\"final_essay\", \"\") \n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Feynman Node Error: {e}\")\n",
    "        return {\"final_essay\": state.get(\"final_essay\", \"\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51040768-2edf-44b6-9dfe-3cb6c54f571c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive Assessment Graph Compiled Successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 17: Interactive Assessment Graph\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Initialize Graph\n",
    "workflow_v2 = StateGraph(AgentState)\n",
    "\n",
    "# 1. ADD NODES\n",
    "workflow_v2.add_node(\"process_context\", process_context)\n",
    "workflow_v2.add_node(\"perform_web_search\", perform_web_search)\n",
    "workflow_v2.add_node(\"generate_quiz\", generate_quiz)\n",
    "\n",
    "# 2. DEFINE EDGES\n",
    "workflow_v2.set_entry_point(\"process_context\")\n",
    "\n",
    "def check_search_requirement(state):\n",
    "    return \"perform_web_search\" if state.get(\"needs_web_search\") else \"generate_quiz\"\n",
    "\n",
    "workflow_v2.add_conditional_edges(\n",
    "    \"process_context\",\n",
    "    check_search_requirement,\n",
    "    {\n",
    "        \"perform_web_search\": \"perform_web_search\",\n",
    "        \"generate_quiz\": \"generate_quiz\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow_v2.add_edge(\"perform_web_search\", \"generate_quiz\")\n",
    "\n",
    "workflow_v2.add_edge(\"generate_quiz\", END)\n",
    "\n",
    "# Compile\n",
    "app_v2 = workflow_v2.compile()\n",
    "print(\"Interactive Assessment Graph Compiled Successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c84edb1-7647-45d5-94d9-c82ce12a959f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING QUIZ FOR: Introduction to Convolutional Neural Networks\n",
      "\n",
      "QUIZ ATTEMPT 1\n",
      "(Generating Questions based on current context...)\n",
      "PROCESSING CONTEXT FOR QUIZ...\n",
      "Using GENERATED ESSAY as the source for questions.\n",
      "QUIZ GENERATOR CONTEXT LENGTH: 2718 chars ---\n",
      "\n",
      "Q1: What are the three main types of layers in an Artificial Neural Network (ANN)?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(questions, \u001b[32m1\u001b[39m):\n\u001b[32m     45\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mQ\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m         ans = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAnswer: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m         user_answers.append(ans)\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Agent_Project\\Lib\\site-packages\\ipykernel\\kernelbase.py:1396\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1394\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1395\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1396\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1397\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_shell_context_var\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_shell_parent_ident\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Agent_Project\\Lib\\site-packages\\ipykernel\\kernelbase.py:1441\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1438\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1439\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1440\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1441\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1442\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1443\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Cell 18: Interactive Quiz Loop\n",
    "\n",
    "# 1. SETUP: VERIFY CONTENT\n",
    "if 'result' not in globals() or not result.get('final_essay'):\n",
    "    print(\"ERROR: No generated lesson found.\")\n",
    "    print(\"Please run Cell 11 first to generate the study material.\")\n",
    "else:\n",
    "    # 2. LOAD INITIAL CONTENT\n",
    "    current_topic = result.get('topic', initial_state['topic'])\n",
    "    original_essay = result.get('final_essay', \"\")\n",
    "    \n",
    "    print(f\"STARTING QUIZ FOR: {current_topic}\")\n",
    "\n",
    "    # 3. INITIALIZE STATE\n",
    "    loop_state = {\n",
    "        \"topic\": current_topic,\n",
    "        \"final_essay\": original_essay, \n",
    "        \"quiz_questions\": [], \n",
    "        \"user_answers\": [], \n",
    "        \"quiz_score\": 0,\n",
    "        \"failed_concepts\": [],\n",
    "        \"doc_context\": original_essay, \n",
    "        \"needs_web_search\": False,\n",
    "        \"quiz_results\": []\n",
    "    }\n",
    "\n",
    "    # 4. START LOOP\n",
    "    max_feynman_triggers = 2\n",
    "    attempts = 0\n",
    "\n",
    "    while attempts <= max_feynman_triggers:\n",
    "        attempts += 1\n",
    "        print(f\"\\nQUIZ ATTEMPT {attempts}\")\n",
    "        \n",
    "        # A. GENERATE QUESTIONS\n",
    "        print(\"(Generating Questions based on current context...)\")\n",
    "        quiz_output = app_v2.invoke(loop_state)\n",
    "        questions = quiz_output.get('quiz_questions', [])\n",
    "        loop_state['quiz_questions'] = questions\n",
    "\n",
    "        # B. ASK QUESTIONS\n",
    "        user_answers = []\n",
    "        if questions:\n",
    "            for i, q in enumerate(questions, 1):\n",
    "                print(f\"\\nQ{i}: {q}\")\n",
    "                ans = input(f\"Answer: \")\n",
    "                user_answers.append(ans)\n",
    "        else:\n",
    "            print(\"Error: No questions generated.\")\n",
    "            break\n",
    "\n",
    "        # C. GRADE ANSWERS\n",
    "        print(\"\\nGrading Answers...\")\n",
    "        loop_state[\"user_answers\"] = user_answers\n",
    "        \n",
    "        grading_output = grade_quiz(loop_state)\n",
    "        \n",
    "        total_score = grading_output.get('quiz_score', 0)\n",
    "        current_failed_concepts = grading_output.get('failed_concepts', [])\n",
    "        results_detail = grading_output.get('quiz_results', [])\n",
    "        \n",
    "        # DISPLAY DETAILED FEEDBACK\n",
    "        print(\"DETAILED FEEDBACK\")\n",
    "        \n",
    "        for i, res in enumerate(results_detail):\n",
    "            q_num = res.get(\"question_index\", i+1)\n",
    "            q_score = res.get(\"score\", 0)\n",
    "            q_feedback = res.get(\"feedback\", \"No feedback provided.\")\n",
    "            \n",
    "            print(f\"Q{q_num}: {q_score}/20\")\n",
    "            print(f\"   Feedback: {q_feedback}\\n\")\n",
    "            \n",
    "        print(f\"TOTAL SCORE: {total_score}%\")\n",
    "        \n",
    "        # D. PASS CHECK\n",
    "        if total_score >= 70:\n",
    "            print(f\"\\nPASSED! You have mastered {current_topic}.\")\n",
    "            print(\"Checkpoint Complete.\")\n",
    "            break\n",
    "            \n",
    "        # E. FAIL CHECK\n",
    "        else:\n",
    "            print(f\"FAILED (<70%). Weak Areas: {current_failed_concepts}\")\n",
    "            \n",
    "            if attempts <= max_feynman_triggers:\n",
    "                print(f\"\\nTriggering Feynman Node ({attempts}/{max_feynman_triggers})...\")\n",
    "                \n",
    "                feynman_input = {\n",
    "                    \"topic\": current_topic,\n",
    "                    \"quiz_results\": results_detail, \n",
    "                    \"user_answers\": user_answers,\n",
    "                    \"quiz_questions\": questions,\n",
    "                    \"final_essay\": original_essay\n",
    "                }\n",
    "                \n",
    "                if 'generate_feynman_explanation' in globals():\n",
    "                    feynman_output = generate_feynman_explanation(feynman_input)\n",
    "                    explanation = feynman_output.get(\"feynman_explanation\", \"\")\n",
    "                    \n",
    "                    print(\"\\nFEYNMAN EXPLANATION:\")\n",
    "                    print(explanation)\n",
    "                    \n",
    "                    # F. UPDATE CONTEXT\n",
    "                    combined_context = (\n",
    "                        f\"{original_essay}\\n\\n\"\n",
    "                        f\"=== REMEDIAL EXPLANATION ===\\n\"\n",
    "                        f\"{explanation}\"\n",
    "                    )\n",
    "                    \n",
    "                    loop_state[\"final_essay\"] = combined_context\n",
    "                    loop_state[\"failed_concepts\"] = current_failed_concepts\n",
    "                    \n",
    "                    input(\"\\nPress Enter to take the Re-Quiz...\")\n",
    "                else:\n",
    "                    print(\"Error: Feynman module not found.\")\n",
    "                    break\n",
    "            else:\n",
    "                print(\"\\nMAXIMUM ATTEMPTS REACHED.\")\n",
    "                print(f\"You have triggered the Feynman remedial help {max_feynman_triggers} times and still scored below 70%.\")\n",
    "                print(\"ACTION REQUIRED: You require additional help to clear this checkpoint.\")\n",
    "                break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
